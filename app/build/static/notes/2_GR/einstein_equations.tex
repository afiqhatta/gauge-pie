\pagebreak
\section{The Einstein Equations} 
Space time is a manifold $\mathcal{ M } $ equipped 
with a Lorentzian metric $ g$. We view 
our metric as some matrix which varies from 
point to point on the manifold. The right way 
to write things down here is to write down an 
action principle, then vary the actions to get our 
equations of motion. 

\subsubsection{The Einstein-Hilbert Action} 
The dynamics is governed by the Einstein-Hilbert 
action. 
There's not very much we can write here. 
The only object we have to play with is our metric  $ g $, 
and from this we have our natural volume form we can use. 
The only one we have is the square root of our determinant 
of our metric. Our action must precede 
\[
 S = \int d^ 4 \sqrt{ - g }  
\] Now, what scalar function can we put here? 
The only thing we can do is to pull out our Ricci scalar, 
so that 
\[
 S = \int d^ 4 x \, \sqrt{  - g }  R 
\] Note that schematically, $ R \sim \partial  \Gamma + \Gamma  \Gamma $, 
and $ \Gamma \sim g ^{ - 1} \partial  g $. 
Thus, $ R $ is a function of two derivatives 
of our metric. Note, this 
means that the only connection we 
could cook up is the Levi-Civita connection. This is the simplest thing we can do!
Now, to derive the equations of motion, we need to vary this field. 
We take the metric and push it wish a small change 
\[
 g _{\mu \nu  } \to g _{ \mu \nu } + \delta g _{ \mu \nu }
\] Now, from this we can also deduce how 
the inverse metric changes with this infinitesimal change. 
\[
 g_{ \rho \mu } g ^{ \mu \nu } = \delta \indices{ ^ \nu _ \rho } \implies 
 \delta g_{ \rho \mu } g ^{ \mu \nu } + g _{ \rho \mu  } \delta g ^{ \mu \nu } = 0 
\]  This means 
we can read off our change $ \delta g ^{ \mu \nu }  $ as 
\[
 \delta g ^{ \mu \nu }  =  - g ^{ \mu \rho } g ^{ \nu \sigma } \delta g_{ \rho \sigma}
\] When we vary the whole thing, 
the trick is to write out the Ricci 
scalar in terms of the Ricci tensor 
contracted with the metric. Then, we 
apply the product rule when looking at a small variation.
When we do the small variation, we have to remember 
to hit the colume form as well. 
\[
 \delta S  = \int d ^4  x \, 
 \left[  \delta ( \sqrt{  - g } ) g ^{ \mu \nu } R _{ \mu \nu } + 
 \sqrt{ - g }  \left(  \delta g ^{ \mu \nu } R_{ \mu \nu } + g^{ \mu \nu } \delta R _{ \mu \nu } \right) \right] 
\] We need to figure out 
what $ \delta \sqrt{ - g }   $  is. To do this, 
we prove a claim that 
\begin{claim}
	We claim that 
	\[
	 \delta \sqrt{ - g }   = - \frac{1}{2 } \sqrt{ - g }  g _{ \mu \nu } \delta g ^{ \mu \nu }
	\] 
\begin{proof}
	We use the fact that $ \log \det A = \tr \log A $, which implies 
	that 
	 \[
		 \frac{1}{\det  A } \delta ( \det  A)  = \tr  = \tr ( \delta \log A )  = \tr ( 
		 A^{ - 1} \delta A ) = \tr ( A ^{ - 1 } \delta A ) 
	 \] Now, susbtituting in our metric $ g $ as 
	 the matrix $ A $ in our identity above, this finally implies that 
	 \begin{align*}
		 \delta \sqrt{ - g} &  = \frac{1}{2 } \frac{1}{\sqrt{ - g}  } ( - g ) 
		 g ^{\mu \nu } \delta g_{ \mu \nu } \\
		 &=  \frac{1}{2 } \sqrt{ -g }  g ^{ \mu \nu } \delta g _{ \mu \nu } 
	 \end{align*} 
\end{proof}
\end{claim}

Now, we compute the variation of our Ricci tensor. 
\begin{claim}
	We have that our variation is 
	\[
	 \delta R_{ \mu \nu } = \nabla _ \rho \delta \Gamma ^ \rho _{ \mu \nu } - \nabla_{ \nu  }
	 \delta \Gamma ^ \rho _{ \mu \rho }
	\]  with 
	\[
	 \delta \Gamma ^ \rho _{ \mu \nu } = \frac{1}{2 } 
	 g ^{ \rho \sigma } ( \nabla _ \mu \delta g _{ \sigma \nu } + 
	 \nabla _ \nu \delta g _{ \sigma \mu } - \nabla _ \sigma \delta g_{ \mu \nu } ) 
	\] 
\begin{proof}
	First note that importantly, $ \Gamma ^ \mu _{ \rho \nu } $ is not a tensor. 
	However, the difference $ \delta \Gamma ^ \mu _{ \rho \nu } $ 
	is a tensor since its the difference between two connections. This means that it is a well defined action 
	to take the covariant derivative of the objects
	In normal coordinates, at some point 
	\begin{align*}
		\delta \Gamma^ \rho _{ \mu \nu } &= \frac{1}{2 }  g ^{ \rho  \sigma }\left( 
		\partial  _ \mu \delta g _{ \sigma \nu } + \partial  _ \nu 
	g _{ \sigma \mu } - \partial  _ \sigma \delta g _{ \mu \nu } \right)   \\
						 &=  \frac{1}{2 } g ^{ \rho\sigma } \left(  
						 \nabla _ \mu \delta g _{ \sigma \nu } 
					 + \nabla _ \nu \delta g _{ \sigma \mu } 
				  - \nabla _{ \sigma } \delta g _{ \mu \nu }\right)  
	\end{align*}
	Since we're in normal coordinates, we can now replace our partial 
	derivatives $ \partial $ with covariant derivatives $ \nabla $. 
	This gives us a tensorial relation, and hence this 
	holds true in all coordinate frames. We can play the same 
	game with our Riemann tensor, 
	\[
	 R \indices{ ^ \sigma _{ \rho \mu \nu } }  = \partial  _ \mu \Gamma ^ \sigma _{ \nu \rho } 
	  - \partial  _ \nu \Gamma ^ \sigma _{ \mu \rho }
	\]  This implies that our small change 
	is given by 
	\begin{align*}
		\delta R \indices{ ^ \sigma _{ \rho \mu \nu } } &=  \partial  _ \mu  
		\delta \Gamma ^ \sigma _{ \mu \rho }  - \partial  _ \nu \delta \Gamma 
		^ \sigma _{ \mu \rho }\\
		&=  \nabla _ \mu \delta \Gamma ^ \sigma _{ \nu \rho } - 
		\nabla _ \nu \delta \Gamma ^ \sigma _{ \mu \rho } \\
	\end{align*} Since $ \Gamma  =0 $ in normal coordinates.  
\end{proof}
\end{claim}
\begin{thm}{(Vacuum Einstein Equations)}

Now we have that, after all the dust has settled, 
that 
\[
 \delta S = \int d ^ 4 x \, \sqrt{ - g }  \left[  
 R _{ \mu \nu }  - \frac{1}{2 } R g _{ \mu \nu } \right] \delta g ^{ \mu \nu } + \nabla _ \mu X ^ \mu  
\] Where we've written 
\[
 X ^ \mu = g ^{ \rho \nu } \delta \Gamma ^ \mu _{ \rho \nu }  - g ^{ \mu \nu } \delta \Gamma ^ \rho _{ \nu \rho }
\] 
When we impose the condition of stationarity for some 
arbitrary change in the metric, we then have a condition for our integrand. 
This yields the vacuum Einstein equations. 
\[
 \delta S = 0 , \forall g ^{ \mu \nu } \implies 
 G _{ \mu \nu } = R _{ \mu \nu } - \frac{1}{2 } R g _{ \mu \nu } =0 
\] Multiplying this quantity by $ g ^{ \mu \nu } $, we have that 
$ R = 0 $, which implies the vacuum Einstein equations 
\[
 R_{ \mu \nu } = 0 
\]
	
\end{thm}


\subsubsection{Dimensional analysis} 
We can use dimensional analysis to fill out the 
constants here. Our action $ S $ has dimension 
$ M L ^{ 2 } T ^{ - 1}  $, Our metric is dimensionless, and 
$ R $ has units of $ L ^{ - 2} $. This implies that 
our full action is 
\[
 S = \frac{ c ^ 3  }{  16 \pi G} \int d ^ 4 x \, \sqrt{ -g }  R
\]  Our Planck mass
is $ \mathcal{ M } _{ pl } ^ 2  = \frac{ \planck c }{8 \pi G }$ and 
this is approximately $ \mathcal{ M } _{ pl } \propto 10 ^{ 18 } G eV $. 
Work with units with $ c = 1 $, and $ \planck = 1 $. Throughout 
the next of the section, we shall 
work in terms of this Planck mass. 

\subsubsection{The Cosmological Constant} 
We could add a further term to the action 
 \[
	 S = \frac{1}{2 } \mathcal{ M  }_{ pl } \int d ^ 4 x \, \sqrt{ - g}  ( R - 2 \Lambda ) 
\] We will study these. 
We have the equation 
\[
 R_{ \mu \nu } - \frac{1}{2 } R g _{ \mu \nu } = - \lambda g _{ \mu \nu } \implies 
 R = 4 \Lambda \implies R_{ \mu \nu }  = \Lambda g _{ \mu \nu }
\]

\subsection{Diffeomorphisms Revisited} 
Our metric has $ \frac{1}{2 } 4 \cdot  5  = 10 $ components. 
But two metrics related by $ x ^ \mu \to \tilde{x } ^ \mu ( x)  $ 
are physically equivalent. 
This means that actually we only have $ 10 - 4  = 6 $ degrees of freedom.
The change of coordinates can be viewed as a diffeomorphism 
\[
 \phi : \mathcal{ M } \to \mathcal{ M }
\] such 'diffeos' are the 'gauge symmetry' of general relativity.
Consider diffeomorphisms which take the form 
\[
	x ^ \mu \to \tilde{ x } ^ \mu ( x) = x ^ \mu + \delta x ^ \mu  
\] Moreover, we can 
view this as a diffeomorphism generated by a vector field 
$ X ^ \mu  = \delta x ^ \mu $. The metric 
transforms as $ g_{ \mu \nu } ( x) \to \tilde{ g } _{ \mu \nu } ( \tilde{ x  })   $
with $ \tilde{ g } _{ \mu \nu } ( \tilde{ x  } )  = \frac{\partial \tilde{ x } ^ \rho  }{\partial x ^ \mu }
\frac{\partial \tilde{ x } ^ \sigma  }{\partial  x ^ \nu }  g _{ \rho \sigma }  ( \tilde{ x  } )  $. 
From our definition that these coordinates are generated by a vector field, 
this is equal to 
\begin{align*}
	\dots &  = ( \delta \indices{ _ \mu ^ \rho } + \partial  _ \mu X ^ \rho ) 
	( \delta \indices{ _ \nu ^ \sigma  } + \partial  _ \nu X ^ \sigma ) 
	( g_{ \rho \sigma } ( x ) + X ^ \lambda \partial  _ \lambda  g_{ \rho \sigma } ( x) ) \\
	      &=  g_{ \mu \nu } ( x) + X ^ \lambda \partial  _ \lambda g _{ \mu \nu } ( x) 
	      + g _{ \mu \rho } ( x ) \partial  _ \nu X ^ \rho + 
	      g _{ \nu \rho } \partial  _ \mu X ^ \rho \\
\end{align*}  
This means that our infinitesimal change is 
\begin{align*}
	\delta g _{ \mu \nu }  & = X ^ \lambda \partial  _ \lambda g _{ \mu \nu } + 
	g _{ \mu \rho } \partial  _ \nu X ^ \rho + g _{ \nu \rho } \partial  _ \mu X ^ \rho \\
			       &= (  \mathcal{ L  } _ X g)_{ \mu \nu }  \\
\end{align*}
Alternatively, we can write this as 
\begin{align*}
	\delta g_{ \mu \nu } &=  \partial  _ \mu X _ \nu + \partial  _ \nu X _ \mu 
	+ X ^ \rho \left(  \partial  _ \rho g _{ \mu \nu } - 
	\partial  _ \mu g _{ \rho \nu } - \partial  _ \nu g _{ \mu \rho }\right) \\
	&=  \partial  _ \mu X _ \nu + \partial  _ \nu X _ \mu + 2 X ^ \rho g _{ \rho \sigma } T ^ \sigma _{ 
	\mu \nu } \\
	&=  \nabla _ \mu X _ \nu + \nabla _ \nu X _ \mu  \\
\end{align*}
Now, let's look back at the action
\[
 \sigma S = \int d ^ 4 \sqrt{ -g  }  G ^{ \mu \nu } \delta g _{ \mu \nu }
\] If we restrict to these changes of coordinates, 
the above 
\[
 \dots = 2 \int d ^ 4 x \, \sqrt{ - g }  G ^{ \mu \nu } \nabla _ \mu X _ \nu 
 =0 \forall X  =  -2 \int d ^ 4 x \, \sqrt{ - g }  ( \nabla _ \mu G ^{ \mu \nu } )  X^ \nu 
\]  this is because changing coordinates is a gauge symmetry. 
This means that our Einstein tensor obeys 
\[
 \nabla _ \mu G ^{ \mu \nu }  = 0
\] This means that diffeomorphisms are 
a symmetry implies the Bianchi identity. 
So, not all of the $ G ^{ \mu \nu } $ are independent. 
We have found four conditions, which means that the 
Einstein equations $ G _{ \mu \nu } $ is really only 
6 equations, which is the right number of components 
to determine our metric $ g _{ \mu \nu } $. 

\subsection{Some simple solutions} 
Let's look at what happens when we have a vanishing 
cosmological constant with $ \Lambda  =0 $. 
We need to solve  $ R_{ \mu \nu }  = 0$. 
It's tempting to write $ g _{ \mu \nu } = 0 $, 
but this isn't allowed because the metric requires an inverse! 
This makes gravity different from other field theories, 
we need to have the constraint that non of the eigenvalues are zero. 
This may suggest that the metric is not a fundamental field. There 
are lots of similarities to this an fluid mechanics. 
The simplest solution is Minkowski space time. 
\[
 ds ^ 2 = - d t ^ 2 + d \vec{x} ^ 2 
\] 

\subsubsection{De Sitter Spacetime} 
In the case, $ \Lambda > 0 $, we can look for solutions 
to $ R _{ \mu \nu }  = \Lambda g_{ \mu \nu }$ which have some 
spherical symmetry. We look for solutions of the form 
\[
	d s^ 2 = - f (r ) ^ 2 d t ^ 2 + f ( r ) ^{ - 2} dr ^ 2 + r ^ 2 ( d \theta ^ 2 
	+ \sin^ 2 \theta d \psi ^ 2 ) 
\] 
We can compute our Ricci tensor 
to find 
\[
	R _{ t t }  =  - f^4 R_{ rr }  = f ^  3 \left( f '' + \frac{2 f ' }{ r } + ( f ' ) ^2 f 
		\right), \quad 
	R_{ \psi \psi }  = \sin ^ 2 \theta  R _{ \theta \theta  } = ( 1 - f ^ 2 - 2 f f ' r ) \sin ^ 2 \theta 
\] 
Now, with this ansatz we can solve 
for $ f ( r) $ by setting $ R_{ \mu \nu } = \Lambda g _{ \mu \nu } $, 
and then solving the equation by substituting in 
specific indices. 
By setting $ \mu , \nu = t t , r r $ we get that 
 \[
	 f '' + \frac{2 f ' }{ r } + \frac{ ( f ' ) ^ 2 }{ f }  = - \frac{\Lambda }{ f }
\] 
Similarly, by setting $ \mu,  \nu = \theta \theta , \psi \psi  $, we have 
\[
 1 - 2 f f ' r - f ^ 2 = \Lambda r ^ 2 
\] This equation is solved by 
\[
 f ( r)  = \sqrt{ 1 - \frac{ r ^ 2 }{ R ^ 2 }} , \quad R ^ 2 = \frac{ 3 }{ \Lambda}
\] This means that our resulting, final metric 
that we get takes the form
\[
	ds ^ 2 = -  \left( 1 - \frac{r^ 2 }{R^ 2 } \right)^2 dt ^ 2 + \left( 1 - \frac{r^2}{R^ 2 } 
	\right) ^{ -2 } dr^ 2 
	+  r ^ 2 d \Omega_2 ^ 2
\] To save ink, we've written $ r ^ 2 ( d \theta ^ 2 + \sin ^ 2 \theta d \phi ^ 2 ) $
as $ r ^ 2 d \Omega_2 ^ 2 $, which is the radius squared, multiplied by 
the familiar metric on a unit 2-sphere. In particular, if we have 
a set of three Cartesian coordinates such that 
\[
 x ^ 2 + y ^ 2 + z ^  2 = r
\] then since this parametrises a $ 2 $-sphere of radius $r$, 
our resulting metric in spherical coordinates is 
 \[
 d^ 2 x + d y ^ 2 + d z^ 2 = dr^2 + r ^ 2 d \Omega ^ 2 _ 2 
\] 
This will save a lot of time later in our calculations 
which involve different ways 
to parametrise this metric. 

This is de Sitter space time (or alternatively called the static patch of 
d S ). Note that we have a valid range from $ r \in [ 0 , R ] $, but the 
metric appears to be singular at $ r = R $. Throughout this section, 
we will check whether this singularity comes 
from merely a poor choice of coordinates, or is a genuine
physical space-time singularity. 
Recall, it's totally okay for this to be a coordinate singularity 
(in fact, as we shall see, it is) because 
when we define coordinates,  we only define them 
in terms of coordinate patches. 
We can look at geodesics. We have the action, where $ \sigma $ represents proper time 
\[
 S  = \int d \sigma \left[  
 - f ( r) ^ 2 \dot{t } ^ 2 + f ( r) ^{ - 2 } \dot{ r } ^ 2 
 + r ^ 2 \left(  \dot{ \theta } ^ 2 + \sin ^ 2 \theta \dot{ \phi  }  ^ 2  \right)  \right] 
\] Here, 
there are two conserved quantities. Nothing depends on $ \phi $, 
so we have that 
$ l = \frac{1}{2 } \frac{\partial  L }{ d \dot{\phi }  } = r ^ 2 \sin ^ 2 \theta \dot{\phi  } $. 
The other conserved quantity we get is the energy of the particle with 
\[
	E =  - \frac{1}{2 } \frac{\partial  L }{\partial  \dot{ t } } = f ( r) ^ 2 
	\dot{t }  
\] For a massive particle, 
we also require that the trajectory is timelike.
Since $ \sigma  $ represents proper time, this means 
that the Lagrangian itself is equal to 
\[
 - f ^ 2 \dot{ t } ^ 2 + f ^{ - 2 } \dot{ r } ^ 2 + r ^ 2 
 ( \dot{ \theta } ^ 2 + \sin ^ 2 \theta  \dot{ \phi } ^ 2  ) = - 1  
\]
Look for geodesics with $ \theta = \frac{\pi }{ 2 } $ and $ \dot{ \theta } ^ 2  $. 
This gives 
\[
	\dot{ r } ^ 2 + V_{ eff} ( r)  = E ^ 2  
\] with 
\[
	V_{ \text{eff} }( r) = ( 1 + \frac{l ^ 2 }{ r ^ 2 } ) ( 1 - \frac{ r ^  2 }{R ^ 2  } ) 
\] For $ l  = 0 $, we have that 
\[
	r ( \sigma)  = R \sqrt{ E ^ 2 - 1}  \sinh ( \frac{ \sigma }{ R } ) 
\]  This hits $ r = R $ in finite $ \sigma $. Meanwhile 
\[
	\frac{ d t }{ d \sigma } = E \left(  1 - \frac{ r ^ 2 }{ R ^ 2 }  \right)  ^{ - 1}
\] Solutions to this have $ t \to \infty $ as $ r \to R $. 
To see this, suppose $ r ( \sigma _ * )  = R $ and expand $ \sigma = \sigma_{ * }  - \epsilon $. 
We find that 
\[
 \frac{ d t }{ d \epsilon } \simeq  - \frac{ \alpha }{ \epsilon } 
\] this of course means that $ t \sim  - \alpha \log ( \frac{ \epsilon }{ R } ) $, 
and $ t \to \infty $ as $ `\epsilon \to 0 $. 
so, it takes a particle finite proper time  $ \sigma $ but infinite 
coordinate time $ t $.

In fact, the de Sitter space time can 
be embedded in 5 dimensional Minkwoski space, $ \mathbb{ R} ^{ 1, 4 } $. 
which is 
\[
	d s ^ 2 =  -  ( d X^ 0 ) ^ 2 + \sum_{ i = 1 } ^ 4 ( dX ^ i ) ^ 2 
\]  Our surface which we are embedding is 
\[
	- ( X^ 0 )^ 2 + \sum_{ i = 1 } ^ 4 ( X ^ i ) ^2  = R ^ 2 
\] This can be viewed as a hyperbola in Minkowski space. 
The flat metric is inherited onto the surface. 
We will show that this is true. 
We let $ r ^ 2  = \sum_{ i = 1 } ^ 3 ( X ^ i ) ^ 2 $ and $ X ^ 0 = \sqrt{ R ^ 2 - r ^ 2  } 
\sinh ( \frac{t}{ R } ) $, and also that $ X ^ 4  = \sqrt{ R ^ 2 - r ^ 2 }  \cosh ( \frac{t}{ R } ) $. 
This means that, we have \[
  - ( X ^ 0 ) ^ 2 + ( X ^ 4 ) ^ 2  = R ^ 2 - r ^ 2
\] Now just substitute and plug those in. We can check that 
of you compute $ d X ^ 0  $ and $ d X ^ 4 $, and plug into 
the metric in 5 dimensional Minkowski space, we'll recover 
the de Sitter metric. Note that we above is a really weird 
parametrisation! We only singled out $ X ^ 0$ and $ X ^ 4 $. 
Moreover, $ X ^ 4 $ only runs from $ - \infty $ to $ \infty $, 
but in our parametrisation we only have that 
$ X ^ 4 > 0 $. These coordinates are not particularly symmetric, 
and moreover cover only $ X ^ 4 \geq 0 $ . 
A better choice of coordinates is 
\[
	X ^ 0 = R \sinh \left(  \tau / R  \right) , \text{ and } X ^ i = \cosh \left(  \tau / R  \right)  \cdot   y
	^ i 
\] where we have a normalisation constraint on $ y $, such that $ \sum_{ i   = 1 } ^ 4 ( y ^ i ) ^ 2  = 1$. 
Another small calculation, we substitute this 
into our 5d Minkowski metric. We have that 
\[
 d s^ 2  = - d \tau ^ 2 + R ^ 2 \cosh ^ 2 \left(  \tau / R  \right)  d \Omega_ 3 ^ 2 
\] where $ d \Omega _ 3 ^ 2 $ is a metric on  $  S^ 3 $. 
This is a hard calculation, but we've swept this under the rug 
and put these into the $ 3 $ sphere metric. 
We can see that these are a better 
description of de Sitter space time because they describe the whole space, 
and has no more coordinate singularities. 
These are global coordinates. This metric also solves 
the Einstein equations with the same cosmological constant
since it's just a change of coordinates 
from our original solution. 
So now we have two metric which describes the same space. 
There's a natural cosmological interpretation here. 
We have a 3-sphere, which initially shrinks, then expands. This 
corresponds to a contracting / expanding universe. 

\subsubsection{Anti de-Sitter Space-time} 
The next solution we will look at is for 
$ \Lambda < 0 $. Again, looking for solutions 
\[
 ds^2 = - f ( r) ^ 2 dt ^ 2 + f ( r) ^{ - 2} dr ^ 2 + r ^ 2 d \Omega _ 2 ^ 2 
\] We find that in this case, 
\[
 f ( r) = \sqrt{ 1 + \frac{ r^ 2 }{ R ^ 2 } }  , \quad R ^ 2 = - \frac{ 3 }{ \Lambda}
\] This is called anti-de Sitter space-time (AdS). 
There is no coordinate singularity here! 
This time, massive geodesics obey the rule $ \dot{ r } ^ 2 + V_{ \text{eff} } = E ^ 2  $. 
This potential energy is what it was before but there's 
now a plus sign instead of a minus sign 
\[
	V_{ \text{eff} } ( r) = \left(  1 + \frac{l ^ 2 }{ r ^ 2 }   \right) \left(  
	1 + \frac{ r ^ 2 }{ R ^ 2 }\right) 
\] What's happening is that 
this kind of looks like a gravitational potential well in which we're stuck in. 
In particular, massive particles seemed to be confined to 
the centre of Anti de-Sitter space. The origin 
is special here.

Now let's look at massless particles. 
Massless particles follow null geodesics. This means 
that in the derivation of our geodesics we had a constrant 
which was $- 1 $, but we can change this to zero. 

\[
	- f ^ 2 \dot{ t} ^ 2 + f ^{ - 2 } \dot{ r } ^ 2 + 
	r^ 2 \left(  \dot{ \theta } ^ 2 + \sin ^ 2 \theta \dot{ \phi } ^ 2    \right)  = 0 
\] This means that 
at the point $ \theta = \frac{ \pi }{ 2 } , \dot{ \theta } = 0  $, 
we have that our potential obeys $ \dot{ r } ^ 2 + V_{ eff } ( r) 
 = E^ 2 $, and our null geodesic obeys 
 \[
	 V_{ \text{ null} } = \frac{ l ^ 2 }{ 2 r ^ 2 } \left(  
	 1 + \frac{ r ^ 2 }{ R ^ 2}\right) 
 \] We introduce new coordinates, $ r = R \sinh \rho $. 
 Plugging this into our de-Sitter metric, the sinh is 
 chosen so the radial coordinate factors out. 
 Thus, we get 
  \[
  d s^ 2 = - \cosh ^ 2 \rho d t ^ 2 +  R^ 2  d \rho ^ 2 
  + R ^ 2 \sinh ^ 2 \rho ( d \theta ^ 2 + \sin ^ 2 \theta d \phi ^ 2 ) 
 \] The null geodesic equation is 
 \[
  R \dot{ r }  = \pm \frac{E }{ \cosh \rho } \implies 
  R \sinh \rho  = E ( \sigma - \sigma _{ 0 } ) 
 \]  
 Massless particles hit $ \rho \to \infty$ as $ \delta \to \infty$.
 However, $ E = \cosh^ 2 \rho \dot{ t } \implies R \sinh \rho  = 
 R \tan \left(  t / R  \right)   = E ( \sigma - \sigma _ 0 ) $. 
 SO, $ t \to \frac{ \pi R }{ 2 } $ as $ \sigma \to \infty $. 
 Massless particles reach infinity of AdS in finite coordinate time. 
 AdS can be viewed as a hyperboloid in $ \mathbb{ R} ^{ 2, 3, } $ 
 as \[
	 -( X ^ 0 ) ^ 2 - ( X ^ 4 ) ^ 2 + \sum_{ i = 1 } ^ 3 ( X ^ i ) ^  2 = R^ 2
 \] Now, let
 \begin{align*}
 	X ^ 0 &=  R \cosh \rho \sin \frac{ t }{ R  }  \\ 
	X ^ 4 &=  R \cosh \rho \cos \frac{ t }{R }  \\
	X ^ i &=  R y ^ i \sinh \rho , \quad \sum ( y ^ i ) ^ 2 = 1 \\
 \end{align*} 
 and we hence recover the AdS metric. 
 There is one last set of coordinates which we can 
 examine. 
 \begin{align*}
 	X^ i &=  \frac{ \tilde{ r }  }{ R } x ^ i , \quad i = 0, 1, 2   \\
	X^ 4 - X ^ 3 = \tilde{ r } 
	X^ 4 + X ^ 3  = \frac{ R ^ 2 }{ \tilde{ r } } + \frac{ \tilde{ r }  }{ 
	R ^ 2 } \eta_{ ij }  x^ i x ^ j 
 \end{align*}
 The metric we get out of this is 
 \[
  d s^ 2 = R ^ 2 \frac{d \tilde{ r } ^ 2  }{ \tilde{ r } ^ 2  } 
  + \frac{ \tilde{r } ^ 2  }{R ^ 2  } \eta_{ ij }dx ^ i dx ^ j 
 \]  These don't cover all of AdS. This is called the Poincare patch. 

\subsection{Symmetries}
Let's look at some symmetries of the metric. 
The first thing we'd like to do is explain what a symmetry actually is. 
Think about a 2 dimensional sphere. 
This has the symmetry group $ SO ( 3) $, 
since we can rotate it in any axis. Now think 
of a rugby ball. This has $ SO ( 2) $ symmetry since 
we can only rotate it about one axis. 
The correct way to think about these things is to consider flows. 
Consider a 1-parameter family of diffeomorphisms 
$ \sigma _ t : \mathcal{ M } \to \mathcal{ M } $. 
Recall that this is associated to a vector field 
\[
 K^ \mu =  \frac{dx ^ \mu }{ dt }
\] where $ \frac{ d x ^ \mu }{ dt } $ are tangent to the flow lines. 
We're going to call this a symmetry if we start at any point, 
flow along, then our destination point looks the same.

This flow is an isometry if the metric 
looks the same at each point along the flow, in other words 
\[
 \mathcal{ L }_K g = 0 \iff \nabla _ \mu K _ \nu + \nabla _ \nu K _ \mu  =0 
\] We can show that the second expression 
is equivalent to the first by recalling the expression 
for a Lie derivative, and then working in normal coordinates to 
get the covariant expression out. 
In components, our Lie derivative is 
\[
	( \mathcal{ L } _ X g )_{ \mu \nu }  =  K ^ \alpha \partial  _ \alpha g _{ \mu \nu } 
	 + g_{ \alpha \nu } \partial  _ \mu K ^ \alpha + 
	 g _{ \alpha \mu } \partial  _ \nu K ^ \alpha 
 \] In normal coordinates, our first term 
 disappears since the metric is flat, and we 
 can convert the partial derivatives to covariant derivatives, 
 which gives us the second expression. This equation is 
called the 'Killing equation' and any vector $ K  $ which 
obeys this is 
called the Killing vector. 
This is the equation which we need to solve. 
These objects describe the symmetries of the metric. 

Note, commuting the Lie derivatives is handy because 
\[
	\mathcal{ L } _ X \mathcal{ L } _ Y - \mathcal{ L } _ Y \mathcal{ L } _ X  = \mathcal{ L } _{ [ X, Y ] }
\] You can 
show this easily in the case of the Lie derivative 
acting on either a function or a vector field (the first is trivial, 
for a vector field just apply Jacobi). From this, we start to get a Lie 
algebra structure that emerges for the group 
of continuous symmetries of the metric, (which 
is exactly what we expect from continuous symmetries).

\begin{example}{Minkowski space} 
With Minkwoski space in our metric, 
the Killing equation implies 
\[
 \partial _ \mu k _ \nu + \partial  _ \nu k _ \mu  = 0
\] In full generality, we have that 
\[
	k _{ \mu }  = c_\mu + \omega _{ \mu \nu } x ^ \nu , \omega_{ \mu \nu }  =- \omega  _{  \nu \mu }
\] We have that $ c _ \mu $ represent our translations, 
and $ \omega_{ \mu \nu } $ represent boosts or rotations 
depending on what indices we're choosing. 
We can define Killing vectors 
\[
 P _ \mu  = \frac{\partial   }{ \partial  x ^ \mu } , \text{ and } M_{ \mu \nu } 
  = \eta _{ \mu \rho } x ^ \rho \frac{\partial  }{\partial  x ^ \nu }   - \eta _{ \nu \rho } x ^ \rho \frac{\partial  }{\partial  x ^ \mu } 
\] Now, we find that $ [ P_\mu, P _ \nu  ]  $ , and that 
\[
	[ M_{ \mu \nu }, P _ \sigma ] =  - \eta _{ \mu \sigma } P _ \nu + \eta_{ \sigma \nu } P_{ \mu } 
\] in addition, 
\[
	[ M_{ \mu \nu } , M_{ \rho \sigma  } ] = \eta_{ \mu \sigma } M_{ \nu \rho } + \eta_{ \nu \rho } M_{ \mu \sigma } 
	 - \eta_{ \mu \rho } M_{ \nu \sigma } - \eta_{ \nu \sigma } M_{ \mu \rho }
\] These are the commutation relations of the Poincare group. 	
\end{example}

\subsubsection{More examples} 
The isometries of dS and AdS are inherited from 
the 5 dimensional embedding. 
de-Sitter space time has isometry group $ SO ( 1, 4 ) $, 
and Anti de-Sitter space has isometry group $ SO ( 2, 3 ) $. 
Both groups have dimension  $ 10 $, same as 
$ SO ( 5 ) $, and the same is the Poincare group as well.
Minkowski and de-Sitter space are equally as symmetric.
In 5d, the Killing vectors are 
\[
 M_{ AB }  = \eta_{ AC } X ^ C \frac{\partial  }{\partial  X ^ B } - 
 \eta _{ B C} X ^ C \frac{\partial   }{\partial  X ^ A } 
\] In this case, $ A $ runs from $ A  = 0 , 1, 2, 3, 4$, 
and we have that the metric are given by 
 \begin{align*}
	 \eta &=  ( - , + , + , + , + )  \\
	 \eta &=  (- , -, + , + , + )  \\
 \end{align*} 
 The flows induced by $ M_{AB } $ map the embedding 
 hyperboloid to itself. These are isometries of 
 ( A ) dS. 
 Let's look at an example in de Sitter space in static patch coordinates. 
 If the metric $ g_{ \mu \nu } ( x) $, does not 
 depend on some coordinate $ y $, then $ K = \frac{\partial }{\partial y } $ 
 is a Killing vector since $ \mathcal{ L }_{ \partial  _ y } g   = 
 \frac{ \partial  g_{ \mu \nu } }{ \partial  y }  = 0 $. 
 So, for the static path, we expect $ \frac{\partial  }{\partial  t }  $ 
 to be a Killing vector.

 We had 
 \begin{align*}
	 X ^ 0 &=  \sqrt{ R ^ 2 - r ^ 2 }  \sinh \left(  \frac{t}{R} \right)  \\
	 X ^ 4 &=  \sqrt{ R ^ 2 - r ^ 2 }  \cosh \left(  \frac{t}{R} \right)  \\
 \end{align*}
 Look at 
 \[
  \frac{\partial  }{\partial  t }  =  \frac{\partial X ^ A  }{\partial t }  
  \frac{\partial  }{\partial  X ^ A }   = \frac{1}{R  } \left(  X ^ 4 \frac{\partial  }{\partial  X ^ 0 }
   + X ^ 0 \frac{\partial   }{\partial X ^ 4 } \right) 
 \]  It's interesting to note that 
 timelike Killing vectors such that $ g_{ \mu \nu  }  k ^ \mu k ^ \nu  < 0 $ 
 are used to define energy. Minkowski and AdS have such objects. 
 de-Sitter space has such an object in the static patch, 
 but not globally. 
For example, 
\[
 K = X ^ 4 \frac{\partial  }{\partial  X ^ 0 }  + X ^ 0 \frac{\partial  }{\partial  X ^ 4 } 
\] Now, the first term increases $ X ^ 0 $ then $ X ^ 4 > 0 $, 
and decreases $ X ^ 0 $ when $ X ^ 4 < 0 $. 
The Killing vector is positive and timelike only in the static patch. 
Elsewhere, it is spacelike. Energy is a subtle concept in dS.

\subsection{Conserved quantities} 
Consider a particle moving on a geodesic  $ x ^ \mu ( \tau ) $ 
in a spacetime with Killing vector $ K ^ \mu $. 
Then, we have that 
\[
 Q  = K_ \mu \frac{d x ^ \mu }{ d \tau } \text{is conserved }
\] To see this, differentiate to find that 
\begin{align*}
	\frac{d Q }{ d \tau }   & = \partial  _ \nu k _ \mu \frac{d x ^ \nu }{ d \tau } \frac{ d x ^ \mu }{ d \tau } 
	+ k _ \mu \frac{ d ^ 2 x  }{ d \tau ^ 2 } \\
	&=  \partial  _ \nu k _ \mu \frac{d k ^ \nu }{ d \tau } \frac{ d x ^ \mu }{ d \tau }  - 
	k _ \mu \Gamma ^ \mu _{ \rho \sigma } \frac{d x ^ \rho }{ d \tau } \frac{ d x ^ \sigma }{ d \tau } \\
	&=  \nabla _ \nu k _ \mu \frac{ d x ^ \nu }{ d \tau } \frac{ d x ^ \mu }{ d \tau } \\ 
\end{align*} 
We can also see this from the action 
\[
 S  = \int d \tau g_{ \mu \nu } \dot{ x } ^ \mu \dot{ x } ^ \nu   
\] Consider $ \delta x ^ \mu ( \tau )  = k ^ \mu ( x) $. We have 
 \[
 \delta S  = \int d \tau \, \partial  _ \rho g_{ \mu \nu } \frac{ d x^ \mu }{ d \tau } \frac{ d x ^ \nu }{ d \tau } 
 + 2 g_{ \mu \nu } \frac{d x ^ \mu }{ d \tau } \frac{ dk  ^ \nu }{ d \tau }
\] 
Now, we use the fact that 
\begin{align*}
	g_{ \mu \nu } \frac{d  k ^ \nu }{ d \tau } &=  \frac{d k _\mu }{ d \tau } - \frac{d g _{ \mu \rho } }{ d \tau } k ^ \rho  \\
						   &=  \left(  \partial  _ \nu k _ \mu 
						    - \partial  _ \nu g _{ \mu \rho } k ^ \rho \right)  
						    \frac{ d x ^ \nu }{ d \tau }\\
\end{align*}
Substituting this into the action 
\[
 \delta S = \int d \tau 2 \nabla _ \mu K _ \nu \frac{ d x ^ \mu }{ d \tau } \frac{ d x ^ \nu }{ d \tau }
\] This implies that $ \sigma S = 0 $ iff $ \nabla _{ ( \mu } k_{ \nu ) }  = 0 $, the Killing equation.

\subsection{Asymptotics of Spacetime} 
Given a spacetime $ \mathcal{ M } $, with metric 
$ g _{ \mu \nu } ( x) $, we consider a 
conformal transformation 
\[
	\tilde{ g } _{ \mu \nu } ( x) = \Omega ^ 2 (  x) g_{ \mu \nu } ( x)  
\] where $ \Omega( x) $ is smooth, and non zero. 
These metrics don't necessarily 
have the same symmetries - they're different metrics 
that in general describe  \textbf{different } space times. 
They do have one thing on common, however, 
which is important. A vector which is 
null in the $ g _{ \mu \nu } $ spacetime 
is also null in the $ \tilde{ g } _{ \mu \nu  }  $ space 
time. 
This means that they have the same causal structure. 
\[
 g_{ \mu \nu }  X^ \mu    X^\nu =0   \iff \tilde{ g } _{ \mu \nu } X^\mu X^\nu  = 0 
\] Since 0 is the dividing line between positve and negative, 
null / spacelike / timelike vectors in $ g _{ \mu \nu } $ 
map to null / spacelike / timelike vectors in $ \tilde{ g } _{ \mu \nu }  $. 
Conformal transformations are something that crop up 
everywhere in physics. 

\subsubsection{Penrose Diagrams}
The idea is to use conformal transformations 
to bring the infinity of space time 
a 'little bit closer', in such a way 
that is becomes simple to visualise what infinity looks like. 
There is some fancy technical way to do these diagrams, 
but we'll just do examples to get the feel.

In Minkowski space in 2 dimensions, $ \mathbb{ R} ^{ 1, 1 } $, 
the metric $ ds ^ 2 = - d t ^ 2 + dx ^ 2 $ (the standard metric). 
We'll do two successive coordinate transformations. 
We introduce lightcone coordinates  $ u  = t  -x $, 
and $ v = t + x $. It's simple to see that 
in these coordinates, 
\[
 ds ^ 2 =  - du dv
\] We have to be very careful about the range in which coordinates move. 
We have that $ u , v \in ( - \infty  , \infty ) $, 
since $ t , x  $  are in the same range. 
Now, the idea is to come up with a second coordinate transform which 
takes infinity to a finite number. We can choose any function we 
like which has an infinite range in an finite domain. 
The simplest and most obvious choice we 
can make is to use the $ \tan $ function. 
We can now map this to a finite range, 
\[
 u = \tan \tilde{ u } , \quad v = \tan \tilde{ v }   
\] The upshot of this 
is that now the 
range of our variables $  \tilde{u }  $ , $ \tilde{ v }  $
is now finite, with $ \tilde{u}   , \tilde{v;w}  \in ( - \frac{ \pi }{ 2 } , \frac{\pi}{ 2 } ) $. 
With differentiation of one forms, we have that for the $ u $ 
coordinate for example, that 
\[
 du = \sec ^2 \tilde{ u } d  \tilde{ u }  
\] 
In these coordinates, the metric is 
\[
 ds ^  2 =  -\frac{1}{\cos ^ 2 \tilde{ u } \cos ^ 2 \tilde{ v}   } d \tilde{ u } d \tilde{ v }   
\] Our form for the metric now is promising, 
because we have something of the form $ \Omega^ 2 du dv $, 
which means we have cooked up something conformally equivalent to 
our lightcone coordinates in the first place, but has 
a finite range!
Now we do a conformal map to get rid of this scaling factor 
by simply multiplying it by the reciprocal. 
Consider the metric 
\[
 d \tilde{ s } ^ 2 = \cos ^ 2 \tilde{ u } \cos ^ 2 \tilde{v } ds ^ 2  = - d \tilde{ u } d \tilde{ v }      
\] Thus, 
we get something that looks like 
the Minkowski metric but now has a limited range. 
We write this range to include the closure of the set (which acts as infinity) 
so that $ \tilde{ u } , \tilde{ v } \in [ - \frac{\pi}{2 } , + \frac{\pi}{2 } ]   $. 
Adding the points $ \pm \frac{\pi}{ 2 } $ that used to be 
$ \pm \infty$ is called conformal compactification.

We'll now try to draw a pictorial 
representation of this spacetime. 
The rule of thumb in general relativity is that light-cone 
coordinates should be drawn at $ 45 $ degrees. 
We make no exception in Penrose diagrams, so we 
draw the coordinates in a diamond shape in the range $ ( - \frac{\pi}{2 } , \frac{\pi}{2 } ) $. 
In this set of coordinates, time is vertical. 
\begin{figure}[h]
	\centering
	\input{penrose-2.pdf_tex}
	\caption{A Penrose diagram of conformally compactified 
	Minkowski spacetime in two dimensions}%
	\label{fig:}
\end{figure}

This is the Penrose diagram. Don't
trust distances on these diagrams, but trust the causal structure. 
What's the form of a general geodesic in this space? 
We derive the geodesic from the Lagrangian
\[
 \mathcal{ L }  = - \dot{ t } ^ 2 + \dot{ x } ^ 2  
\] Then, we solve the geodesic equations 
to get the timelike geodesics 
\[
	x ^ \mu ( \tau ) = \left(  K \tau + A , \pm \sqrt{ K ^ 2 - 1 }  \tau  + B \right) 
\] Now, when we substitute this 
into our new lightcone coordinates, 
we find that all geodesics, in terms of the coordinates 
$ ( \tilde{ u }, \tilde{ v  } )   $, tend to $ ( \frac{\pi}{2 } , \frac{\pi}{2 } )$
if we go far enough into the future. Similarly, we get to 
$ (  - \frac{\pi}{2 } , -\frac{\pi}{ 2 } ) $ if we 
go far enough into the past.  

We can draw various geodesics on this diagram, 
in particular timelike geodesics with constant $ x $, 
and spacelike geodesics and with constant $  t$  
(of course, there are other geodesics but these are the ones well draw in
figure \ref{fig:p_2}. 
These are geodesics in our \textbf{original } choice 
of metric.

All timelike geodesics start at the point $ \peninf ^ -  , [ - \frac{\pi}{2 } , - \frac{\pi}{2  }] $, 
and end at $ \peninf ^ + , [ \frac{\pi}{2 } , \frac{\pi}{ 2   }]$. These are
called past / future timelike infinity. 
Meanwhile, all spacelike geodesics 
start and end at two points $ \peninf ^ 0  , [ - \frac{\pi}{2 }, + \frac{\pi}{2 } ] $ or 
$ [ + \frac{\pi}{2 } , - \frac{\pi}{ 2 } ] $. These are called spacelike 
infinity. 

\begin{figure}[h]
	\centering
	\input{penrose-3.pdf_tex}
	\caption{The Penrose diagram of two dimensional Minkowski 
	space with some geodesics drawn on}
	\label{fig:p_2}
\end{figure}

All null curves start at $ \scri ^ - $ "scri-minus" and end at $ \scri ^ + $ "scri-plus".
These null curves would be represented by diagonal lines on the Penrose diagram. 
These all called past and future null infinity.

There are some things we can read off
from a Penrose diagram. They tell us 
basic things about the spacetime.
For example, any two points on the spacetime 
have a common future and a common past. 

\subsubsection{4 dimensional Minkowski space} 
Let's now do the same thing 
for $ \mathbb{ R} ^{ 1, 3 } $.
We follow the same routine - get a metric, 
and wrangle it into a form which is finite so we 
can start drawing diagrams. 
We do something similar. 
The metric is best written in 
polar coordinates 
\[
 ds ^ 2 = - dt ^ 2 + d r ^ 2 + r ^ 2 d \Omega^ 2 _ 2 
\] We, as before, 
do a change of coordinates into light-cone 
coordinates (but in $ t $ and $ r $ ) so that 
\begin{align*}
	u &=  t - r = \tan \tilde{ u }   \\
	v &=  t + r  =  \tan \tilde{ v } 
\end{align*}
After switching to these light-cone coordinates, 
we then do the same coordinate transform $ u  = \tan \tilde{ u } , 
v  = \tan \tilde{ v }  $ to make our range finite. 
We get that  
\begin{align*}
	ds ^ 2 &=  - d u dv + \frac{1}{4 } ( u - v ) ^ 2 d \Omega_ 2 ^ 2  \\
	       &=  \frac{1}{4 \cos^ 2 \tilde{ u } \cos ^ 2 \tilde{ v }   } \left(  
	       - 4 d \tilde{ u } d \tilde{ v } + \sin ^ 2 ( \tilde{ u } - \tilde{ v } ) d \Omega _ 2 ^ 2     \right)  \\
\end{align*}
The only tricky thing to verify here is the prefactor in front of 
our angular component of our metric. This can be
done however by just expanding out the $ \sin $ term with double 
angle formulae then dividing it. 
Finally, we then do a conformal transformation by multiplying this 
whole thing by $ \cos ^ 2 $
This is still 4 dimensional, so to present 
this in two dimensions something has to be removed, we ignore the spherical part. 
Unlike in Minkwoski space, we also require that $ r \geq 0 $ which implies that 
$ v \geq u $, which means that 
\[
  - \frac{\pi}{2 } \leq \tilde{ u } \leq \tilde{ v } \leq \frac{\pi}{2 }   
\] We hence drop the $ S ^ 2 $ and draw the Penrose diagram which 
appears to be sliced in two to reflect this condition. 

Note that the left hand line on the diagram 
is not a boundary of space time - it is 
merely where $ \tilde{ u }  = \tilde{ v } \implies r = 0   $, 
and $ S ^ 2$ shrinks to zero here. So, for a null geodesic 
like the path of a photon, when it hits this 
left hand boundary representing $ r = 0 $, it bounces back off 
in the other direction to head to  $\mathscr{J} ^ + $. 

\begin{figure}[h]
	\centering
	\input{penrose-5.pdf_tex}
	\caption{The Penrose diagram of two dimensional Minkowski 
	space with some geodesics drawn on}
	\label{fig:p_2}
\end{figure}

\subsubsection{de Sitter} 
In global coordinates, de Sitter space 
is represented by 
\[
 ds ^ 2 = - d \tau ^ 2 + R ^ 2 \cosh ^ 2 \left(  \frac{ \tau }{ R }  \right)  d \Omega_ 3 ^ 2 
\] We introduce conformal time, 
which makes the metric have a factor which sits out front.
Conformal time is given by 
\[
	\frac{ d \eta }{ d \tau }  = \frac{1}{ R \cosh \left(  \tau / R  \right)  } 
	\implies \cos \eta = \frac{1}{\cosh \left(  \tau /  R  \right) }
\] where $ \eta \in ( - \frac{\pi}{2 } , \frac{\pi}{2 } ) $. 
Plugging this in, 
we get the following metric 
\[
	ds ^ 2= \frac{R ^ 2 }{ \cos^ 2 \eta } \left(  
	 - d \eta ^ 2 + d \Omega_ 3 ^ 2 \right)  
\] We write out the 3 sphere metric as $ d \chi ^ 2  + \sin ^ 2 \chi d \Omega _ 2 ^2 $. 
de Sitter is conformal to 
\[
 ds ^ 2 = - d \eta ^ 2 + d \chi ^ 2 + \sin ^ 2 \chi  d \Omega_2 ^ 2 
\] Now we can draw our Penrose diagram. 

We see that the boundary of de Sitter 
is spacelike. 
No matter how long you wait, you cannot 
see the whole space, nor can you influence 
the whole space. This is given by a diagonal line. 
We can check that the static patch coordinates map to 
the intersection of the event horizon and the particle horizon.

\pagebreak 
\section{Coupling to matter} 
In this section, we'll be looking at how 
matter 'backreacts' with the metric. Matter itself 
changes the dynamics of our physical system.

We'll start simple and consider fields first. 
With a field in space-time, like we do in quantum field theory, 
we associate an action to the field. This action 
as a kinetic part, and a potential. 
We first consider the scalar field 
\[
	S = \int d ^ 4 x \left(  - \eta ^{ \mu \nu } \partial  _ \mu \phi \partial  _ \nu \eta 
	+ V ( \phi ) \right)   
\] We call this thing a matter 
field because it dictates the dynamics of matter. 
In this case we're in Minkowski space-time. 
Now, the natural way to generalise this would be $ \eta $ with 
our new metric $ g $ (which may depend on our position on the manifold now), 
and also include our canonical measure $ \sqrt{ - g }  $ in the integrand. 
In addition, to make sure we're dealing with manifestly tensorial 
objects, we should change our partial derivatives 
to covariant derivatives. 

In the end, we get a form for the scalar field which 
is 
\[
 S_{\text{scalar } }  = \int d ^4 x \, \sqrt{  - g }  
 \left(  - g^{ \mu \nu } \nabla _ \mu \phi \nabla _ \nu \phi  + V ( \phi )  \right) 
\]
The fact that we're now not just considering 
the Minkowski metric means that we can 
include things in this matter field which might  
depend on the metric. For example, we may decide 
to include the effect of the Ricci scalar in our action. 



\subsection{Energy Conservation} 
In this section, we'll talk about 
the subtleties of current, energy and 
momentum conservation in curved space-time. 
What we'll see is that while everything is fine 
and dandy in flat space-time, there's something 
that goes wrong when we try to construct conserved charges 
that come from the covariantly conserved energy-momentum 
tensor in curved space-time. Loosely speaking, 
\[
\nabla _ \mu T ^{ \mu \nu }  =0 \text{ does not imply a conserved }  P ^ \mu
\] 
In flat space, we have the familiar currents and 
energy momentum tensor which obey 
\[
\partial _ \mu J ^ \mu  =0 , \quad \partial  _ \mu T ^{ \mu \nu }  = 0
\] Now, our conserved current 
could come from say, the symmetry of a phase rotation 
in a complex scalar field (using Noether's theorem). 
We already know that in quantum field theory 
our energy momentum tensor comes from symmetries of 
translating space-time.

From these conservation 
laws, we can extrapolate conserved charges. 
These conserved objects are obtained by 
integrating the first around some spatial region 
which we call $ \Sigma $. $ \Sigma $ is like 
some slice of space in space-time which 
we usually take to be quite large. 
\[
Q ( \Sigma )  = \int _{ \Sigma } d ^ 3 x \, J ^ 0, \text{ and } P ^ \mu ( \Sigma )  = \int _{ \Sigma } d ^ 3 x T ^{ 0 \mu } 
\] Now, what exactly are the objects $ Q $ and $ P $? 
Well, we know that $ J ^ 0 $ is a number, so $ Q ( \Sigma ) $ must 
be a number. Now, what is it a function of? Since we integrating out the spatial degrees of freedom 
of $ J ^ 0 $, it's a function of time. Hence, we have that 
\[
Q ( \Sigma ) : \mathbb{ R} \to \mathbb{ C }, \text{ for any } \Sigma 
\] where $ \Sigma $ is some spatial slice in flat space-time. 
In addition, we have that $ P ^ \mu $ is also just a function 
\begin{claim}
Provided that now current flows out 
of our space-time cylinder, the quantity $ Q ( \Sigma ) $ is conserved. 
Specifically, we have that between two points in time, 
say $ t_1 $ and $ t_2 $, we require that the 
change in $ Q ( \Sigma ) $ between these two points remain 
the same. 
To understand conservation here, we need to bound this in a region 
of space-time. What we do is that we smear 
our spatial region across cylinder in space-time, then 
assert that no current flows in or out of this cylinder.

\begin{proof}
	We first need to define the 
	volume which we're integrating 
	the conserved current over. 
	In this case, we take a cylinder through space-time.

	\begin{figure}[h]
		\centering
		\input{sp-cylinder.pdf_tex}
		\caption{Here our volume in four space is just a cylinder.}
		\label{fig:sp-spacetime}
	\end{figure}
	From our conservation law, we assert that $ \partial _\mu J ^ \mu = 0 $
	here. This means that our integral over the whole volume is zero. 
	Thus, 
	\begin{align*}
		 0 &=  \int d ^ 4 x \, \partial  _ \mu J ^ \mu   \\
		 &=  \int _{ t _ 1  }^{ t_2 } dt \, \int_{ \Sigma } d ^ 3 x \, \partial  _ t 
		 J ^ 0 + \int _ B d ^ 3 x \, \partial  _ i J ^ i \\
		 &=  \int _{ t_1 } ^{ t_2 } dt \, \partial  _ t \left( 
		 \int _{ \Sigma } d ^ 3 x J ^ 0  \right)  + \int _{ B } d ^ 3 x \partial  _ i J ^ i  \\
		 &=  [Q ( \Sigma ) ]( t_2 ) - \left[  Q ( \Sigma )  \right]( t_1 ) 
		  + \int_{ B } d ^ 3 x \partial  _ i J ^ i  
	\end{align*}
	We recognize the expression in brackets in the first term as 
	the definition $ Q $. 
	We denote $ B $ as the boundary of this space-time cylinder. 
	Note that this boundary is time-like (although it's not entirely clear 
	why this is important right now). 
	Now, crucially, we impose the condition that on the boundary $ B $, 
	we have that the current vanishes, so $ J ^ i  =0 $. 
	This then enforces charge conservation.

	We can play this same game with the conserved charge 
	$ P ^ \mu( \Sigma )   = \int_{ \Sigma} d ^ 3 x T^{ 0 \mu }  $. 
	We recognise that from the conservation law that 
	$ \partial  _ \nu  T ^{ \nu \mu } = 0 $.
	As before, just integrate over 4 space in the 
	required region. 
	\[
	  0 &=  \int dt \int d ^ 3 x \partial  _ 0 T ^{ 0 \mu }  + \int _ B 
	  d ^ 3 x \, \partial  _ i T ^{ i \mu } \\
	    &=  P ^ \mu ( \Sigma ) ( t_2 ) - P ^ \mu ( \Sigma ) ( t_1 )  + 0  \\
	\] Here, we imposed the condition that 
	$ T ^{ i \mu } $ is zero on $ B $. This does the trick, and 
	we have yet another conserved charge. 
\end{proof}
\end{claim}

This was all well and good in flat space time,
but we want to generalise this to 
see how things work in curved spacetime. 
We have that instead, our quantities of 
interest obey covariant conservation laws. 
\[
\nabla _ \mu J ^ \mu  =0 , \quad \nabla _ \mu T ^{ \mu \nu }  =0 
\] In this case, we 
can safely say that the charge associated with 
the conserved current $ J ^ \mu $ is conserved.
This can be shown by recalling the divergence theorem 
for curved space-time with $ n  = 4  $.  
We have that 
\[
0  = \int_{ V } d ^ 4  x \sqrt{ - g }  \nabla _ \mu J ^ \mu  = \int _{ \partial  V } 
d ^ 3  x \sqrt{  | \gamma | }  n _ \mu J ^ \mu 
\] In this case, we take 
our closed volume $ V $ to be the space-time enclosed in the
cylinder with boundary 
\[
\partial  V  = \Sigma _ 1 \cup \Sigma _ 2 \cup B 
\] We have to be a little bit more 
careful here. In particular, 
we need to define two different 
surfaces $ \Sigma _ 1 $ and $ \Sigma _ 2 $ 
since there's no canonical way to 
map our these surfaces throughout time. 
\begin{figure}[h]
\centering
\input{sp-cylinder-2.pdf_tex}
\caption{We now deal with the case when we have curved space-time}%
\label{fig:}
\end{figure}
Now, the trick here is to partition this boundary integral up 
into the slices
\[
0  = \int _{ \Sigma_ 1 } d ^ 3 x \, \sqrt{ | \gamma | }  n _ \mu J ^ \mu + 
\int _{ \Sigma_ 2 } d ^ 3 x \, \sqrt{ | \gamma | }  n_ \mu J ^ \mu + 
\int _ B d ^ 3 x \, \sqrt{ | \gamma | }  n _ \mu J ^ \mu 
\] Again, if we impose that on the boundary, we 
have that $ J ^ \mu  = 0 $, then we recover 
charge conservation.
We then have 
charge conservation 
\[
Q ( \Sigma _ 1) = Q ( \Sigma _ 2 ) 
\] where $ Q $ is defined analogously as before, 
where we have $ Q ( \Sigma )  = \int _{ \Sigma } d ^ 3 x \, \sqrt{ | \gamma | }  n _\mu J ^ \mu  $. 

\subsubsection{A foray into conservation in Electromagnetism} 
\begin{example}{(Charge conservation in electromagnetism)}
Let's look at the case of conserved 
quantities in electromagnetism. 
The first thing we start with is the electromagnetic 
tensor $ F $, which is a two-form. 
If we want to create an action to integrate over this, 
the most natural thing we can 
do is to wedge product these two things together 
to get a four form, which we can integrate in four dimensional 
space.

Our resulting action then looks like 
\[
S_{ \text{ top} }  =   - \frac{1}{2 } \int F \wedge F 
\] How do we make sense 
of this object in terms of physical fields which 
we observe? In components, this is 
\[
\frac{1}{2 } \left( \frac{1}{4 }  \right)  
\int F _{ \mu \nu} F_{ \alpha \beta } \,  dx^ \mu \wedge  dx ^ \nu \wedge  dx ^ \alpha \wedge  dx ^ \beta  
\] Now, which terms in this expansion survive? 
Since we're anti-symmetrising over all of the indices $ \mu, \nu , \alpha , \beta $ 
this means that any terms in which $ F _{ \mu \nu } F _{ \alpha \beta } $ 
contain common values like $ F _{ 01 } F _{ 0 1 } $ go to zero. 
So, we have to consider terms that are like $ F _{ 01 } F _{ 23 } $ 
and permutations of these. 
It's not hard to convince yourself that, adding all of these permutations
together cancels our prefactor of $ \frac{1}{8 } $ and we have that 
\[
S_{ \text{ top }  }  = \int F \wedge  F  = \int dx ^ 1 dx ^ 2 dx ^ 3 dx ^ 4 \vec{E} \cdot  \vec{B}
\]
Now, to incorporate this with what we know 
about GR, we can try couple this 
action with a metric by placing in the Hodge star. 
This gives us something slightly different 
\[
S_{ \text{...} }  = \int F \wedge  \star F  
\] We can also try to compute this object explicitly. 
(We'll finish this another time)
\end{example}

Now, something goes wrong when we 
try to compute the associated charge from 
the covariant conservation law $ \nabla _ \mu T ^{ \mu \nu }  = 0$. 
Integrating over 4-space, we have that 
\[
0 = \int _ V d ^ 4 x \, \nabla _ \mu T ^{ \mu \nu } 
\] Now, is there a way to turn this integral 
into a surface term which we can take to zero?
For the divergence theorem, we could have written 
$ \nabla _ \mu J ^ \mu $ as a total integral. 
This is achieved by writing 
\[
\nabla _ \mu J ^ \mu  = \partial  _ \mu J ^ \mu + \Gamma^ \mu _{ \mu \rho } J ^ \rho 
\] as a total integral. 
Recall, this can be done 

The same argument does not work 
for $ T ^{ \mu \nu } $. Now we have 
\[
0 = \int _ V  d^ 4 x \, \nabla _ \mu T ^{ \mu \nu }  
\] Now, we have a bit of an issue here. 
There's a hanging index $ \nu $, so 
we can't apply our usual divergence theorem. 
In fact, there is no divergence theorem for this! 
Instead, we have 
\[
\sqrt{ - g } \nabla _ \mu T ^{ \mu \nu }  =0 \iff 
\partial  _ \mu \left( \sqrt{ - g }  T ^{ \mu \nu }  \right)   = 
- \sqrt{ -g } \Gamma ^ \nu _{ \mu \rho } T ^{ \mu \rho }  
\] This comes from two occurences of the Christoffel 
symbols given by doing the covariant derivatives on $ T ^{ \mu \nu } $. This looks like a 
driving force, which roughly speaking means 
that $ T ^{ 0 \mu } $ is not  conserved. 
This extra term can be viewed as 
energy seeping into the gravitational field 
itself, since matter backreacts with our field!

Suppose our spacetime has a Killing vector $ K $. 
Define 
\[
J _ T ^\mu  = K _ \nu T ^{ \mu \nu   } 
\]  Now, this 
quantity is conserved as well! So, 
by the Killing equation and covariant 
conservation, we have that 
\[
\nabla _ \mu J _ T ^ \mu  = \left( \nabla _ \mu K _ \nu  \right)  T ^{ \mu \nu } 
+ k _ \nu \nabla _ \mu T ^{ \mu \nu }  = 0 
\] Now, we can repeat the same steps which we did before, 
and define the conserved charge 
\[
Q _ T ( \Sigma ) = \int _{ \Sigma } d ^ 3 x \, \sqrt{ | \gamma | }  n_ \mu J ^ \mu _ T 
\] We have multiple interpretations 
of this. 
If $ g _{ \mu \nu } k ^ \mu k ^ \nu < 0  $ in other words timelike, 
this can be interpreted as energy. 
What if there isn't a Killing vector 
is space-time? 
Can we make sense of the total energy which 
is possessed by both by the matter field and the gravitational 
field? 
The short answer : no.  
There is no diffeomorphism invariant local energy density 
for the gravitational field. 
This is statement we can prove! However, 
we should stop here since these types of things 
are unphysical as non-diffeomorphism 
invariant things are unphysical.
There is however, one statement we can make. 
Precise statements can only be made asymptotically. 
For example, $ \mathscr{J } ^ + $  in Minkowski space.
This is called the Bondi energy. 
We want conserved energy since it allows us to solve equations!

\pagebreak 
\section{When Gravity is weak} 
We will solve the Einstein equations 
perturbatively, working in what 
we call 'almost inertial coordinates'.
Almost inertial coordinates are coordinates which 
look like Minkowski space, but adding a small term 
$ h_{ \mu \nu }  $ on the end which we assume to be small
\[
g _{ \mu \nu } = \eta _{ \mu \nu } + h _{ \mu \nu } \text{ with } h _{ \mu \nu } \ll 1 
\]
Adding a small field onto Minkowski space 
like this has an important interpretation  - 
we're now thinking of gravity as a field $ h _{ \mu \nu } $ 
that acts on the stage of Minkowski space. 
In particular, 
we think of gravity as a spin 2 field $ \eta_{ \mu \nu } $ 
field $ h _{ \mu \nu } $ propagating in Minkowski 
space. I won't go into the details of why $ h _{ \mu \nu }  $ 
is thought of as a spin $ 2 $  field. 

In particular, since we're considering Minkowski space as
the main metric here, we will raise and lower indices 
using $\eta _{ \mu \nu }  $ rather than $ g _{ \mu \nu } $. 
For example, we have that when we apply the Minkowksi metric 
twice to raise the indices on $ h _{ \mu \nu } $, we get 
\[
h ^{ \mu \nu }  = \eta ^{ \mu \rho } \eta ^{ \nu \sigma  } h _{ \rho \sigma } 
\] 
Just as in normal field theory, we would hope 
that the field $ h _{ \mu \nu } $ would be invariant 
under some transformations. In particular, we 
impose the condition that the theory that is Lorentz invariant 
under transformations $ x ^ \mu \to \Lambda \indices{^ \mu _ \nu } x ^ \nu  $, 
and 
\[
h ^ \mu \nu  = \Lambda \indices{ ^ \mu _ \rho } \Lambda \indices{ ^ \nu _ \sigma } h^{ \rho \sigma }  ( \Lambda^{ -1  } x ) 
\]  

\subsection{Linearised theory} 
We work to leading order on $ h _{ \mu \nu } $. 
We have that the inverse metric is 
given by perturbating by the negative, so we have that 
\[
g ^{ \mu \nu } = \eta ^{ \mu \nu }  - h ^{ \mu\nu } 
\] We can find that this is indeed the 
correct inverse. Just verify that $ g^{ \mu \rho  } g_{ \rho \nu }  = \delta \indices{ ^ \mu _ \nu }  $: 
\begin{align*}
g^{ \mu \rho } g_{ \rho \nu } &=  \left( \eta ^{ \mu \rho }  - h ^{ \mu \rho }  \right)  \left( 
\eta _{ \rho \nu } + h _{ \rho \nu } \right)   \\ 
			      &=  \eta ^{ \mu \rho } \eta _{ \rho \nu }  - h ^{ \mu \rho } \eta _{ \rho \nu } + h _{ \rho \nu } \eta ^{ \mu \rho } + O ( h ^ 2 )  \\
			      &=  \delta \indices{ ^ \mu _ \nu }  - h \indices{ ^ \mu _ \nu } + h \indices{ ^ \mu _ \nu } + O ( h ^ 2 ) \\
			      &=  \delta \indices{ ^ \mu _ \nu } + O ( h ^ 2)  
\end{align*}
Be aware that when we're saying 'inverse', we actually 
mean 'inverse to first order in $ h $' in linearised theory.  
From this, we can compute the Christoffel components
as well, to first order in $ h$. 

\begin{defn}{(Christoffel components in linearised theory)}
\[ \Gamma ^ \sigma _{ \nu \rho } = \frac{1}{2 } \eta ^{ \sigma \lambda } \left( 
\partial  _ \nu h _{ \lambda \rho } + \partial  _ \rho h _{ \nu \lambda }  - \partial  _ \lambda h _{ \nu \rho } \right)   \]
\end{defn}
We can calculate our Riemann 
tensor as well in linearised theory.
Schematically, we have that $ R \sim \partial  \Gamma - \partial  \Gamma + \Gamma \Gamma  - \Gamma \Gamma$ .
Now, since we've shown in the above that $ \Gamma $ is 
a $ h $ term, we know that $ \Gamma \Gamma \sim O ( h ^ 2 ) $, 
so we can ignore these terms. 
If we calculate just the derivative terms 
in linearised theory, we then get 
\begin{align*}
R \indices{ ^ \sigma _{ \rho \mu \nu } }  &=  \partial  _ \mu \Gamma^ \sigma _{ \nu \rho } 
 - \partial  _ \nu \Gamma ^ \sigma _{ \mu \rho } + \Gamma ^ \lambda _{ \nu \rho } \Gamma ^ \sigma _{ \mu \lambda } 
 - \Gamma ^ \lambda _{ \mu \rho } \Gamma ^ \sigma _{ \nu \lambda } \\
					  & \simeq \partial _ \mu \Gamma^\sigma_{ \nu \rho } 
					   - \partial  _ \nu \Gamma ^ \sigma _{ \mu \rho } \\
					  &=  \frac{1}{2 } \eta ^{ \sigma \lambda } \left( 
					  \partial  _ \mu \partial  _ \sigma h _{ \nu \lambda } 
				  - \partial _ \mu \partial _ \lambda 
			  h _{ \nu \rho } - \partial  _ \nu 
		  \partial  _ \rho h _{ \mu \lambda } + \partial  _ \nu 
	  \partial  _ \lambda h _{ \mu \rho } \right)   
\end{align*}
When we contract our indices to get the Ricci tensor, 
we get that 
\begin{align*}
R_{ \mu \nu }  &= \frac{1}{2} ( \partial  ^ \rho \partial  _ \mu h _{ \nu \rho } + \partial  ^ \rho \partial  _ \nu 
h _{ \mu \rho }  - \Box h _{ \mu \nu } - \partial  _ \mu \partial _ \nu h ) \\
R &=  \partial  ^ \mu \partial  ^ \nu h _{ \mu \nu }  - \Box h  
\end{align*}
where we've define the Laplacian operator 
$ \Box = \partial  _ \mu \partial  ^ \mu $.
Also, we have that  $ h = h \indices{_ \mu ^ \mu }   = \eta ^{ \mu \nu } h _{ \mu \nu } $. 
Finally, we have that our Einstein-Tensor given by $ G _{ \mu \nu } = R_{ \mu \nu  }  -\frac{1}{2 } g_{ \mu \nu } R $. This can also be expanded linearly in terms of the above. 
Just substitute in our expressions for $ R _{ \mu \nu } $ and $ R$ and 
you'll find that 
\[
G _{ \mu \nu } = \frac{1}{2 } \left[  \partial  ^ \rho \partial  _ \mu h _{ \nu \rho } 
+ \partial  ^ \rho \partial  _ \nu h _{ \mu \rho }  - \box h _{ \mu \nu } 
- \partial  _ \mu \partial  _ \nu h  - \left( \partial  ^ \rho 
\partial  ^ \sigma h _{ \rho \sigma }  - \box h \right)  h _{ \mu \nu } \right]  
\] Like the other expressions, we 
find that the Einstein tensor is 
a term in $ h $. Because the Einstein tensor obeys the 
Bianchi identity 
\[
 \nabla ^ \mu G _{ \mu \nu } =  0
\] since $ G _{ \mu \nu } $ is a term 
proportional to $ h $ and its derivatives, we can 
forget about the extra Christoffel symbol here. 
This means we only need to include the first partial derivative, 
and he that that $ G _{ \mu \nu }$ obeys the linearised Bianchi identity $ \partial  _ \mu G ^{ \mu \nu }  =0  $. 

\subsubsection{The Fierz-Pauli Action}
To look at symmetries, we can reformulate 
the above in terms of action principles. 
The Einstein equation $ G _{ \mu \nu }  = 8 \pi G T _{ \mu \nu } $ follows from 
\begin{align*}
	S_{ FP  } = \int d ^ 4 x \frac{1}{ 8 \pi G } \left[ 
	 - \frac{1}{4 } \partial  _ \rho h _{ \mu \nu } \partial  ^ \rho h ^{ \mu \nu } + 
 \frac{1}{2 } \partial  _ \rho h _{ \mu \nu } \partial  ^ \nu h ^{ \rho \mu } 
 + \frac{1}{4 } \partial  _ \mu h \partial  ^ \mu h  - \frac{1}{2 } \partial  _ \nu h ^{ \mu \nu } \partial  _ \mu h \right]  
 + h _{ \mu \nu } T ^{ \mu \nu } 
\end{align*}
This arises from $ S _{ EH } $ by expanding to order $ h ^ 2 $. 
We can vary this action first without including the matter 
term to get the vacuum equations. 
Varying the action, we find that relabelling 
indices and integrating by parts. Our variation is given 
first by
\begin{align*}
	\delta S_{FP}  = \frac{1}{ 8 \pi G } \int d ^ 4 x \, 
	[  - \frac{1}{2 } \partial  _ \rho h _{ \mu \nu } 
		\partial  ^ \rho \delta h _{ \mu \nu }  & + \frac{1}{2 } \partial  _ \rho h _{ \mu \nu } \partial  ^ \nu \left( \delta h ^{ \rho \mu }  \right)  
	+   \frac{1}{2 }  \partial  _ \rho \delta h _{ \mu \nu } \partial  ^ \nu h ^{ \rho \mu }+ \\ 
	   & \frac{1}{2 } \partial  _ \mu \left( \delta h  \right)  \partial  ^ \mu h 
 - \frac{1}{2 } \partial  _ \nu \delta h ^{ \mu \nu } \partial  _ \mu h - \frac{1}{2 } \partial  _ \nu h ^{ \mu \nu } \partial  _ \mu \delta h ] 
\end{align*}
Now, the trick here is to expand $ h $ to first order so that 
$ h  = h ^{ \mu \nu } \eta _{ \mu \nu } $.
Varying $ h $ gives $ \delta h  = \eta _{ \mu \nu } \delta h ^{ \mu \nu } $. 
Relabelling the indices and integrating by parts 
gives 
\begin{align*}
	\delta S _{ FP } = \frac{1}{ 8 \pi G } \int d ^ 4 x \, 
	\frac{1}{2 } \left( \partial  ^ \rho \partial  _ \rho h _{ \mu \nu }  \right)
	\delta h^{ \mu \nu } & + \frac{1}{2 } \partial  _ \nu 
	h _{ \mu \rho } \partial  ^ \rho \left( \delta h ^{ \mu \nu }  \right) 
	+ \frac{1}{2 } \partial  ^ \rho \left( \delta h ^{ \mu \nu }  \right) 
	\partial  _ \nu h _{ \rho \mu } + \\ \frac{1}{2 } 
	\partial  _ \rho \left( \delta h ^{ \mu \nu }   \right)  \eta _{ \nu \mu } 
	\delta ^ \rho h - \frac{1}{2 } \partial  _ \nu \delta h^{ \mu \nu } \partial  _ \mu h - \frac{1}{2 } \partial  _ \rho h ^{ \sigma \rho } \partial  _ \sigma \delta h ^{ \mu \nu } \eta _{ \mu \nu } 
\end{align*}
After simplifying this even further, 
we can factor out the Einstein tensor in 
linearised theory from this action. 
This is given by 
\[
	\delta S _{ FP }  = \frac{1}{8 \pi G } 
	\int d^ 4 x \left[ \frac{1}{2 } \partial  _ \rho \partial  ^ \rho 
	h _{ \mu \nu }  - \partial  ^ \rho \partial  _ \nu h _{ \rho \mu } 
- \frac{1}{2 } \left( \partial  ^ \rho \partial  _ \rho h  \right)  \eta _{ \mu \nu } + \frac{1}{2 } \partial  _ \nu \partial  _ \mu h + \frac{1}{2 } \partial  _ \rho \partial  _ \sigma h ^{ \rho \sigma } \eta _{ \mu \nu }  \right]   
\] We recognize this 
however as the action 
\[
 \delta S_{ FP }  = \frac{1}{8 \pi G } \int d ^ 4 x \left[   - 
 G _{ \mu \nu } \delta h ^{ \mu \nu } \right] 
\] 

\subsubsection{Gauge Symmetries}
The action above has a lot of 
nice symmetries we can work with, 
in particular, gauge symmetries. 
Much like in electrodynamics, we 
can explore the kinds of transformations 
on our manifold which leave this action 
invariant. 

One transformation we can do 
is on the coordinates of the manifold. 
Under an infitesimal diffeomorphism $ x ^ \mu \mapsto x ^ \mu + \xi ^ \mu ( x) $, 
we induce a Lie derivative on the metric generated 
by the vector field $ \xi $. 
 \[
	 \delta g _{ \mu \nu }  = \left( \mathcal{ L } _ \xi g  \right)  _{ \mu \nu } 
	  = \nabla _ \mu \xi _ \xi + \nabla _ \nu \xi _ \mu 
\] We view this as a gauge transformation of $ h _{ \mu \nu } $ 
which, to leading order is 
\[
 h _{ \mu \nu } \to h _{ \mu \nu } + \partial  _ \mu \xi_ \nu + \partial  _ \nu \xi _ \mu 
\] Note that we only have partial 
derivatives here since we are assuming that 
not only $ h $, but $ \xi $ is also small 
and linear in $ h$. This means that 
the terms $ \sim \Gamma \xi $ are order $ h ^ 2 $, 
and we can ignore them. 

We can check that $ R \indices{ \mu _{ \rho \nu \sigma } }  $ 
and $ S _{ F P } $ are both invariant under gauge transformations. 
The first thing we're going to do to make life 
easy is to pick a gauge and use gauge symmetry. 
The sensible thing to do is to pick a symmetry called the de Dander gauge. 
This choice of gauge obeys 
\[
	\partial  ^ \mu h _{ \mu \nu }   -\frac{1}{2 } \partial _ \nu h = 0  
\]  The interesting thing is that this is analogous to 
the Lorentz gauge in electromagnetism. 
This is analogous to the Lorentz gauge $ \partial  _ \mu A ^ \mu = 0 $ in the equations 
of motion. 
An aside, in the full non-linear theory, the generalisation 
of the de-Donder gauge is something quite elegant! It's
the condition that 
\[
 g ^{ \mu \nu } \Gamma ^ \rho _{ \mu \nu }  = 0
\]  This is not  atensor eqaution. This is ok - this is a gauge 
choice and this is coorddinate depenedent. We also 
have four equations to solve  - and this recovers our linearised 
gauge which we presented earlier. 

In de-Donder gauge, the linearised Einstein equations become 
\[
 \box h _{ \mu \nu }  - \frac{1}{2 } h _{ \mu \nu } \box h  = - 16 \pi G T _{ \mu \nu } 
\]
Given this gauge, we're now in a nice position 
to define a new object which we call 
\[
 \overline{ h } _{ \mu \nu }  = h _{ \mu \nu }  - \frac{1}{2 } \eta _{ \mu \nu } h  
\] This is easy to invert.
We have that $ \overline{ h }  = \eta _{ \mu \nu } \overline{ h } ^{ \mu \nu }  =  -h $. 
And so, our inverse expressing $ h $ in terms of $ \overline{ h } $. 
$  \overline{ h}  $ is easy to solve! Our equation 
is just given by 
\[
 \box \overline{ h } _{ \mu \nu }  = - 16 \pi G T _{ \mu \nu }
\] 

\subsection{The Newtonian Limit} 
Consider stationary matter with $ T _{ 0 0 }  = \rho ( \vec{x} )  $.
This doesn't change in time. Thus, we can just write 
the wave operator 
\[
 \box  =  - \partial  _ t ^ 2 + \nabla ^ 2 
\] and we look for solutions with $ \frac{\partial  }{ \partial  t }  = 0 $. 
Thus, the equation's 
we're trying to solve just look like 
\[
	\nabla ^ 2 \overline{ h } _{00 }  = - 16 \pi G \rho ( \vec{x} ) , \text{ and } \nabla ^ 2 
	\overline{ h } _{ 0i }  = \nabla ^ 2 \overline{ h } _{ ij }  = 0
\]  One of 
our familir solutions to this 
is just the Newtonian gravitational potential! 
These has the solution $ \overline{ h } _{0i }  = \overline{ h } _{ ij }  =0 $. 
And, we have that $ \overline{ h } _{ 00  }  = - 4 \Phi $. 
Where, we have that $ \Phi  $ is the Newtonian gravitational potential
\[
	\nabla ^ 2 \Phi   = 4 \pi G \rho ( \vec{x} ) 
\] This looks a lot like Maxwell's. This is because 
our extra $ \nu $  index enforces gauge symmetry. 
What does this do at a classical level? 
Gauge symmetry allows us to have evolution without ambiguity. 
So we have that this thing gives $ h _{ 0 0  } =  -  2 \Phi  $, 
and that $ h _{ ij }  = - 2 \Phi  \delta_{ij }  , h _{ 0i }  = 0$. 
This means that 
we have our solution for a metric 
\[
	ds ^ 2  = - ( 1 + 2 \Phi  ) dt ^ 2 + ( 1 - 2 \Phi  ) d \vec{x} ^ 2 
\] This is the metric for a Newtonian gravitational 
potential. 
Now, suppose that our point mass $ M $ 
has the gravitational potential, 
\[
 \Phi   =   - \frac{GM}{r } 
\] The metric then agrees with the Taylor 
expansion of the Schwarzchild metric! 
By the way, there's 
a famous factor of $ 2 $ buried in this. 
We can argue in general grounds that 
what sits beside $ \Phi  $ needs to be a 2 
in fornt of $ d t ^ 2 $. But classically, 
we have no information about what we can say in front of 
$ d \vec{x} ^ 2 $. However, 
the Einstein equations predict the 
extra factor of  $  - 2 \Phi   $ in 
front of $ d \vec{x} ^ 2 $, which 
gives us the offset required to agree with experiment. 

\subsection{Gravitational Waves}
Gravitational waves are a big deal! 
From our Einstein momentum tensor, 
we have wave solutions in GR obeying the 
equation 
\[
 \box \overline{ h } _{ \mu \nu }  = 0
\] The solution is $ \overline{ h } _{ \mu \nu  }  = \Re \left( H _{ \mu \nu } e ^{ i \kappa _ \rho x ^ \rho }  \right)    $. 
Our matrix $ H _{ \mu \nu } $ is complex, symmetric and tells us our polarisation matrix. 
This object solves the wave equation providing 
$ k _ \mu k ^ \mu  = 0$. 
This tells us that gravitational waves travel at the speed of light. There's 
one thing we missed here. To derive the above equation, we 
had to make sure that we were in the 
de Donder gauge! Thus, we have to 
impose the condition that $ \partial  _ \mu \overline{ h  }^{ \mu \nu }  =0 $, 
provided that $ k ^ \mu H_{ \mu \nu }  = 0 $ !
In terms 
of electromagnetism this gives us restrictions 
on the polarisation of our wave. 
We can make further gauge transformations that leave us in 
the de Donder gauge. 
\[
 h _{ \mu \nu } \to h _{ \mu \nu } + \partial  _ \mu \xi _ \nu + \partial  _ \nu \xi _ \mu 
\] This means that 
\[
 \overline{ h } _{ \mu\nu } \to \overline{ h } _{ \mu \nu } + \partial  _ \mu \xi _ \nu _ \partial  _ \nu \xi _ \mu 
  - \partial  ^ \rho \xi _{ \rho } \eta _{ \mu \nu } 
\]  This leaves us in the de Donder gauge provided that 
\[
 \box \xi _ \mu  =0
\] We can take, for example, that $ \xi _ \mu  = \lambda _ \mu e ^{ i \kappa _ \rho x ^ \rho }$. 
This shifts the polarisation vector
$ H _{ \mu \nu } \to H _{ \mu \nu } + i \left( \kappa _ \mu \lambda _ \nu + k _ \nu \lambda _ \mu  - k ^ \rho \lambda _ \rho 
\eta _{ \mu \nu } \right)  $. 
We can choose $ \lambda _ \mu $ such that 
\[
 H _{ 0 \mu }  = 0 \text{ and } H ^\mu _ \mu = 0 
\] This is the transverse and traceless gauge. 
This has the advantage that $ \overline{ h } _{ \mu \nu }  = h _{ \mu \nu } $. 
Let's calculate the number of possible polarizations 
that we could get from this. 
We initially have a 4 by 4 symmetric matrix. 
Then, we imposed the de Donder gauge, then we have the residual 
gauge transformations. 
This means 
\[
 \text{number of polarizations }  = 10 - 4- 4 =2
\] This is cool because this 
is the number of polarizations of light. 
This is a coincidence that the number of 
polarizations of a graviton matches that of light. 
As an example, consider a wave in the z-direction. 
We choose the wave vector $ k ^ \mu = ( \omega, 0 , 0, \omega ) $. 
The de-Donder gauge tells us that 
\[
 k ^ \mu H _{ \mu \nu } = 0 \implies H _{ 0 \nu } + H _{ 3 \nu }  = 0
\] Then in the transverse and traceless gauge, we 
write that 
\[
	H_{ \mu \nu } = \begin{pmatrix}  0 & 0 & 0 & 0 \\
	0 & H _ + & H _{ X } & 0 \\
0 & H _ X & - H _ + & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix} 
\] We have some questions. How do we make gravitational waves 
in the first place? We'll cover that later. 
Another reasonable question to 
ask is how to measure gravitational waves? 

\subsection{Measuring gravitational waves} 
A single particle is not enough to detect the waves. 
We need to consider a family of particles, and 
in particular a family of geodesics. 
Consider the family of geodesics $ x ^ \mu \left( \tau , s  \right)  $
 where $ \tau $ is our affine parameter and $ s $ is 
 denotes geodesics. 
 We have that 
 \[
  \text{4 - velocity } u ^ \mu = \left. \frac{\partial  x ^ \mu}{\partial  \tau }  \right\vert_{ s } 
 \] and also our displacement across geodesics. 
 \[
  S ^ \mu  = \left. \frac{\partial  x ^ \mu }{\partial  s }  \right\vert_{ \tau } 
  \] We take particles in flat space $ u ^ \mu  = ( 1, 0 , 0 , 0) $. 
  We use the geodesic deviation equation
  \[
   \frac{d ^ 2 S }{ s \tau ^ 2  } = R \indices{ ^ \mu _{ \rho \sigma \nu } } u ^ \rho u ^ \sigma s ^ \nu  
  \]  We work to leading order in $ h $, and $ R $ is linear in $ h $. 
  Since we're working to linear order, 
  we leave $ u $ fixed. We also replace $ \tau $ with $ t $, 
  the coordinate time in Minkowski space since 
  the difference will be something of order $ h $ . 
  Thus, we have the equation 
  \[
   \frac{ d ^2 S ^ \mu }{d t ^  2  } = R \indices{ ^ \mu _{ 0 0 \nu } } S ^ \nu  
  \] Now, using our previous result for the linearised Riemann tensor, 
  we get that 
  \[
   \frac{d ^ 2 S ^ \mu }{ d t ^ 2 } = \frac{1}{2 } \frac{d ^ 2 h \indices{ ^ \mu _ \nu }  }{ dt ^ 2 } S ^ \nu 
  \] So now what happens? For a wave in
  the z direction, we see that from the form of $ H_{ \mu \nu } $ 
  is the components, we have that 
  \[
   \frac{ d ^ 2 S ^ 0 }{ d t ^ 2 } = \frac{d ^ 2 S ^ 3 }{  dt ^ 2 }  =0 
  \] So, all the action happens in the $ \left(  x, y  \right)  $ plane. 
  We'll focus on the place $ z = 0 $. 
We have two polarisations to look at. 

In the $ H _ +  $ polarisation, we set $ H _ X = 0 $, 
which implies that we have 
\begin{align*}
	\frac{ d ^ S ^  1}{ dt ^ 2 } &=   - \frac{\omega ^  2 }{ 2 } H _ + e ^{ i \omega t } S ^ 1  \\ 
	\frac{ d ^ 2  S ^ 2  }{ d t ^  2 } &=  \frac{ \omega ^  2}{ 2 } H _ + e ^{ i \omega t }  S^  2 \\ 
\end{align*}
The solution to this is 
\begin{align*}
	S ^ 1 ( t ) & = S ^ 1 ( 0 ) \left[  1 + \frac{1}{2 } H _ + e ^{ i \omega t } + \dots  \right] \\
	S ^ 2 (t ) &=  S ^ 2 ( 0 ) \left[  1 - \frac{1}{2 } H _ + e ^{ i \omega t }  \right]   \\ 
\end{align*} 
These are the geodesic equations. Taking the real part, 
we get that the circle is squished in and out as an ellipse. 
$ S ^ \mu $ is the displacment to neighbouring geodesics. 
When the move in at $ x ^ 1 $, the move out at $ x ^ 2 $. 

Now, we can play a similar game for  $ H _ X $ polarisation. 
We have that $ H _ +  = 0 $  implies 
\begin{align*}
	\frac{d ^ 2 S ^ 1 }{ dt ^ 2 } &=   - \frac{\omega ^ 2 }{ 2 } H_ X e ^{ i \omega t } S ^  2  \\ 
	\frac{ d ^  2 S ^ 2 }{ dt ^ 2 } &=   - \frac{\omega ^  2 }{ 2 } H _X e ^{ i \omega t } S ^  1  
\end{align*}
We now have the solutions 
\begin{align*}
	S ^ 1 ( t ) &=  S ^  1( 0 ) + \frac{1}{2 } S ^  2( 0 ) H _X e ^{ i \omega t } + \dots  \\ 
	S ^ 2 ( t ) &=  S ^  2 ( 0 ) + \frac{1}{2 } S ^ 1 ( 0 ) H _ X e ^{ i \omega t} + \dots  
\end{align*}
We define $ S _{ \pm }  = S ^ 1 \pm S ^ 2 $. It's the same 
as before, but rotated by $ 45 ^{ \circ } $!

Gravitational wave detectors have two perpendicular
arms. As a wave passes, the change in length is 
\[
	\mathcal{ L }  = \mathcal{ L } \left( 1 \pm \frac{H _ + }{ 2 }  \right)  \implies \frac{\delta \mathcal{ L } }{ 
	\mathcal{ L } }  = \frac{ H _ + }{ 2 }
\]  We'll see shortly that astrophysical 
sources give $ H _ + \sim 10^{ - 21 } $. This 
is fine for linearised theory. For arms of 
length $ \mathcal{ L } \sim 3 km $, we need a change in 
the length of arm $ \delta \mathcal{ L }  = 10 ^{ - 18 } m  $. 
This is small!
An aside: everything we've done is in the linearised 
model, which is fine. There is however a class 
of exact gravitational wave solutions, called Brinkmann metrics. 
This metric is
\[
	ds ^ 2  = - du dv + dx ^ a dx ^ a + H_{ ab } ( u ) x ^ a x ^ b d u ^  2
\] We introduced lightcone coordinates here where $ u = t - z $ and $ v = t + z $
We're indexing over  $  a = 1, 2 $. $ H_{ ab } ( u ) $ is arbitrary with 
$ H ^ a _ a  = 0 $. 
This solves the Einstein equations. 


\subsection{Making Waves}
In this section we'll look at how to make grasvitational waves. 
We generate electromagnetic waves by shaking charges, 
and we generate gravitational waves by shaking mass. 
We want to solve the equation 
\[
 \Box \overline{h } _{ \mu \nu }  =  - 16 \pi G T _{ \mu \nu }
\] The right hand side must be 
small since we're working in linearlised 
theory. 
We also have a restriction that $ T _{ \mu \nu } $ must be 
non-slowly moving. 
Let's look at how this works. 
Suppose we have a region of space, in the diagram 
below. (Insert here). 
We can solve this using Green's functions, 
by putting the Green's function on $ T $, and integrating 
over this. 
\[
 \overline{h } _{ \mu \nu }  = 4 G \int_{ \Sigma } d ^ 3 x ' \, 
 \frac{T _{ \mu \nu } \left( \vec{x} '  , t _{\text{ret} }  \right) }{ |\vec{x} - 
 \vec{x} ' | } 
\] where we define the retarded time $ t _{ \text{ret } }  = t - | \vec{x} - \vec{x} ' | $. Recall we derive 
the Green's function by first fourier transforming, 
then solving the Helmholtz equation. Alternatively, 
in QFT, we can Fourier transform in 4-space and 
then choose the retarded time contour to find 
our integral. 
ONe comment - this equation we derived while in 
de Donder gauge, so we should make sure 
the solution obeys the de-Donder gauge condition.
\[
 \partial  _ \mu T ^{ \mu \nu  }  = 0
\]  We can check this. 
This is analogous to electromagentism where 
we impose that the current obeys the Lorentz gauge. 
Now, this is the general solution, 
and we want to know what this solution looks like a long way away. 
We Taylor expand! For $ r \gg d $, we have 
that 
\[
 | \vec{x} - \vec{x} ' | \simeq r - \frac{\vec{x} \cdot  \vec{x}  '}{ r } + \dots 
\] If we take the reciprocal of this we 
get that 
\[
 \frac{1}{| \vec{x} - \vec{x} ' | } \simeq \frac{1}{r } + \frac{\vec{x} \cdot  \vec{x} ' }{ r ^ 3 } + \dots 
\] Since $ \vec{x} ' $ is buried in $ t_{\text{ret } } $, 
we need to Taylor expand this out as well. 
\[
	T_{ \mu \nu } \left( \vec{x} ', t_{ \text{ret } }   \right)  = 
	T _{ \mu \nu } \left( \vec{x} ' , t - r  \right)  + 
	\dot{ T } _{ \mu \nu } \left( \vec{x} ' , t - r  \right)  \frac{\vec{x} \cdot  \vec{x} ' }{ r } + \dots  
\]  At leading order, we have that our 
field is 
\[
 \overline{ h } _{ \mu  \nu } \simeq \frac{4 G }{ r } \int _{ \Sigma } 
 d ^ 3 x ' \, T _{ \mu \nu } \left( \vec{x} ', t - r   \right)  
\] If we look at the specific components, 
we have that 
\[
 \overline{h}_{00 } \simeq \frac{4 G E }{ r } \text{ with } 
 E = \int _{ \Sigma } d ^ 3 x ' \quad T _{ 00} \left( \vec{x} ' , t - r  \right)  
\] Similarly we have 
\[
 \overline{ h } _{ oi } \simeq  - \frac{4 G P _ i }{ r } \text{ with } 
 P _ i   = - \int_{ \Sigma } d ^ 3 x ' T _{ 0i } \left( \vec{x} ' , 
 t - r \right) 
\] Note, these equations are 
okay for the inspiral part of the motion, but not 
okay for the 'merger' and 'ringdown' part of the 
star merger. 
The interesting physics part of the solution comes from 
\[
 \overline{ h } _{ ij } \simeq \frac{ 4 G }{ r } \int _{ \Sigma } d ^ 3 x' 
 T _{ ij } \left( \vec{x} ' , t - r \right) 
\] Now, to manipulate this 
we write \[
	T ^{ ij }  = \partial  _ k \left( T ^{ ij } x ^ j  \right)  
- \left( \partial  _ k T ^{ ik }   \right) x ^ j \]
But, using the fact that the energy momentum tensor is 
conserved, we gave that the above 
\[
	\dots = \partial  _ k \left( T ^{ ik } x ^ j   \right)
	 + \partial  _ 0 T ^{ 0i  } x ^ j 
\] where we used the identity $ \partial  _ \mu T ^{ \mu  \nu }  = 0 $. 
Anti-symmetrising, we have that 
\begin{align*}
	T^{ 0 ( i } x ^{ j ) } &=  \frac{1}{2 } \partial  _ k 
	\left( T ^{ 0k } x ^ i x ^ j  \right)    - \frac{1}{2 } \left( \partial  _ k T^{ 0k }  \right)  x ^ i x ^ j \\
			       &=  \frac{1}{2 } \partial  _ k \left( T ^{ 0k } x ^ i x ^ j  \right)  + \frac{1}{2 } \partial  _ 0 T ^{ 0 0 } x ^ i x ^ j  \\
\end{align*}
Now, we can put this into the integral for the 
expression $ \overline{ h } _{ ij}  $, and 
we can drop any spatial derivatives 
because we can treat them as boundary terms. 
We put this into $ \int _{ \Sigma } d x ' $. 
Hence, we're only left with time 
derivatives in our object we and we get that 
\[
	\overline{ h } _{ ij } \simeq \frac{ 2 G }{ r } \ddot{I }_{ij }\left( t - r \right)  
\]  where $ I _{ ij }  = \int d ^ 3 x ' \, T ^{ 0 0 } (\vec{x} ' , t ) x_ i '  x _ j' $
is defined as the quadrapole of the energy distribution in $ \Sigma $.
If we continue this expansion, we have multiple 
pole expansions after this. Note that, 
we could now use $ \partial  _ \mu \overline{ h } ^{ \mu \nu }  = 0 $ to 
find corrections to $ \overline{ h } _{ 0 0 } $ and $ \overline{ h } _{ 0 i} $
using $ \overline{ h } _{ ij } $. Also, 
if we shake matter at some characteristic frequency $ \omega $, 
then we're going to create waves which have a frequency 
of roughly $ \omega $ as well.
Because $ T ^{ ij } $ has two indices, 
we have that we get a dquadrapole instead of 
the dipole as in electromagnetism. 
We couldn't have a dipole in the expansion, 
since momentum is conserved and can't shake backwards 
and forwards.

\begin{example}{(An example Binary system)}
	Consider two objects, each with mass $ \mathcal{ M } $ 
	in a circular orbit rather than in an elliptic orbit, 
	which will be in the $ \left( x, y  \right)  $ plane 
	at distance $ R $. 
	If we assume Newtonian gravity, we 
	get that the expression for frequency 
	is 
	\[
	 \omega ^ 2  = \frac{2 G M }{ R ^ 3  }
	\] Viewed as point particles, 
	we get that the energy momentum tensor is 
	\[
		T ^{ 0 0 } \left( \vec{x}, t  \right)  = M \delta ( z ) 
		\left[  \delta \left( x - \frac{1}{2 } R \cos \omega t  \right)  \delta \left( y  - \frac{1}{2 } R \sin \omega t  \right) + \delta \left( x + \frac{1}{2 } R \cos \omega t  \right)  \delta \left(  y + \frac{1}{2 } R \sin \omega t  \right)  \right] 
	\] To compute 
	$ I _{ ij } \left(  t \right)  $ to find 
	\[
	 I _{ ij }  = \frac{M R ^ 2 }{ 4 } 
	 \begin{pmatrix}  1 + \cos \omega t & \sin \omega t & 0 \\
	 \sin 2 \omega t & 1 - \cos \omega t & 0 \\
 0 & 0 & 0 \\ \end{pmatrix} 
	\] where we've used the double angle formula 
	to help simplify out the terms. 
	This tells us that 
	\[
	 \overline{ h } _{ ij }  = \frac{ -  2 G M R ^ 2 \omega ^ 2 }{ r } 
	 \begin{pmatrix}  \cos 2 \omega t_{ \text{ ret } } & \sin 2 \omega t _{ \text{ret } } & 0 \\ \sin 2 \omega t _{ \text{ret } } & - \cos 2 \omega t_{ \text{ ret } } & 0 \\ 0 & 0 & 0  \end{pmatrix} 
	\] So we get circularly polarised gravitational waves which 
	are travelling in the $ z $ direction. Using the fact 
	that from Newtonian gravity, $ \omega ^ 2  = \frac{ 2 G M }{ R ^ 2 } $, 
	we get that 
	\[
	 | h_{ ij } | \sim \frac{ G ^ 2 M ^ 2 }{ R r }
	\] There's something surprising. 
	When we are looking at light through a telescope, 
	the dimness goes as $ \frac{1}{R  } ^ 2 $ here, it's
	$ \frac{1}{  R} $. This is becasue we're not 
	measuring intesity but strains. This 
	meanas that if we double our intensity, 
	we can see $ 8 $ times as more since we double our range 
	and have an additional volume factor  $ 8 $. 
	To get a large $ | h _{ ij } | $, we need compact objects 
	nearby. But, the most compact objects 
	are black holes and the closest they 
	can possibly come if we have two black holes is 
	the Schwarzchild radius, $ R _S  = 2 G M $.
	As they approach, 
we have that $ | h _{ ij } | \sim \frac{ G M }{ r } $ . 
A black hole of a few solar masses $ R _ S \sim 10 k m $
in the Andromeda galaxy ($ r \sim 10 ^{ 18 } km $  )
gives us the strength of the gravitational wave 
to be $ |h _{ ij } | \simeq 10 ^{ - 17 } $.
Observed galaxies are even farther away, 
with LIGO detecting strengths at $ 10 ^{ - 21 }$. ! 


\subsection{Power Radiated} 
How much energy is emitted in gravitational waves? 
For electromagnetism, we compute the 
power 
\[
 \mathcal{ P }  = \int_{ S ^ 2 } d ^ 2 S_i T ^{ 0 i }
\] The $ T ^{ 0i } $ component is called 
the Poynting vector. 
For gravitational waves, we would need to define
an energy momentum tensor $t _{ \mu \nu } $ 
for the gravitational field which, in the linearised 
theory, should obey 
\[
 \partial  _ \mu t ^{ \mu \nu }  = 0
\] That's the goal - 
we need to come up with 
something like a conserved energy momentum tensor, 
then integrate over the Poynting vector. 
Sadly, there's no such object which is gauge 
invariant. Or more precisely, 
there is no such gauge invariant object. 
The thing before depends on the choice of coordinates. 
There is a way to proceed - we have to work 
in Minkowski space. We look at $ \mathscr { J }^ +  $, 
and look at the energy radiated at this point. 
A correct treatment studies 
energy which hit $ \mathscr{ J  } ^ + $ in Minkowski 
space, and it turns out 
that one can define gauge invariant things at this 
infinity. This is something called Bondi energy. 

Instead, we're going to do things in a hand-wavy way. 
We're gonna be looking for 
just order of magnitude estimates, and just 
be sloppy in this section.

We have the Fierz Pauli action. 
As constructed, this looks similar to 
all other actions in QFT with the field $ h _{ \mu \nu } $, 
as a theory in flat space, and compute the Noether current 
for translations. 
We can treat it as any other action, 
and in particular compute the Noether current. 
However, what we get is 
not gauge invariant or symmetric. This is 
the same in Maxwell theory, but 
in Maxwell theory we can add extra terms to make it 
symmetry and gauge invariant. However, in the 
Fierz-Pauli action there's nothing we can do to 
make it gauge invariant. 

In $ TT $ gauge, with $ h = 0 $ 
and $ \partial  _ \mu h ^{ \mu \nu }  = 0 $ , the Fierz-Pauli 
action is 
\[
 S _{ FP }   = - \frac{1}{8 \pi G } \int d ^ 4 x \, \frac{1}{4 } 
 \partial  _ \rho h _{ \mu \nu } \partial  ^ \rho h ^{ \mu \nu } 
\] Pretend that $ h _{ \mu \nu }$  are a bunch 
of scalar fields. The energy density 
is 
\[
	t ^{ 0 0 } \sim \frac{1}{G } \dot{h _{ \mu \nu } }\dot{h ^{ \mu \nu } }
\]  For wave solutions, 
the $ \nabla h^{ \mu \nu } \cdot  \nabla h ^{ \mu \nu }  $ 
term contributes the same since we can 
sub in the wave equation. 
Previously, we had the solutions
written in terms of our field 
\[
	\overline{ h } _{ ij } = \frac{ 2 G }{ r } \ddot{I}_{ ij }
\]  This is not in TT 
gauge, If we put it in this form, we get 
\[
	h _{ ij } \sim \frac{ G }{ r } \ddot{Q}_{ij }
\] with $ \mathcal{ Q } _{ ij } = I _{ ij }  - \frac{1}{3 } I _{ kk } \delta _{ij } $. This suggests that 
the energy density in gravitational waves 
far from the source is given by 
the time derivative of $ h $, with leads to 
three time derivatives on $ Q $, so that 
\[
	t ^{ 0 0 } \sim \frac{ G }{ r ^ 2 } \dddot{\mathcal{ Q } }_{ ij }
\]  Integrated over a sphere, 
this suggests that the power emitted 
is 
\[
 P \sim  G \dddot{Q}^ 2 _{ ij } 
\] It turns out that this approximation is 
correct. The correct result 
is $ \mathcal{ P }  = \frac{ G }{ 5 }\dddot{Q}^ 2 _{ ij }$. 
This is from the treatment at $ \mathscr{J } ^ + $ 
using the Bondi energy. There was 
an assumption in this solution 
that things were stationary. 
The problem is that at every single step, 
the calculation we did relies on 
our choice of coordinates. 
How does it make any sense that we're getting 
the right answer? This is probably due to dimensional 
analysis. If we follow Bob Wald's book, 
they take the Einstein equations 
and expand them to second order. Then, 
we carry the second order piece to the otherside, 
and wrangle this into the form of $ t _{\mu \nu } $. 
As we average over space and time, 
the lack of gauge invariance is less severe, since 
the terms are suppressed by larger volumes.
This leads to something that we call almost gauge 
invariant. This is dubious. 
However, if we average over all of spacetime, 
we get a method that recovers the Bondi energy. 

There's something called the Holst Taylor binary. 
This is a couple of neutron stars orbiting each other, 
and one of them is a pulsar. 
This means that measured over many years, you 
can measure the frequency of the orbit. 
The frequency decreases by 10 micro seconds every year, 
and this result agrees with the calculation 
we've done here. 

The error is that if we did things this way, 
we would get a bunch of other stuff. 

Let's put some numbers in this and 
see what we're going to get. 
\end{example}

\begin{example}
	Take a binary system $ \omega ^ 2 R \sim \frac{ G M }{ R ^ 2  }$. 
	The quadrupole 
	is proportional to $ \mathcal{  Q} \sim M R ^ 2 $
	by dimensional analysis. This means that 
	the third time derivative is given by 
	\[
		\dddot{Q} \sim \omega ^ 3 \mathcal{ M } R ^ 2 
	\]  This means that our power is given by 
	\[
		\mathcal{ P } \sim G  \dddot{\mathcal{ Q}} ^ 2 \sim 
		\frac{ G ^ 4 M ^ 5 }{ R ^ 5 } 
	\] It turns out that in regular dimensions, 
	this is correct. But, it turns out that the 
	Schwarzchild radius, $ R _ S = \frac{ 2 G M }{ c ^ 2 } $. 
	We get that our power constructed is 
	\[
		\mathcal{ P }  = \left( \frac{ R _ S}{ R }  \right)  ^{ 5 } 
		\mathcal{ L } _{ planck}
	\] with $ \mathcal{ L } _{ \text{planck  } }  = \frac{ c ^ 5 }{ G } $ which is roughly equivalent $ 3. 6   \times 10 ^{ 52 } J s ^{ - 1} $.  
	This is an enormous amount of energy emitted per second! 
	The sun emits $ \mathcal{ L } _{ \sun  } \simeq 10 ^{ - 26 } \mathcal{ L } _{ \text{ planck } }  $. All the stars in the 
	observable universe emit $ \mathcal{ L } \sim 10 ^{  - 5 } \mathcal{ L } _{ \text{planck } } $. Yet, when two black holes 
	collide, they have $ R \sim R _ S $ and so $ \mathcal{ L } \sim \mathcal{ \text{ Planck }}$. This is quite astonishing  -
	they are astonishingly violent events! You might think, 
	surely gravitational waves are emitted by some less violent 
	events. 
	Two objects with different masses $ M _ 1 \gg M _ 2 $ 
	has a power which is emitted 
	\[
	 P \sim \frac{ G ^  4 M _   1 ^ 3 M _ 2 ^ 2 }{ R ^ 5 }
	\] Now we can start calculating the gravitational 
	waves emitted by other things. 
	In the solar system, we can calculate the gravitational 
	waves emitted by Jupiter, where $ \mathcal{ M } _{ J }  \sim 
	10 ^{ - 3 } \mathcal{ M } _{ \sun } $, and $ R \simeq 10 ^{ 8 } km $. 
	If we plug this is, we get that 
	\[
	 \mathcal{ P } \sim 10 ^{ - 44 } \mathcal{ L }_{ \text{planck} } 
	  = 10 ^{ - 18 } \mathcal{ L } _{ \sun }
  \] 
\end{example}
\begin{example}{(Waving around arms)}
	Suppose that you wave your arms wildly. 
	$ \mathcal{ Q } \sim 1 kg m ^ 2 $ and 
	$ \dddot{Q} \sim 1 kg m ^ 2 s ^{ - 3 } $. 
	The formula for the power emitted is 
	\[
		\mathcal{ P } \sim G \dddot{\mathcal{ Q } }^ 2 / c ^ 5 \sim 10^{ - 5 2 } J s ^{ - 1 } 
	\]  How small is this number? A single 
	graviton has $ E  = \planck \omega 	 $, so if $ \omega  = 1 s ^{ - 1 } \implies E \simeq 10 ^{ - 3 4} J $ . To emit a single graviton, you 
	should wave your arms for 
	$ T \sim 10 ^{ 18 } s \simeq 10 \text{billion years } $.
\end{example}


\subsection{Summary}

\subsubsection{Gauge symmetries in linearised theory} 

We can significantly reduce the 
complexity of the equations in linearised theory 
by fixing the gauge. 
\begin{itemize}
	\item An infinitesimal diffeomorphism on the metric induces the following transform on the perturbation as well as the trace removed form
		\[
		 h_{ \mu \nu } \to h_{ \mu \nu } + \partial  _ \mu \xi _ \nu 
		 + \partial  _ \nu \xi _ \mu, \quad 
		 \overline{ h } _{ \mu \nu }  \to \overline{ h} _{ \mu \nu } 
		 + \partial  _ \mu \xi _ \nu + \partial  _ \nu \xi _ \mu 
		  - \eta _{ \mu \nu } \partial  _ \rho \xi ^ \rho 
		\]
	\item With this transformation we can impose 
		that we're working in the de Donder gauge: 
		\[
		 \partial  ^ \mu \overline{ h } _{ \mu \nu }  =  0 
		\] 
	\item This gauge gives us the forced 
		wave equation to solve 
		\[
		 \Box \overline{ h } _{ \mu \nu }  =  - 16 \pi T_{ \mu \nu }
		\] 
\end{itemize}

\subsubsection{Gravitational wave solutions and polarisations}

\subsubsection{Gravitational waves from a source}
We'll summarise the procedure of finding $ \overline{ h }_{ \mu \nu }$ 
from the energy-momentum tensor $ T^{ \mu \nu } \left( \vec{x}, t  \right)$. 

\begin{itemize}
	\item We need to solve the forced wave equation 
		\[
			\Box \overline{ h }_{ \mu \nu }  =  - 16 \pi T_{ \mu \nu }, \quad \Box  = - \partial _ t ^ 2 + \partial  _ x ^ 2 
		\]
	\item We import the same result from electromagnetism that 
		applying a retarded Green's function gives us the desired result 
	\[
		\overline{ h }^{ \mu \nu }  = \int d ^ 3 x '  \, \frac{T ^{ \mu \nu } \left(  
		\vec{x} ' , t - | \vec{x} - \vec{x} ' | \right) }{ | \vec{x} - \vec{x} '  | }
	\] where we define $ t_{ \text{ret} } = t - | \vec{x}  - \vec{x} ' | $. 
\item Since $ \partial  _ \mu T ^{ \mu \nu }  = 0 $, the de Donder gauge condition is also obeyed with $ \partial_ \mu \overline{ h} ^{ \mu \nu }  = 0 $. (I should probably work on proving this sometime).
\item The quadrapole moment $ I_{ ij } $ and obeys 
	\[
		\int d ^3 x' T_{ ij } \left(  \vec{x} ' , t  \right)   = \frac{1}{2 } \ddot{I }_{ ij } \left( t  \right), \quad I_{ ij } ( t )  = \int d ^ 3 x ' T ^{ 00 } \left( \vec{x}  ', t   \right) x _ i x _ j  
	\]   
\item We employ the approximation $  | \vec{x} - \vec{x} ' |   = r - \vec{x} ' \cdot  \hat{ \vec{x} } $ to approximate the stress-energy 
	tensor and the metric perturbation as
	\begin{align*}
		T^{ \mu \nu } \left( t - | \vec{x} ' - \vec{x} |, \vec{x} '  \right)  & \simeq T ^{ \mu \nu } \left(  t - r + \hat{\vec{x} } \cdot  \vec{x} ' , \vec{x} '  \right)  \simeq T^{ \mu \nu } \left(  t - r , \vec{x} '  \right)  + \hat{ \vec{x} } \cdot  \vec{x} ' \partial _ 0 T ^{ 0 \nu } 
		\left(  t - r , \vec{x} '  \right) \\ 
		\overline{ h } _{ ij } \left( t, \vec{x} \right) 
		&=  \frac{4}{r } \int d ^ 3 \vec{x} ' \, 
		T_{ ij } \left( t - r , \vec{x} '  \right)
	\end{align*}
We assumed that the source is moving slowly so the second term 
with the derivative with respect to time disappears. 
\end{itemize}
