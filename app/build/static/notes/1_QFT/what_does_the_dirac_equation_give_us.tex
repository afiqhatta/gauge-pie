\subsection{What does the Dirac equation give us?} 
The Dirac equation is important because it provides the framework for quantization of spin-$\frac{1}{ 2}$ particles, like electrons and other fermions. Another startling prediction that the Dirac equation gives us is the existence of anti-matter. This equation is an amazing combination of the geometry of spinors in Minkowski space-time, and the wave-function formalisation of quantum mechanics that we all know and love. 
In this section, we'll provide some motivation for constructing the Dirac equation, solve it, then quantise this object to give rise to particles (fermions). 

Right now we'll try to analyse how fields with \textbf{multiple}
components change under an underlying Lorentz transformation. 
Recall that when we have a Lorentz transformation in our 
coordinates, we induce a transform on our scalar field. 
\[
	x ^ \mu \to ( x ') ^ \mu = \Lambda \indices{ ^ \mu _ \nu } x  ^ \nu, \quad 
 \phi ( x) \to \phi ' ( x) = \phi ( \lambda ^{ -1 } x ) 
\] Most particles have an intrinsic angular momentum-spin however, 
and so transform in a non-trivial way 
under boosts and rotations. 
For example a spin-1 vector field $ A ^ \mu $ (for example, 
our familiar electromagnetic vector potential) transforms under a 
Lorentz boost as 
\[
	A ^ \mu ( x) \to (A ') ^ \mu ( x) = \Lambda \indices{ ^ \mu _ \nu } A ^ \nu ( \Lambda ^{ - 1 } x )  
\] There's no 
reason a priori why vector fields with 
multiple components need to transform with $ \Lambda \indices{ ^ \mu _ \nu } $
multiplying it out front. In general, we have that our field transforms 
as 
\[
	\phi ^ a ( x) \to D \indices{ ^ a _ b  } ( \Lambda ) \phi ^ b ( \Lambda ^{ - 1} x )  
\] where our matrices $ D $ form a representation of our Lorentz group. Let's 
explain why this is. We treat $ \psi ^ a $ as a vector which 
is acted on by a symmetry. However, for this symmetry to  \textbf{act} 
on an object like a vector, it needs to be represented in 
the same space (for example, as a matrix). 
Up until now, we've been representing a Lorentz transformation group
in it's standard form as a matrix, but this isn't
the only representation (recall the Lorentz group isn't 
defined in terms of matrices in the first place, but 
as members of the orthogonal group $O(1, 3 )$ ). 
Representations obey the properties that the group structure is preserved.
This means that, if $ D $ is a representation, then
\begin{align*}
	D ( \Lambda _ 1 ) D ( \Lambda _ 2) & = D ( \Lambda _  1 \Lambda _ 2 ) \\
	D ( \Lambda ^{ - 1} ) &= D ( \Lambda ) ^{ - 1} \\
	D ( I ) &= 1 
\end{align*} To find representations 
we look at the Lorentz algebra, considering infinitesimal transformations
\[
 \Lambda \indices{ ^ \mu _ \nu } = \delta \indices{ ^ \mu _ \nu } + 
 \epsilon \omega \indices{ ^ \mu _ \nu } + O ( \epsilon ^ 2 )  
\] Working to infinitesimal order, the find that 
the generators obey the relation 
\[
	\Lambda \indices{ ^ \mu _ \sigma  } \Lambda \indices{ ^ \nu _  \rho }  =  \eta ^{ \mu \nu }
\]  Substituting this into our relation we have that 
\[
	( \delta \indices{ ^ \mu _ \sigma } + \epsilon \omega \indices{ ^ \mu _ \sigma } ) ( 
	\delta \indices{ ^ \nu  _ \rho }   + \epsilon \omega \indices{ ^ \nu  _ \rho }  ) \eta ^{ \sigma \rho }  =
	\eta ^{ \mu \nu } + O ( \epsilon ^ 2 ) 
\]  This implies that our generator satisfies 
\[
 \omega _{ \mu \nu } = - \omega _{ \nu \mu } \implies 
 \omega _{  \mu \nu } \text{ is anti symmetric}
\] This generator has $ 6 $ components, split up into 
3 rotations and 3 boosts. Thus, we can introduce a basis of 
six $ 4 \times 4 $ matrices 
\[
	( \mathcal{ M } ^{ \rho \sigma } ) ^{ \mu \nu }  = \eta ^{ \rho \mu } \eta ^{ \sigma \nu } 
	- \eta ^{ \sigma \mu } \eta ^{ \rho \nu }
\] We can lower the index here to give 
\[
	( \mathcal{ M } ^{ \rho \sigma } ) \indices{ ^ \mu _ \nu } = 
	\eta ^{ \rho \mu } \delta \indices{ ^ \sigma  _ \nu }  - 
	\eta ^{ \sigma \rho } \delta \indices{ ^ \rho _ \nu } 
\]  For example, we have that 
\[
	( \mathcal{ M } ^{ 01  } ) \indices{ ^ \mu_ \nu } = 
	\begin{pmatrix}  0 & 1 & 0 & 0 \\ 
	1 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{pmatrix} 
\] This specific generator generates a boost in the $x ^ 1 $ 
direction. We can hence write our generator as 
a linear sum of these basis matrices. 
\[
	\omega \indices{ ^ \mu _ \nu } = \frac{1}{2 } \left(  \Omega_{ \rho \sigma } \mathcal{ M } ^{ \rho \sigma } \right)
	\indices{ ^ \mu _ \nu } 
\]  We call $ \mathcal{ M }^{ \rho\sigma } $ the generators 
of our Lorentz group, and our corresponding $ \Omega ^{ \rho\sigma } $ 
the anti symmetric parameters of the Lorentz transformation.  
Our Lorentz algebra, one can calcuate, is 
\[
	[ \mathcal{ M } ^{ \rho \sigma } , \mathcal{ M  } ^{ \tau \nu  } ] 
	= \eta ^{ \sigma \tau } \mathcal{ M } ^{ \rho \nu } - \eta ^{ \rho \tau } \mathcal{ M} ^{ \sigma \nu }
	- \eta ^{ \rho \nu } \mathcal{ M }^{ \sigma \tau } - \eta ^{ \sigma \nu } \mathcal{ M } ^{ \rho \tau }
\] What we've 
done here is that we've calculated the Lie bracket of two 
elements in our representation. This means that any other representation 
of the Lorentz group necessarily satisfies this relation, since 
representations of a Lie algebra needs to preserve the Lie bracket. 
Our corresponding boost is $ \exp ( \frac{1}{2 } \Omega_{ \rho \sigma  } ) \mathcal{ M } ^{ \rho \sigma }$.
This is because when we are returning 
the infinitesimal transformation back into its full form 
by exponentiating. 

\subsection{The Spinor Representation} 

Now, the aim of the game is to try and find 
other representations which satisfy the 
Lorentz algebra.
To help us find representations that satisfy the 
Lorentz algebra, we start by defining 
something called the Clifford algebra. This is an algebra whose 
elements satisfy the anti-commutation 
relations 
\[
 \left\{  \gamma ^ \mu , \gamma ^ \nu  \right\}  = 2 \eta ^{ \mu \nu } I , 
 \quad \left\{  \gamma ^ \mu , \gamma ^  \nu  \right\}   = \gamma ^ \mu \gamma ^ \nu 
 + \gamma ^ \nu \gamma ^ \mu 
\] where $ \gamma ^ \mu $ are a set of four matrices. 
We have that our matrices in the algebra obey 
the properties 
\begin{align*}
	\gamma ^ \mu \gamma ^ \nu & = - \gamma ^ \nu \gamma ^ \mu , \quad \mu \neq \nu \\
	( \gamma ^ 0 ) ^ 2 & = I, \quad ( \gamma ^ i ) ^ 2 =  - I , \quad i \in \left\{ 1, 2, 3  \right\} 
\end{align*}
Our simpliest representation which obeys these commutation relation 
are a set of $ 4 \times 4 $ matrices, which we call the Chiral representation. 
These are given in block matrix form as 
\[
	\gamma ^ 0 = \begin{pmatrix}  0 & I _ 2 \\ I _ 2 & 0  \end{pmatrix} , \quad 
	\gamma ^ i = \begin{pmatrix}  0 & \sigma ^ i \\ - \sigma ^ i & 0  \end{pmatrix} 
\] Here, $ \sigma ^ i  $  are the 
Pauli matrices given by 
\[
	\sigma ^ 1 = \begin{pmatrix}  0 & 1 \\ 1 & 0  \end{pmatrix}  , \quad 
	\sigma ^ 2 = \begin{pmatrix}  0 & - i \\ i & 0  \end{pmatrix} , \quad
	\sigma ^ 3  = \begin{pmatrix}  1 &  0 \\ 0 & 1  \end{pmatrix} 
\] 

These Pauli matrices 
obey the commutation and anti commutation relations 
\[
 \left\{  \sigma ^ i , \sigma ^ j  \right\}  = 2 \delta ^{ ij } I _ 2 , 
 \quad [ \sigma ^ j , \sigma ^ k ] =  2i \epsilon ^{ jkl } \sigma ^ l 
\] Given this representation, we can also 
generate a new representation by conjugating by a constant 
invertible matrix $ U$, so $ U \gamma ^ \mu U ^{ - 1} $  works 
also as a representation. 

If we define 
\[
	S ^{ \rho\sigma } : = \frac{1}{4} [  \gamma ^ \rho ,  \gamma ^ \sigma ] 
	= \begin{cases}
		0 & \rho = \sigma \\ 
		\frac{1}{2  } \gamma ^ \rho \gamma ^ \sigma &  \rho \neq \sigma 
	\end{cases}
	 = \frac{1}{2 } \gamma ^ \rho \gamma ^ \sigma  - \frac{1}{2 } \eta ^{ \rho \sigma } I 
\] we aim to show that this satisfies 
the Lorentz algebra, whilst being philosphically different 
to the algebra we defined before. 
Now, expanding this whole thing out explicitly is difficult to 
do, so we prove a handful of useful relations to show this. We can 
 
\begin{claim}
We have that 
	\[
		[ S ^{ \mu \nu } , \gamma ^ \rho ]  = \gamma ^ \mu \eta ^{ \nu \rho } 
		  - \gamma ^ \nu \eta ^{ \rho \mu }
	\]  
\begin{proof}
There's some steps we have to follow and it's not as straightforward 
as it seems from first glance. 
The basic idea is to commute things out 
so that we only have one $ \gamma $ factor per term. 

\begin{align*}
	[S ^{ \mu \nu } , \gamma ^{ \rho } ] &=  
	\frac{1}{2 } [ \gamma ^ \mu \gamma ^ \nu  - \eta ^{ \mu \nu } , \gamma ^{ \rho }  ] \\
					     &=  \frac{1}{2 } [ \gamma ^ \mu \gamma ^ \nu , \gamma ^ \rho ]  \\
					     &=  \frac{1}{2  } ( \gamma^ \mu \gamma ^ \nu \gamma ^ \rho - 
					     \gamma ^ \rho \gamma ^ \mu \gamma ^ \nu ) 
\end{align*}
Now, this is a bit tricky to manage. The key is to anti-commute things 
in the right order. We anti-commute the last two 
matrices in the first term, and the first two matrices in 
the last term. 
The above is then equal to 

\begin{align*}
	\dots & = \frac{1}{2} \gamma ^ \mu ( \left\{  \gamma ^ \nu , \gamma ^ \rho  \right\}   - \gamma ^ \rho \gamma ^ \nu )
	 - \frac{1}{2 }\left(  \left\{  \gamma ^ \rho , \gamma ^ \mu  \right\}  - \gamma ^ \mu \gamma ^ \rho  \right)  \gamma ^ \nu \\
	      &=  \frac{1}{2 } \gamma ^ \mu \left(  
	      2 \eta ^{ \nu  \rho }  - \gamma ^ \rho \gamma ^ \nu \right)   - \frac{1}{2 } 
	      ( 2 \eta ^{ \rho \mu } - \gamma ^ \mu g \gamma ^ \rho ) \gamma ^ \nu \\
	      &=  \gamma ^ \mu \eta ^{ \nu \rho } - 
	      \gamma ^ \nu \eta ^{ \rho \mu }
\end{align*}
\end{proof} 
\end{claim}
Using this, we can then prove that $ S^{ \rho \sigma} $
satisfies the Lorentz algebra! This means we 
would then be able to use this 
as a valid representation of the Lorentz group. 
\begin{claim}
	\[
		[ S ^{ \rho\sigma } , S ^{ \tau \nu } ] = 
		\eta ^{ \sigma \tau } S ^{ \rho \nu }  - 
		\eta ^{ \rho \tau } S ^{ \sigma \nu } 
		+ \eta ^{ \rho \nu } S ^{ \sigma \tau } 
		 - \eta ^{ \sigma \nu } S ^{ \rho \tau }
	\]

\begin{proof}
We can expand out one side and appeal to the relation 
we proved earlier. 
\begin{align*}
	[ S ^{ \rho \sigma }, S^{ \tau \nu } ] &=  
	\frac{1}{2 } [ S ^{ \rho \sigma } ,  \gamma ^ \tau 
	\gamma ^ \nu - \eta ^{ \tau \mu } I ] \\
	&=  \frac{1}{2 } [ S^{ \rho \sigma } , \gamma ^{ \tau } 
	\gamma ^{ \nu } ] \\
	&=  \frac{1}{2 } [ S ^{ \rho \sigma } , \gamma ^ \tau ] 
	\gamma ^{ \nu } + \frac{1}{2 } \gamma ^ \tau [ 
	S ^{ \rho \sigma } , \gamma ^ \nu ] \\
	= \frac{1}{2 } ( \gamma ^ \rho \eta ^{ \sigma \tau}  - \gamma ^ \sigma 
	\eta ^{ \rho \tau } ) \gamma ^ \nu + \frac{1}{2 } \gamma ^ \tau 
	( \gamma ^ \rho \eta ^{ \sigma \nu }  - \gamma ^ \sigma \eta ^{ \rho \nu 
	} ) 
\end{align*}
Now, to recover what we had earlier, we need to sub out our expressions 
with two gammas for an expression in $S$. To do this, 
we invert our relation for $ S $ so that 
\[
 \gamma ^ \mu \gamma ^ \nu  = 2 S ^{ \mu \nu } + \eta ^{ \mu \nu } I 
\] We then 
get that the above is equal to 
\begin{align*}
	\dots & = \frac{1}{2 } \left(  2 ^{ \rho \nu } \eta ^{ \sigma \tau }
	 + \eta ^{ \sigma \tau } \eta ^{ \rho \nu } I \right) \\ 
	      &  - \frac{1}{2 } \left(  
	      2 S^{ \sigma \nu } \eta ^{ \rho \tau } + \eta ^{ \sigma \nu } 
      \eta ^{ \rho \tau } I  \right) \\
	      & + \frac{1}{2 } \left(  2 S^{ \tau \rho } \eta ^{ \sigma \nu }
	      + \eta ^{ \rho \tau } \eta ^{ \sigma \nu } I \right) \\
	      & - \frac{1}{2 } \left(  2 S ^{ \tau\sigma }
	      \eta ^{ \rho \nu } + \eta ^{ \rho \nu } \eta ^{ \tau \sigma }\right)
	      \\
	      &=  S ^{ \rho \nu } \eta ^{ \sigma \tau } 
	       - S^{ \sigma \nu } \eta ^{ \tau \rho } + 
	       S ^{ \tau \rho } \eta ^{ \sigma \nu } 
	        - S ^{ \tau \sigma } \eta ^{ \rho \nu }\\
\end{align*}
The terms with two $ \eta $ terms cancel out. 
The object that we're left with is precisely the Lorentz algebra. 

\end{proof}
\end{claim} Thus, $ S $ provides a representation of 
the Lorentz group. 
We now define a Dirac spinor, $ \psi _ \alpha ( x) $which is a four component 
vector that satisfies the following transformation 
law 
\[
	\psi ^ \alpha ( x) \to  S[ \Lambda ] \indices{ ^ \alpha _ \beta } \psi ^ \beta ( 
	\Lambda ^{ - 1} x ) 
\] where we've defined $ \Lambda = \exp \left(  \frac{1}{2 } 
\Omega _{ \rho \sigma } M ^{ \rho \sigma } \right)  $, and 
our spinor representation $ S [ \Lambda ] = \exp \left(  
\frac{1}{2 } \Omega _{ \rho \sigma } S ^{ \rho \sigma } \right)  $. 
We need to check that the Spinor representation is not 
equivalent to the usual vector representation, in the
sense that we need to check what we've
written down gives something \textbf{different} than 
our standard Lorentz boost. 

To check that what we have is different, we trial a particular Lorentz transformation (in this case, a rotation by $ 2 \pi$). 

\begin{example}{(The Spinor representation is different)} 
If we choose 
\[
 S^{ ij } = \frac{1}{4 }\left[  \begin{pmatrix}  
 0 & \sigma ^ i \\ - \sigma ^ i & 0 \end{pmatrix}  , 
 \begin{pmatrix}  0 & \sigma ^ j \\ 0 & \sigma^ k   \end{pmatrix}  \right]  
 =  - \frac{i \epsilon ^{ ijk } }{ 2 } \begin{pmatrix}  \sigma ^ k & 0 
 \\ 0 & \sigma^k \end{pmatrix}  \text{ from } \sigma ^ i \text{ algebra}
\] If we write as a paramater 
$ \Omega_{ ij } =  - \epsilon _{ ijk } \phi ^ k $ . 
Exponentiating, we get that 
\[
	S [ \Lambda ]  = \exp \left(  \frac{1}{2 } \Omega _{ \rho \sigma } 
	S ^{ \rho\sigma } \right)  = \begin{pmatrix}  
	e ^{ i \phi \cdot  \sigma / 2  } & 0 \\ 0 & 
e^{ i \phi \cdot  \sigma / 2 } \end{pmatrix}  
\]   Now, if we consider a rotation of 
$ 2 \pi $ abou the $ x ^ 3 $ axis, we get that 
our corresponding representation is 
\[
	S [ \Lambda ] = \begin{pmatrix}  e ^{ i \pi \sigma ^ 3 }` & 0 \\ 
	0 & e ^{ i \pi \sigma ^ 3 } \end{pmatrix}   = - I _ 4 
\] In this notation, the exponential 
needs Thus, a rotation of $ 2 \pi  $  takes a 
spinor $ \phi _ \sigma ( x ) \to  - \phi _{ \sigma } ( x) $, not like a vector, 
which goes like $ \Lambda = I $ as expected (in our fundamental representation). 

Now, what happens with boosts of spinors 
\[
	S ^{ 0i  }  = \frac{1}{2 } \begin{pmatrix}  - \sigma ^ i & 0 \\ 0 & \sigma ^ i   \end{pmatrix}  
\]  If we write our boost parameter as 
$ \Omega _{ 0i }  = \chi _ i $, then our corresponding representation 
is 
\[
	S [ \Lambda ] = \begin{pmatrix}  e^{  - \chi \cdot \sigma / 2   } & 
	0 \\ 0 & e ^{ \chi \cdot  \sigma / 2 } \end{pmatrix}  
\] Note that for rotations, $ S [ \Lambda ] $ is unitary, since $ S [ \Lambda ] ^ \dagger S [ \Lambda ]  = I $, but for boosts, it's not.
\end{example} 

\begin{thm}{(No finite dimensional, unitary representations of the Lorentz group)} 
There are no finite dimensional unitary representations of the Lorentz group! 

\begin{proof} 
$ S [ \Lambda ]  = \exp \left[  \frac{1}{2 } \Omega_{ \rho \sigma } 
S ^{ \rho \sigma } \right]  $ is only unitary if $ S ^{ \rho \sigma } $ are 
anti hermitian. Now, when we take the Hermitian conjugate 
of a commutator, not only does each element pick up a 
hermitian conjugate, but the arguments in the commutator switch around. 
This means we have to pick up a minus sign. 
\[
	( S ^{ \rho \sigma } ) ^ \dagger  = -  \frac{1}{4 } [ ( \gamma ^ \rho ) ^ \dagger , 
	( \gamma ^ \sigma ) ^ \dagger ] 
\] can be anti-hermitian only if all $ \gamma ^ \mu $ are hermitian or are all anti hermitian. 
However, this can't be arranged, and is impossible to do. 
This can't be arranged, because
\[
 ( \gamma ^ 0 ) ^ 2 = 1 \] 
 This means in particular that $ \gamma ^ 0 $ has real eigenvalues, 
 which means it can't be hermitian since hermitian matrices 
 only have pure imaginary eigenvalues. 
\[
 ( \gamma ^ i ) ^ 2 = 1 \implies \gamma ^ i \text{ can't be hermitian }
\] In general, there's no way to pick $ \gamma ^ \mu $  such that $ S ^{ \mu \nu } $ 
are anti-Hermitian.
\end{proof} 
\end{thm} 

\subsection{Constructing a Lorentz Invariant action of $ \psi $ }
Now, something of immediate interest is to see whether we 
can construct some sort of action from this. To carry this out, we
should try to construct Lorentz invariant quantities. 
We write $ \psi ^ \dagger ( x )   = ( \psi ^ * ) ^ T ( x ) $. 
One question that we might have is to ask whether 
$ \psi ^ \dagger ( x) \psi( x) $ is a Lorentz scalar. 
However, under a Lorentz transformation, 
\[
	\psi ^ \dagger ( x) \psi  ( x) \to \psi ^ \dagger ( \Lambda ^{ - 1} x ) 
	S [ \Lambda ] ^ \dagger S [ \Lambda ] \psi( \Lambda ^{ - 1}x ) 
\] This is not invariant in general since $ S [ \Lambda ] $ is 
not unitary. 
In the chiral representation, we have that 
\[
	( \gamma ^ 0 ) ^ \dagger  = \gamma ^ 0 , \quad ( \gamma ^ i) ^ \dagger = 
	 - ( \gamma ^ i ) 
\] We can verify by checking for each index, 
that we can write out an identity to relate 
the hermitian conjugate of a gamma matrix to 
an expression which doesn't involve conjugates as 
\[
 ( \gamma ^ \mu ) ^ \dagger = \gamma ^ 0 \gamma ^ \mu \gamma ^ 0 
\] Thus, we can find the Hermitian conjugate of $ S $ as 
\[
	( S ^{ \mu \nu } ) ^ \dagger = - \frac{1}{4 } [ ( \gamma ^ \mu ) ^ \dagger, 
	( \gamma^ \nu ) ^ \dagger ]  =
	- \frac{1}{4 } [ \gamma ^ 0 \gamma ^ \mu \gamma ^ 0 , 
	\gamma ^ 0 \gamma ^ \nu \gamma ^ 0 ]  = - \gamma ^ 0 S ^{ \mu \nu } \gamma ^ 0 
\]  We do this because, since $ \gamma ^ 0 = ( \gamma ^ 0 ) ^{ -1 } $, 
when we exponentiate this object we can pull out the $ \gamma ^ 0 $ on
both sides. Hence, our exponential gives 
\[
 S [ \Lambda ] ^ \dagger = \exp \left(  \frac{1}{2 } 
 \Omega _{ \mu \nu } ( S ^{ \mu \nu } ) ^ \dagger \right)   = \gamma ^ 0 S [ \Lambda ] ^{ - 1} 
 \gamma ^ 0 
\]
\begin{defn}{(The Dirac adjoint)}
	The Dirac adjoint of  $ \psi $ is defined as 
	\[
	\overline{\psi } ( x) := \psi ^ \dagger  (x) \gamma ^ 0 
\] We define this object in the spirit of 
creating scalars, vectors and other objects which transform nicely 
under Lorentz transformations. 
\end{defn}

 
\begin{claim}{(Lorentz invariance of $ \overline{\psi } \psi $)}
Our claim is that $ \overline{ \psi } \psi  $ is indeed a Lorentz scalar. 
To prove this 
observe that 
\[
	\overline{ \psi  } \psi  = \psi ^ \dagger \gamma ^ 0 \phi \to \psi ^ \dagger ( 
	\Lambda ^{ - 1} x ) S [ \Lambda ] ^ \dagger \gamma ^ 0 S [ \Lambda ] \psi ( 
	\Lambda ^{ - 1 }x ) 
\] Using the identity above, we get that this is 
the same. 
\end{claim} 

\begin{claim}{($ \overline{\psi } \gamma ^ \mu \psi $ transforms as a Lorentz vector)}
Things that transform nicely under Lorentz boosts 
are called Lorentz vectors (or more 
familiarly, 4-vectors). This means that they 
transform much like how a position vector 
transforms under a Lorentz boost: 
\[
 x ^ \mu \to \Lambda \indices{^ \mu _ \nu } x ^ \nu  
\] 
We claim that the object $ \overline{\psi } \gamma ^ \mu \psi  $
transforms in this way to, where under a Lorentz 
transform we have that 
\[
 \overline{ \psi } \gamma ^ \mu \psi \to 
 \Lambda \indices{ ^ \mu _ \nu } \overline{ \psi } \gamma ^ \nu 
 \psi 
\]
\begin{proof} 
	Our vector transforms as follows (note that 
	the $ \gamma ^ \mu $ matrix doesn't change 
	since it's a constant object - only the spinors change.
\[
	\overline{ \psi } \gamma ^ \mu \psi \to \overline{ \psi } S [ \Lambda ] ^{ - 1} 
	\gamma ^ \mu S [ \Lambda ] \psi 
\]  For this to be a Lorentz vector, we require that 
\[
	S [ \Lambda ]^{ - 1} \gamma ^ \mu S [ \Lambda ] = \Lambda \indices{ ^ \mu _ \nu } \gamma ^ \nu  
\] To go from here, we need to 
write out the transformations in terms of the 
exponents of their generators. In particular, 
we require that the coefficients of the 
generators $ \Omega_{ \rho \sigma  }  $ are 
the same on both sides  - it's just the matrices $ \mathcal{ M } $
and $ S $ that are different since we're dealing with distinct 
representations. 
\[
	\Lambda \indices{ ^ \mu _ \nu } = \exp \left(  
	\frac{1}{2 } \Omega _{ \rho \sigma  }\mathcal{ M } ^{ \rho \sigma } \right)  , 
	\quad S[ \Lambda ] = \exp \left(  \frac{1}{2 } \Omega _{ \rho \sigma } 
	S ^{ \rho \sigma } \right) 
\] So, we need to prove that 
\[
	( \mathcal{ M  }^{ \rho \sigma } ) \indices{ ^ \mu _ \nu } \gamma ^ \nu 
	=- [ S ^{ \rho \sigma } , \gamma ^ \mu ] 
\] This can be shown to be true by observing that 
\[
 \left(  \eta ^{ \rho \mu }  \delta \indices{ ^ \sigma _ \nu }
  - \eta ^{ \sigma \mu } \delta \indices{ ^ \rho  _ \nu }  \right)  \gamma ^ \nu 
    = \eta ^{\rho \mu } \gamma ^{ \rho }  - \gamma ^{ \rho } \eta ^{ \sigma \mu } = 
    - [ S ^{ \rho \sigma } , \gamma ^{ \mu } ] 
\] 
\end{proof} 
\end{claim} 
Now, the upshot of doing all this 
work is that we can now write down 
an action (which by right should be Lorentz invariant). 
We know that $ \overline{\psi }  \gamma ^ \mu \psi $ is 
a Lorentz four vector, which implies that 
$ \overline{ \psi } \gamma ^ \mu \partial  _ \mu \psi $ 
is a Lorentz invariant quantity. We also already know that 
$ \overline{ \psi } \psi $  is also Lorentz invariant on its 
own. Finally, 
we can construct a Lorentz invariant action from these objects, 
by setting 
\[
	S = \int  d^ 4 x \, \overline{ \psi  } \left(  
	 \gamma ^ \mu \partial  _\mu  - m \right) \psi ( x) 
\] 
\subsection{The Dirac equation} 
Varying $ \overline{ \psi } $ independently 
in the Euler Lagrange equations gives us the Dirac equation.
Because there is no dependence on $ \dot{ \overline{ \psi } }  $, 
we have that our equation of motion is given by 
\[
 \frac{\partial  \mathcal{L } }{\partial  \overline{ \psi } }   = 0 
\] 
Specifically, this is the equation 
\[
 \left(  i \gamma ^ \mu \partial  _ \mu - m  \right)  \psi  =0 
\] This is first order, not second order like KG.
To save some ink, we write 
objects which are contracted with $ \gamma ^ \mu $ with 
a slash. For example, we write $ A _ \mu \gamma ^ \mu = \slashed{ A } $. In this notation, 
the Dirac equation reads  
 \[
	 \left(  i \slashed{\partial } - m  \right)  \psi = 0 
\] Note that each component of $ \psi $ solves
the KG equation. 
\begin{align*}
	( i \slashed{\partial} + m ) ( i \slashed {\partial} - m ) \psi &=  0  \\
	( \gamma ^ \mu \gamma ^ \nu \partial  _ \mu \partial  _ \nu + m ^ 2 ) \psi &=  0  \\ 
	( \frac{1}{2 } \left\{  \gamma ^ \mu , \gamma ^ \nu  \right\}  \partial  _ \mu \partial  _ \nu + m^ 2 ) \psi &  = 0 \\
	- ( \partial  ^ 2 + m ^ 2 ) \psi & = 0 
\end{align*}

\subsection{Chiral Spinors} 
Since $ S [ \Lambda ] $ is block diagonal in our 
Chiral representation, we say that it's reducible (since 
we can write the representation as a direct sum of 
two different representations). 
It decomposes into 2 irreducible representations. 
We write our spinor as 
\[
 \psi = \begin{pmatrix} u _ L \\ u _ R  \end{pmatrix} 
\] where $ u_L , u _ R $ are 2 $ \mathbb{ C } $ component objects
which we call Weyl, or chiral, spinors. 
These objects transform identically under rotations, so that 
\[
 u _{ L, R } \to e ^{ \phi \cdot  \sigma / 2 } u _{ L , R }
\] but under boosts, they transform in the opposite fashion. This 
can be seen by just multiplying the matrix with the vector 
as $ \psi \to S[ \Lambda ]_{ \text{ rot } } \psi $, which gives us 
\[
 u _{ L } \to e ^{ - \chi \cdot  \sigma / 2 } u_L  , \quad u _{ R } \to e ^{ \chi \cdot  \sigma / 2 } u _ R
\] Heuristically we write 
\[
	u _{ L } \sim ( \frac{1}{2 } , 0 )\quad u _{ R } \sim ( 0 , \frac{1}{2 } ) \in ( SU ( 2) , SU ( 2) ) 
\] we have that $ \psi $ is in $ ( \frac{1}{2 } , 0 ) \oplus ( 0 , \frac{1}{2 } ) $. 

\subsubsection{The Weyl equation} 
If we take our Dirac Lagrangian 
\[
	\mathcal{L}_D  = \overline{\psi} \left(i\slashed{\partial} - m\right)\psi 
\] which is equal to 
\[
	\dots = i u_L ^ \dagger \overline{\sigma} ^ \mu \partial  _ \mu u _ L + 
 i u _ R ^ \dagger  \sigma ^ \mu \partial  _ \mu u _{ R } - m \left(  
 u _ L ^ \dagger u _ R + u _ R ^ \dagger u _ L \right) 
\] where we define $ \sigma ^ \mu = ( I , \sigma ) , \overline{\sigma } ^ \mu = ( I , - \sigma ) $.
This is derived simply by writing out 
the components explicitly, then multiplying
by the required matrices. 
A massive fermion requires both $ u _L $ and $ u _ R $ , but 
the massless limit $ m =0 $ requires only $ u _ L $ or $ u _ R $. 
The mass term is mixing up left handed and right handed spinors. 
In the case  $ m = 0$, we get the following EL equations
\[
 i \sigma ^ \mu \partial  _ \mu u _ L = 0 , \quad i \overline{ \sigma } ^ \mu \partial  _ \mu u _ R  = 0 
\] These are called Weyl's equations. 
In classical particle mechanics, the number of degrees of freedom is given by 
half the dimension of phase space. in field theory, we need to do things different
and discuss the number of degrees of freedom per spacetime point. 
In field theory, we have a scalar $ \phi $ and $ \Pi_{ \phi } = \dot { \phi } $, so our 
real degrees of freedom is $ \frac{1}{2 } \times 2  = 1$. 
However, for a spinor $ \psi _{ \alpha } $ we have 8 degrees of freedom since 
it's complex. For our conjugate momenta, 
\[
 \Pi _{ \psi } = i \psi ^{ i } 
\] which doesn't add any degrees of freedom. This means 
that our real degrees of freedom amounts to $\frac{1}{2 } \times 8  = 4$. 
We have 2 for the spin up and spin down particle, and 2 for the 
spin up and spin down anti-particle.

\subsection{Dirac Field Bilinears}  
Throughout this section, 
we've only been using a specific representation 
of $ S $ (which we dubbed the chiral representation). 
However, note that in a different basis,  $ S [ \Lambda ] $ is not necessarily block diagonal! We can transform to a different 
basis by applying the map  
\[
 \gamma ^ \mu \to U \gamma ^ \mu U ^{ - 1 }, \psi \to U \psi 
\] We use 
\[
 \gamma ^{ 5 }  : = i \gamma ^ 0 \gamma ^ 1 \gamma ^ 2 \gamma ^ 3 
\]  to define Weyl spinors in a basis independent way. 
This object has very nice properties which relate 
agonistically with $ \gamma ^ \mu $ for $ \mu  = 0 , 1, 2,3 $. 
\begin{claim}{(Commutation relations for $ \gamma ^ 5 $)}
	The $ \gamma ^ 5$ matrix satisfies the 
	relations 
\[
	\left\{  \gamma ^ \mu , \gamma ^ 5 \right\}   = 0 , \quad  \left(  \gamma ^ 5  \right)  ^ 2 = I \] 

\begin{proof}
	To prove the first 
relation, it's instructive to set $ \mu  =0  $ just to 
see what's going on. We have that the anti-commutator is 
\begin{align*}
	\left\{ \gamma ^ \mu , \gamma ^ 5  \right\}  &=  i ( 
	\gamma ^ 0 \gamma ^ 0 \gamma ^ 1 \gamma ^ 2 \gamma ^ 3  + 
	\gamma ^ 0 \gamma ^ 1 \gamma ^ 2 \gamma ^ 3 \gamma ^ 0 ) \\
						     &=  i ( \gamma ^ 1 \gamma ^ 2 \gamma ^ 3 - \gamma ^ 1 \gamma ^ 0 \gamma ^ 2 \gamma ^ 3 \gamma ^ 0 )  \\
						     &=  i ( \gamma ^ 1 \gamma ^ 2 \gamma ^ 3 + \gamma ^ 1 \gamma ^ 2 \gamma ^ 0 \gamma ^ 3 \gamma ^ 0 )  \\
						     &=  i ( \gamma ^ 1 \gamma ^ 2 \gamma ^ 3 - \gamma ^ 1 \gamma ^ 2 \gamma ^ 3 ( \gamma ^ 0 ) ^ 2 )   = 0
\end{align*}
We've used liberally here the fact that 
\[
 \gamma ^ \mu \gamma ^ \nu = - \gamma ^ \nu \gamma ^ \mu \text{ when } \nu \neq \mu 
\] For the second relation, we use this fact as well. 
Note that when we pass a $ \gamma ^ j  $ matrix
past $ n $ matrices $ \gamma ^ i $ where $ i $ never equals
$ j  $, we pick up a factor of $ ( - 1) ^ n $. 
Thus, note that $ ( \gamma ^ 5 ) ^ 2$ is just 
\begin{align*}
	( \gamma ^ 5) ^ 2 & = i^ 2 \gamma ^ 0 \gamma ^ 1 \gamma ^ 2 \gamma ^ 3 \gamma ^ 0 \gamma ^ 1 \gamma ^ 2 \gamma ^ 3 \\
			  &=  ( - 1) ^ 4 \gamma ^ 1 \gamma ^ 2 \gamma ^ 3 \gamma ^ 1 \gamma ^ 2 \gamma ^ 3  \\
			  &=  ( - 1) ^ 3 \gamma ^ 2 \gamma ^ 3 \gamma ^ 2 \gamma ^ 3  \\
			  &=  ( - 1) ^ 4 I  = I 
\end{align*} 
\end{proof}
\end{claim}
Now, we can write out $ \gamma ^ 5 $ explicitly 
depending on the representation we choose. 
We check that in our chiral representation, 
\[
	\gamma ^ 5 = \begin{pmatrix}  - I & 0 \\ 0 & I  \end{pmatrix} 
\] We define projection operators in the spirit of 
finding a way to extract the left-handed and right-handed spinors 
from the entire spinor. We define  
\[
	P _ L = \frac{1}{2 } ( I _ 4 - \gamma ^ 5 ) , \quad P _ R = \frac{1}{2 } ( 1 + \gamma ^ 5 ) 
\] These obey the properties that come with what 
we usually know as a projection operator, namely, 
that projecting twice is the same as projecting once, 
and that $ P_ L $ and $ P _ R $ project onto 'orthogonal' 
spaces 
\[
 P_ L ^ 2 = P_L , \quad P _ R ^ 2 = P _ R , \quad P _ L P _ R = 0 
\] We then define 'left handed' and 'right handed' spinors
$ \psi _ L $ and $ \psi_ R $, 
which are the projection spinors with these operators 
\[
 \psi _ L = P_L \psi , \quad \psi _ R = P _ R \psi 
\] for left handed and right handed spinors respectively. 
Under a Lorentz transformation, 
\[
	\overline{ \psi } ( x) \gamma ^ 5 \psi ( x) \to \overline{ \psi } ( \Lambda ^{ - 1} x ) 
	S [ \Lambda ] ^{ - 1} \gamma ^ 5 S [ \Lambda ] \psi 
\] Checking that $ [ S_{ \mu\nu } , \gamma ^ 5 ] $, we have that 
this is 
\[
	\dots = \overline{ \psi } ( \Lambda ^{ -1 } x ) \gamma ^ 5 \psi ( \Lambda ^{ - 1} x ) 
\] This is called a pseudoscalar since it transforms under 
parity transformation. We can also define the axial vector, $ \overline{ \psi } \gamma ^ 5 \gamma ^ \mu 
\psi $ which transforms in the same way. 

\subsection{Parity} 
We'll now explore how spinors transform under discrete 
transformations. We'll look at a specific class of transformations 
which flips either our time coordinate or our spatial coordinate. 
The transformations are called parity transformations. 
Ultimately, we'll find that 
$ \psi _ L $ and $ \psi _ R $ are related by a parity trasnformation. 
In the Lorentz group $ O ( 1, 3 ) $, we've 
dealt with boosts and rotations, which are a continuous 
group of transformations. However, there are other discrete Lorentz transformations 
which are not part of the Lorentz group's component connected to the identity. 
These transformations are  
\[
 \text{Time Reversal } T : x ^ 0 \to  - x ^ 0 , \quad x ^ i \to x ^ i 
\] The other one is parity. 
\[
 \text{Parity } P : x ^ 0 \to x ^ 0 , \quad x ^ i \to  - x ^ i 
\] Other transformations like  $x ^ 2 \to - x ^ 2 $
are connected to the identity, because something like this can 
be written as a rotation. 
Under $ P $, rotations don't change sign, but 
boosts do. 
\[
 u_{ L , R } \to e^{ \phi \cdot  \sigma / 2} u_{ L , R }, \quad 
 u _{ L, R } \to e^{  \mp \chi \cdot  \sigma / 2} u_{ L, R }
\] This is equivalent to writing, 
in our new notations with $ \psi _{ L , R }  = \frac{1}{2 } ( I \mp \gamma ^ 5 )  \psi $, 
that  $ P $ exchanges LH and RH spinors. 
\[ 
	P : \,  \psi_{ L , R } ( \vec{x} , t ) \to \psi_{ R, L } ( - \vec{x} ,  t) 
\] Since our parity transformation switches around 
the left and right handed components of the spinor, it is 
completely equivalent to applying the $ \gamma ^ 0 $ matrix to the spinor, 
(but also we have to remember to change the $ \vec{x} $ sign) 
\[
	P : \,  \psi ( \vec{x}, t ) \to \gamma ^ 0 \psi ( - \vec{x}, t ) 
\]
How do our terms in our $\mathcal{ L } $ density change? We look at each field one 
by one 
Firstly, 
\[
	\overline{ \psi } \psi ( \vec{x}, t) \to \overline{ \psi } \psi ( - \vec{x}, t ) 
\] Also, 
\[
	\overline{\psi } \gamma ^ \mu \psi ( \vec{x}, t ) \to \begin{cases}
		\mu = 0 & \overline{ \psi } \gamma ^ 0 \psi ( - \vec{x}, t ) \\
		\mu = i & \overline{ \psi } \gamma ^ 0 \gamma ^ i \gamma ^ 0 \psi ( -\vec{x}, t ) 
		= - \overline{ \psi } \gamma ^ i \psi ( - \vec{x}, t ) 
	\end{cases}
\] On the other hand, we have that under parity, 
\[
	\overline{ \psi } \gamma ^ 5 \gamma ( \vec{x}, t ) \to \overline{ \psi } \gamma ^ 0 \gamma ^ 5 \gamma ^ 0 
	\psi ( - \vec{x}, t ) = - \overline{ \psi } \gamma ^ 5 \psi 
\] In addition, 
\[
 \overline{ \psi } \gamma ^ 5 \gamma ^ \mu \psi \to \overline{ \psi } \gamma ^ 0 \gamma ^ 5 \gamma ^ 0 \psi 
  = \begin{cases}
	  \mu = 0 &  - \overline{ \psi } \gamma ^5 \gamma ^ 0 \psi \\
	  \mu = i & + \overline{ \psi } \gamma ^5 \gamma ^ i \psi 
  \end{cases}
\] To summarise, 
we write down the number of components as
\begin{equation}
\begin{aligned}
	\overline{ \psi } \psi &1\\
	\overline{ \psi } \gamma ^ \mu \psi &4\\
	\overline{\psi } S^{ \mu \nu } & 6\\
	\overline{\psi } \gamma ^  5 \psi & 1\\
	\overline{\psi } \gamma ^ 5 \gamma ^ \mu \psi & 4\\ 
\end{aligned} 
\end{equation}this has a total of $ 16 $ components. 
Now we add extra terms to $ \mathcal{ L } $ involving $ \gamma ^ 5 $. This 
can break $ P $ invariance. For example, 
\begin{equation*}
		\mathcal{ L }  = g  W_ \mu \overline{\psi} \frac{ \gamma ^ \mu ( 1 - \gamma ^ 5 ) \psi }{ 2}
\end{equation*}
This represents a $ W $ boson vector field coupling only to LH $\psi$ ' s. 
If $\mathcal{ L }$ treats $\psi _ L$ and $\psi _ R$ equally it is called vector like. 
If they appear differently they're called chiral. 

\subsection{Symmetries and Currents of Spinors} 
If we have a space time translation $x ^ \mu \to x ^ \mu - \epsilon ^ \mu $, 
then  $ \Delta \psi  = \epsilon ^ \mu \partial  _ \mu \psi $. This 
gives us the stress energy tensor 
\[
 T ^{ \mu \nu }  = i \overline{ \psi } \gamma ^ \mu \partial  ^ \nu \psi - \eta ^{ \mu \nu } \mathcal{ L }
\] We get a conserved current when equations of motion 
are obeyed, do we can impose them in $ T ^{ \mu \nu } $. 
\[
	\mathcal{ L } _ D = \overline{ \psi } \left(  
	i \slashed{\partial} - m \right)  \psi  = 0 
\] This implies $ \mathcal{ L }  = 0 $ in $ T ^{ \mu \nu } $ thus 
\[
 T ^{ \mu \nu } = i \overline{ \psi } \gamma ^ \mu \partial  ^ \nu \psi 
\] 
\[
	S = \int  d^ 4 x \frac{1}{ 2 } \overline{ \psi } \left(  i \slashed{\partial}^{ \rightarrow}
	- m \right)  \psi + \frac{1}{2 } \overline{ \psi } ( - i \slashed{\partial} ^{ \leftarrow } - m ) \psi 
\] This is 
\[
	\int d ^ 4 x \frac{1}{2 } \overline{ \psi } ( i \slashed {\partial} ^{ \leftrightarrow} - 2m ) \psi 
\]  where $\slashed{\psi} ^{ \leftrightarrow }  = \slashed{\partial} ^ \rightarrow - \slashed{\partial} ^ 
\leftarrow $. So
\[
	T ^{ \mu \nu }  = \frac{ i }{ 2} \overline{ \psi } ( \partial  ^ \mu \partial  ^ \nu - \partial  ^ \nu \partial  ^ \mu ) \psi 
\]
\subsection{Lorentz transformations} 
We know how a spinor is supposed to transform. 
We have that infinitesimally, 
\[
	\psi \to S [ \Lambda ] \indices{ ^ \alpha _ \beta }  \psi ^ \beta  ( x ^ \mu - \omega  \indices{ ^ \mu _ \nu} x ^ \nu )  
\] where we have that $ \omega  $ is generated as 
\[
\omega \indices{ ^ \mu _ \nu } =  \frac{1}{2 } \Omega_{ \rho \sigma } ( M ^{ \rho \sigma } )\indices{ ^ \mu _ \nu }  
\] Since we defined earlier that 
\[
( M ^{ \rho \sigma } ) \indices{ ^ \mu _ \nu } = \eta ^{ \rho \mu } \delta \indices{ ^ \sigma _ \nu }
 - \eta ^{ \sigma \mu } \delta \indices{ ^ \rho _ \nu } 
\] This implies that $ \omega ^{ \mu \nu } = \Omega ^{ \mu \nu } $. 
Our infinitesimal change in our spinor is 
\[
\delta \psi ^ \alpha    = i \omega ^{ \mu \nu }  \left[ 
x ^ \nu \partial  _ \mu \psi ^ \alpha  - \frac{1}{2 }  ( S ^{ \rho \sigma } ) \indices{ ^ \alpha 
_ \beta } \psi ^ \beta  \right] 
\] Our corresponding conjugate change is 
\[
\delta \overline{ \psi } _ \alpha  = 
- \omega ^{ \mu \nu } \left[  x _ \nu \partial  _ \mu \overline{\psi }_ \alpha 
+ \frac{1}{2 } \overline{\psi } ( S_{ \mu \nu } ) \indices{ ^ \beta _ \alpha }  \right]  
\] where the last term comes from $ \overline{\psi }_ \beta  S [ \Lambda ] ^{ - 1} $. 
Our conserved current 
\[
( J ^ \mu ) ^{ \rho \sigma }  = x ^ \rho T ^{ \mu \sigma } - x ^ \sigma T ^{ \mu \rho }  - i 
\overline{ \psi } \gamma ^ \mu S ^{ \rho \sigma } \psi 
\] THe first term looks like a real scalar stress energy tensor. 
The new piece will give us spin $ \frac{1}{2 } $ after we quantise the
field. 
For example, looking at the last term $ ( J ^ 0 ) ^{ ij }  =  -i \overline{ \psi } \gamma ^ 0 S ^{ ij } \psi$. 
Using the representation in Pauli matrices, 
we get that the above is equal to 
\[
( J ^ 0 ) ^{ ij }  = \frac{1}{2 } \epsilon ^{ ijk  } \psi ^ \dagger 
\begin{pmatrix}  \sigma ^ k & 0 \\ 0 & \sigma ^ k  \end{pmatrix} \psi  
\] 
\subsection{Internal vector symmetry} 
We get that under the phase rotation 
\[
\psi \to e^{ i \alpha } \psi \implies \delta \psi  = i \sigma \psi 
\] This gives us a conserved quantitiy 
\[
j ^{ \mu _ \nu }  = \overline{ \psi } \gamma ^ \mu \psi \text{ a vector current }
\] This gives us the conserved charge 
\[
Q = \int d^ 3 x \, \overline{\psi } \gamma^ 0 \psi  = \int d ^ 3 x \, \psi ^ \dagger \psi 
\]  in other words, an electric charge. 

\subsection{Axial Symmetry} 
For massless spinors in the $ m = 0 $ limit, 
we transform 
\[
\psi _{ \alpha } \to \left(  e ^{ i \alpha \gamma ^ 5 }  \right) \indices{ _ \alpha ^ \beta }
\psi _ \beta 
\] This rotates left handed and right handed spinors in the 
opposite direction. This leads to 
the conserved axial vector current 
\[
j _ A ^ \mu  = \overline{ \psi  } \gamma ^ \mu \gamma ^ 5 \psi 
\] 

\subsection{Plane-Wave Solutions}
Now, let's actually start writing down solutions to the 
Dirac equation. 
We want to solve $ ( i \slashed{\partial}  -m ) \psi = 0 $. 
Even though this is a first order differential equation 
and typically we wouldn't think of using wave solutions, 
we try this anyway and make the ansatz 
\[
\psi = u_{ \vec{p} } e ^{ - i p \cdot  x }
\] where $ u _{ \vec{p} }  $ is a constant spinor 
depending on $ \vec{p} $ . 
Substituting this in, using the chiral representation
of $ \gamma ^ \mu $, we have that 
\[
( \gamma ^ \mu p _ \mu - m ) u _{ \vec{p} }  = 0  = 
\begin{pmatrix}  - m & p _ \mu \sigma ^ \mu \\ p _ \mu \overline{ \sigma } ^ \mu 
& - m  \end{pmatrix} u _{ \vec{p} }  =0 
\] Here, we are again using 
our notation that $ \sigma^ \mu = ( 1 , \sigma ) $, and $ \overline{ \sigma } ^ \mu  = ( 1 , - \sigma ) $. 

\begin{claim}{(The Spinor plane-wave solution)}
	
\end{claim}
Our claim is that we have a solution 
given by 
\[
u _{ \vec{p} }  = \begin{pmatrix}  \sqrt{ p \cdot  \sigma }  \xi \\
\sqrt{ p \cdot  \overline{ \sigma } }  \xi \end{pmatrix} 
\] for any two component spinor $ \xi $ such that $ \xi ^ \dagger \xi = 1 $. 
To prove this, we let  $ u _ { \vec{p} } = ( u _ 1, u _ 2 ) $, and 
substitute into the above such that 
\[
( p \cdot  \sigma ) u _ 2 = m u _1 , \quad ( p \cdot  \overline{ \sigma } ) u _ 1 
 = m u _ 2 
\] Either of these equations implies the other, since 
\begin{align*}
( p \cdot  \sigma ) ( p \cdot  \overline{ \sigma } ) &=  
p_0^ 2 - p _ i p _ j \sigma ^ i \sigma ^ j \\
&=   p_0 ^ 2  - p _ i p_ j \frac{1}{2 } \left\{  \sigma ^ i , \sigma ^ j  \right\}  \\
&=  p _\mu p ^ \mu   = m ^ 2  
\end{align*}

Now, we try the ansatz $ u _ 1 = ( p \cdot  \sigma ) \xi $ for the 
two component spinor $ \xi ' $. 
Substituting this into the above, 
we have that 
\[
u _ 2 = \frac{1}{m} ( p \cdot  \overline{ \sigma } ) ( p \cdot  \sigma ) \xi = m \xi ' 
\] Hence, 
any vector of the form $ u _{ \vec{p} }  = A ( ( p \cdot  \sigma ) \xi ' , m \xi ' ) $. 
To make this look more symmetric, choose $ A = \frac{1}{m } $  and 
$ \xi '  = \sqrt{ p \cdot  \overline{ \sigma } }  \xi $  with $ \xi $ const. 
Then, we have that 
\[
u _{ \vec{p} }  = \begin{pmatrix}  \sqrt{ p \cdot  \sigma }  \xi \\
\sqrt{ p \cdot  \overline{ \sigma }   } \xi  \end{pmatrix}  
\]  
Examples. Let's take $ \mathbb{p } = 0$, then we have 
that our solution looks like 
\[
u_{ \vec{p} = 0 }  = \sqrt{ m }  \begin{pmatrix}  \xi \\ \xi  \end{pmatrix} \text{ for any } \xi 
\] Under spatial rotations, we have that 
\[
\xi \to e ^{ i \sigma \cdot  \phi  / 2 } \xi 
\] After quantisation, $ \xi $ describes the spin of the spinor. 
For example, we have that 
\[
\xi = \begin{pmatrix}  1 \\ 0  \end{pmatrix}  \text{ represents spin up along } x ^ 3 \text{ axis }
\] Let's consider a particle boosted along the $ x ^ 3 $ direction. 
Now, the momentum is not going to be zero. 
Now what we have is that 
\[
u_{ \vec{p} }  = \begin{pmatrix}  \sqrt{ E - p ^ 3 }  \begin{pmatrix}  1 \\ 0  \end{pmatrix} 
\\ \sqrt{ E + p_3 }  \begin{pmatrix}  1 \\ 0  \end{pmatrix}  \end{pmatrix} 
\] which, in the $ m \to 0 $ or $ E \to p^ 3 $ limit, converges to 
\[
\sqrt{ 2 E }  \begin{pmatrix}  0 \\ 0 \\ 1 \\ 0  \end{pmatrix} 
\] Now, with instead $ \xi  = \begin{pmatrix}  0 \\ 1  \end{pmatrix}  $, 
when we act on this we instead get that 
\[
u _{ \vec{p} }  = \begin{pmatrix}  \sqrt{ E + p^ 3 }  \begin{pmatrix}  0 \\ 1   \end{pmatrix}  \\
\sqrt{ E - p ^ 3 }  \begin{pmatrix}  0 \\ 1  \end{pmatrix}  \end{pmatrix} 
\] which tends to 
\[
\sqrt{2 E }  \begin{pmatrix}  0 \\ 1 \\ 0 \\ 0  \end{pmatrix} 
\]
\subsection{Helicity}

The Helicity operator projects angular momentum 
along the direction of motion. 
If we define 
\[
h = \hat{\vec{p} } \cdot  \vec{s}  = \frac{1}{2 } \hat{ p } _ k 
\begin{pmatrix}  \sigma ^ k & 0 \\ 0 & \sigma ^ k  \end{pmatrix} 
\] A massless spin up operator has $ h = \frac{1}{2 } $, and a massless spin down 
particle has $ h = - \frac{1}{2 } $. 

\subsubsection{Negative frequency solutions} 
If we define $ \psi  = v _{ \vec{p} } e ^{ i p \cdot  x } $. 
The Dirac equation then gives 
\[
v_{ \vec{p} }  = \begin{pmatrix}  \sqrt{ p \cdot  \sigma }  \eta \\
- \sqrt{ p \cdot  \overline{ \sigma }  } \eta  \end{pmatrix} 
\] where we have as well that $ \eta ^ \dagger \eta  = 1 $ and $ \eta $ 
is a constant 2 -spinor. 

\subsection{A canonical Basis for normalised Spinors} 
In what follows, we'll construct a basis 
for the two component spinors in a way such that 
some nice identities will hold when we're doing calculations. 
It will be convenient for us to choose the basis 
\[
	\xi ^ 1  = \eta ^ 1 = \begin{pmatrix}  1\\ 0  \end{pmatrix} , 
	\quad \xi ^ 2 = \eta ^ 2 = \begin{pmatrix}  0 \\ 1  \end{pmatrix} 
\] This gives us the sweet property that these 
things are normalised, so 
\[
 ( \xi ^ r ) ^ \dagger \xi ^  s =  \delta ^{ r s }, \quad 
 ( \eta ^ r ) ^ \dagger \eta ^ s = \delta ^{ r s }
\] In this basis, we then get 
two independent solutions for both $ u(\vec{p} ) $ 
and $ v ( \vec{p} ) $, which 
we will index as $ u ^ s ( \vec{p} ) $ and $ v ^ s ( \vec{p}  ) $. 
We get these solutions by just plugging in $ \xi ^ s $ or $ \eta ^ s $
into the respective spinors -  these linearly independent solutions are given by 
\[
	u ^ s (\vec{p} )  = \begin{pmatrix}  
	\sqrt{ p \cdot  \sigma }  \xi \\ \sqrt{ p \cdot  \overline{ \sigma } }  
\xi \end{pmatrix}, \quad v ^s ( \vec{p} ) = \begin{pmatrix}  
\sqrt{ p \cdot  \sigma }  \eta \\  - \sqrt{ p \cdot  \overline{\sigma}}  \eta \end{pmatrix}
\]  The neat thing is that, now with our 
choice of basis for the two component spinors, 
we get that $ u ^ s $ and $ v ^ s $ are themselves 
normalised depending on how we contract them. 
We can contract them in two ways. 
The first thing that we can do is take the hermitian 
dot product, so something like $ u^{ s \dagger  } u ^ r $. 
Secondly, we could've also equally defined $ \overline{ u } ^ s  = u^{ s \dagger } \gamma ^ 0 $, and we also check the normalisation 
$ \overline{ u } ^ s u ^ r $. It turns out, both 
will be useful. 

Let's do the first contraction. 
\begin{align*}
	u^{ s \dagger } u ^ r &=  \begin{pmatrix}  \xi^{ s \dagger } \sqrt{ p \cdot  \sigma } & \xi ^{ s \dagger } \sqrt{ p \cdot  \overline{ \sigma } }   \end{pmatrix} 
	\begin{pmatrix}   \sqrt{ p \cdot  \sigma }  \xi ^{ r  } \\
	\sqrt{ p \cdot  \overline{ \sigma } }  \xi ^{ r } \end{pmatrix} \\
	&=  \xi ^{ s \dagger } ( p \cdot  \sigma ) \xi ^{ r } 
	+ \xi ^{ s \dagger } ( p \cdot  \overline{ \sigma } ) \xi ^{ r } \\
	&=  2p_0 \xi ^{ s \dagger } \xi ^ r  \\ 
	&=  2 p_0 \delta ^{ rs  } 
\end{align*}
We can see clearly that this is 
not a necessarily Lorentz invariant 
contraction since $ p_0 $ changes under boosts. 
Now, lets do the other type of contraction which 
is indeed Lorentz invariant! We have that 
\begin{align*}
	\overline{u }^{ s \dagger } u^ r &= \begin{pmatrix}  
		\xi ^{ s \dagger } \sqrt{ p \cdot  \sigma }  & 
\xi ^{ s \dagger } \sqrt{ p \cdot  \overline{ \sigma } }  \end{pmatrix} 
\begin{pmatrix}  0 & I \\ I & 0  \end{pmatrix}  \begin{pmatrix} 
\sqrt{ p \cdot  \sigma }  \xi ^ r \\ \sqrt{ p \cdot  \overline{ \sigma } }  \xi ^ r 
\end{pmatrix} \\
		   &=  2 \xi ^{ s \dagger }  \sqrt{ ( p \cdot  \sigma   ) 
		   ( p \cdot  \overline{ \sigma   } ) }   \\
		   &=  2m \delta ^{ r s }  
\end{align*}
In the above we've used the relation we proved 
earlier that $ ( p \cdot  \sigma ) ( p \cdot  \overline{ \sigma } )  = m ^ 2 $. 

Now, what about the 'negative frequency' spinors 
$ v ^ s ( \vec{p} ) $? 
Well, it is easy to also check that these spinors
obey similar normalisation conditions, up to 
a minus sign. 
\[
 v ^{ s \dagger} v ^ r = 2 p_0 \delta ^{ rs } , 
 \quad \overline{ v }^{ s } v ^{ r }  =  - 2m \delta ^{ rs }
\] 
Finally, something we will also have to use 
frequently in the coming section is 
the 'outer product' of the spinors. 
In this case, instead of doing a dot product, 
we sum over the spinors in the other way round 
to create a matrix.

\begin{claim}{(Outer products of spinors)}
	We have that the outer products of the two spinors 
	$ u ^ s ( \vec{p} ) $ and $ v ^s ( \vec{p} ) $ satisfy 
	\[
		\sum_{ s= 1 , 2 } u^ s ( \vec{p} ) \overline{ u } ^ s ( \vec{p} )  =
		\slashed{p} + m 
	\] And similarly, we have that our 
	negative frequency solution acts somewhat in a conjugate fashion, 
	with 
	\[
		\sum_{ s = 1, 2 } v ^ s ( \vec{p} ) \overline{ v } ^ s ( \vec{p} )  = 
		\slashed{p} - m 
	\]
\begin{proof}
	Proving this is just a simple matter 
	of writing out the definitions, and using 
	the fact that the outer product $ \xi ^ s \xi^{ s \dagger }$ and 
	$ \eta ^{ s } \eta ^{ s \dagger } $
	is just the identity matrix. 
	Similarly, we have that for $ v ^ s ( \vec{p} ) \overline{v} ^{ s  } ( \vec{p} )  $, 
	we get that
	\[
		v^ s ( \vec{p} ) = \begin{pmatrix}  \sqrt{ p \cdot  \sigma }  
		\eta ^ s \\  - \sqrt{ p \cdot  \overline{ \sigma } }  \eta ^ s 
	\end{pmatrix} , \quad \overline{ v } ^ s ( \vec{p} ) 
	= \begin{pmatrix}  - \eta ^{ s \dagger } \sqrt{ p \cdot  \overline{ \sigma } } & 
	\eta ^{ s \dagger } \sqrt{ p \cdot  \sigma }  \end{pmatrix} 
	\] Now, doing the outer product and summing over $ s $ gives
	\begin{align*}
		\sum_{ s } v ^ s ( \vec{p} ) 
		\overline{ v } ^ s ( \vec{p} )  &=  \sum_{ s } 
		\begin{pmatrix}   - \sqrt{ p \cdot  \sigma }  \eta ^ s 
		\eta ^{ s \dagger } \sqrt{ p \cdot  \overline{ \sigma } }  & 
	\sqrt{ p \cdot  \sigma }  \eta ^ s \eta ^{ s \dagger  } \sqrt{ p \cdot  \sigma }  \\
	\sqrt{ p \cdot  \overline{ \sigma } }  \eta ^ s \eta ^{ s \dagger } \sqrt{ p \cdot  \overline{ \sigma } }  & - \sqrt{ p \cdot  \sigma }  \eta ^ s \eta ^{ s \dagger } \sqrt{ p \cdot  \overline{ \sigma } }  \end{pmatrix}  \\
														   &=  \begin{pmatrix}  - m I & p \cdot  \sigma \\
														   p \cdot  \overline{ \sigma } &   -mI  \end{pmatrix}  \\
	\end{align*}
	Now, with the observation that $ \slashed{p} = \gamma ^ \mu p _ \mu $, which is 
	\[
		\slashed{p} = \begin{pmatrix}  0 & p \cdot  \sigma \\
		p \cdot  \overline{ \sigma } & 0 \end{pmatrix}  
	\] we are left with the result that 
	\[
		v ^ s ( \vec{p} ) \overline{ v }^ s ( \vec{p} ) = \slashed{p} - m  
	\] where the $ - m $ is implicitly multiplied by the 
	identity matrix. 
\end{proof}
\end{claim}


\subsection{Quantising the Dirac field}
In conclusion, we've found two 
plane wave solutions of the Dirac equation, which, for 
cleanliness, we will write as 
$ u ^ s (\vec{p} )  $ and $ v ^s ( \vec{p} )$. 
Recall, the $ s $ index let's us choose between 
$ \xi ^ 1  $  or $ \xi ^ 2 $ in the definition $ u^ s ( \vec{p} )$, 
or $ \eta ^ 1 $ or $ \eta ^ 2 $ in the definition of $  v ^ s ( \vec{p} ) $.  
When we take these solutions and write them out 
in Fourier modes, we have that 
\begin{align*}
\psi ( \vec{x} ) &=  \sum _{ i = 1 } ^ 2 
\int \frac{ d^ 3 p }{ ( 2 \pi ) ^ 3 \sqrt{ 2 E_{ \vec{p} } }  } \left[  
b_{ \vec{p} } ^ s u _{ \vec{p} } ^ s e ^{ i \vec{p} \cdot  \vec{x} } 
+ c_{ \vec{p} } ^{ s \dagger } v_{ \vec{p} } ^ s e ^{ - i \vec{p} \cdot  \vec{x}}\right] \\
\psi ^ \dagger ( \vec{x} ) &=  \sum _{ i = 1 } ^ 2 
\int \frac{ d ^ 3 p }{ ( 2 \pi ) ^ 3 \sqrt{ 2 E _{ \vec{p} } }  } \left[  
	b_{ \vec{p} } ^ { s \dagger }  u_{\vec{p} } ^{ s \dagger } e ^{ - \vec{p} \cdot  \vec{x} } + 
c_{ \vec{p} } ^ s v_{ \vec{p}} ^{ s \dagger } e ^{ i \vec{p} \cdot  \vec{x} } \right] \\ 
\end{align*}
Analogous to our previous case in 
nucleon anti-nucleon quantisation, we have that
$ b_{\vec{p} }^ s $  and $ b_{\vec{p} } ^{ s \dagger } $ 
represent the annihilation and creation 
operators for $ u( \vec{p} ) ^ s $, and that $  c_{ \vec{p} } ^ s , 
c_{ \vec{p} } ^{ s \dagger } $  represent annihilation 
and creation for $ v ^ s ( \vec{p} ) $. 
In spinor quantisation, it turns out that we require 
anti commutations relations instead of commutation relations, with 
\[
\left\{  A, B  \right\}   = AB + B A 
\] We'll go into more detail about why we 
need anti-commutation relations later, 
but for now just acknowledge that this is due to the fact that 
if we were to impose commutation relations, 
we'll come across the problem of unbounded negative energy. 
The specific anti-commutation relations are:  
\[
\left\{  \psi _ \alpha ( \vec{x} ) , \psi _ \beta ( \vec{y} )  \right\}   = 0 
= \left\{  \psi _{ \alpha } ^ \dagger ( \vec{x} ) , \psi _{ \beta } ^ \dagger 
( \vec{y} ) \right\}  , \quad \left\{  \psi _ \alpha ( \vec{x} ) , 
\psi _{ \beta }^\dagger ( \vec{y} ) \right\}  = \delta _{ \alpha \beta } \delta ^ 3 ( \vec{x} - \vec{y} ) 
\]
In the same vein as the case we 
had with scalar fields and nucleons, 
we construct a set of commutation relations on 
the creation and annihilation operators
which are logically equivalent to our anti-commutation 
relations. We can prove that these are equivalent to 
\[
\left\{  b_{ \vec{q} } ^ r , b _{ \vec{q} } ^{ s \dagger }  \right\}  = 
( 2 \pi ) ^ 3 \delta ^ 3 ( \vec{p} - \vec{q} ) \delta ^{ rs }  = \left\{  c_{ \vec{p} } ^ r , 
c _{ \vec{q} } ^{ s \dagger }\right\} 
\]
To show that this is true, we'll do just one direction 
and check that our anti-commutation relations hold true. 

To show this, observe that 
\begin{align*}
	\left\{  \psi , \psi ^ \dagger  \right\}  &=  \sum_{ r, s } \int 
	\frac{ d ^ 3 p d ^ 3 q }{( 2 \pi )^{6 }  2 \sqrt{ E_{ p } E_{q }  }  } 
	\left[  \left\{  b _{ \vec{p} } ^{ s } , b _{ \vec{q} } ^{ r \dagger }  \right\}  
	u _{ \vec{p} } ^{ s } u _{ \vec{q} } ^{ r \dagger } e ^{ i \cdot  ( \vec{p} \cdot  \vec{x}  - \vec{q} \cdot  \vec{y}}
 + \left\{  c_{\vec{p} } ^{ s \dagger } , c_{\vec{q} } ^{ r }  \right\}  v _{ \vec{p} } ^ s v _{ \vec{q} } ^{ r \dagger } 
 e ^{ - i ( \vec{p} \cdot  \vec{x} - \vec{q} \cdot  \vec{y} ) }\right] \\
 &= \sum_{ r, s } \int \frac{d ^ 3 p d ^ 3 q}{ ( 2 \pi )^{ 6 }  2 \sqrt{ 
 E_ p  E_ q } } \left[  ( 2 \pi )^{ 3 }  \delta _{ rs } \delta ( \vec{p} - \vec{q} ) 
 u_{ \vec{p} } ^{ s } u _{ \vec{q}  } ^{ r \dagger } e ^{ i ( \vec{p} \cdot  \vec{x} - \vec{q} \cdot  \vec{y} ) } +  ( 2 \pi )^{ 3 }  \delta _{ rs } \delta ( \vec{p} - \vec{q} ) v _{ \vec{p} } ^{ s } v _{ \vec{q} } ^{ r \dagger } e ^{ - i ( \vec{p} \cdot  \vec{x} - \vec{q} \cdot  \vec{y}}\right] \\
  &=  \sum _ s \int \frac{d ^ 3 p  }{ ( 2 \pi )^{ 3 }  2 E _ p } \left[  
  u _{ \vec{p}  } ^{ s } \overline{u} _{\vec{p} } ^{ s } \gamma ^ 0 e ^{ i \vec{p} \cdot  ( \vec{x} - \vec{y} ) } 
   + v_{ \vec{p} } ^{ s } \overline{v}_{ \vec{p} } ^{ r } \gamma ^ 0 e ^{  -i \vec{p} \cdot  ( \vec{x} - \vec{y} ) }\right]  \\
  &=  \int \frac{ d ^ 3 p  }{ ( 2 \pi )^{ 3 }  2 E_{p } } \left[ ( 
  \slashed{p} + m  ) \gamma ^ 0 e ^{ i \vec{p} \cdot  ( \vec{x} - \vec{y} ) }
   +  ( \slashed{p} -m ) \gamma ^ 0  e ^{  -i \vec{p} \cdot  ( \vec{x} - \vec{y}) } \right]  \\
   &=   \int \frac{ d ^ 3 p  }{ ( 2 \pi )^{ 3 }  } 
   \frac{ m }{ E_{ p }  } e ^{ i \vec{p} \cdot  ( \vec{x} - \vec{y} ) }\\
   &=  \int \frac{ d ^ 3 p  }{ ( 2 \pi )^{ 3 }  E_{ p }  } \left[  
   ( \gamma ^ 0 p ^ 0 - \gamma ^ i p _ i + m ) \gamma ^ 0 e ^{ i \vec{p} \cdot  ( \vec{x} - \vec{yu} ) }
    + ( \gamma ^ 0 p ^ 0 + \gamma ^ i p ^ i - m ) \gamma ^ 0 e ^{ i \vec{p} \cdot  ( \vec{x} - \vec{y} ) }\right]  \\
   &=  \delta ( \vec{x} - \vec{y} )  \\
\end{align*}
Going into the second last line, we switched the 
3 momentum variable $ \vec{p} \to  - \vec{p} $ in the second term. 
Going into the last line, we also used the fact that $ ( \gamma ^ 0 ) ^ 2  =1 $. 

We have that in the last line, since our measure 
is Lorentz invariant, we boosted into 
the rest frame so that $ m $ cancels with $ E_{ p }  $. 


We do the Legendre transform to 
get our Hamiltonian density. It's easy to 
see that our conjugate momenta $ \pi $ is 
$ \pi = i \psi^{ \dagger } $. This means that 
our Hamiltonian looks like 
\begin{align*}
\mathcal{ H } &=  \pi \dot{ \psi }  - \mathcal{ L }   \\
&=  i \psi ^ \dagger \dot{ \psi }  - i \overline{ \psi } \gamma ^ 0 \partial  _ 0 
\psi - i \overline{ \psi } \gamma ^ i \partial  _ i \psi + m \overline{ \psi } \psi \\
&=  \overline{ \psi }( - i \gamma ^ i \partial  _ i + m ) \psi  
\end{align*}
By the way, one needs to be careful that 
the index $ i $ here only sums over the spatial 
derivatives (this makes sense since the 
Hamiltonian shouldn't be time independent anyway 
since it's a conserved quantity). 
If we plug in $ \psi , \overline{ \psi } $ from the above, 
we use anti commutation relations and some reuslts on inner 
products of spinors to get that 
\[
u _{ \vec{p} } ^{ r \dagger } u _{ \vec{p} } ^ s  = 
v_{\vec{p} } ^{ r \dagger } v _{ \vec{p} } ^ s  = 2 p_0 \delta ^{ rs } , \quad 
u_{\vec{p} } ^{  r\dagger } v_{\vec{p} } ^ s = 0 = v_{ \vec{p} } ^{ r \dagger  } u_{ \vec{p} } ^ s 
\] 
This means that for our Hamiltonian, 
we fortunately get a positive definite quantity
\[
H = \int \frac{ d^ 3 p }{ ( 2 \pi ) ^ 3 } E _ p \sum_{ s = 1 } ^ 2 
\left(  b_{ \vec{p} } ^{ s \dagger  } b _{ \vec{p} } ^ s 
+ c _{ \vec{p} } ^{ s \dagger } c _{ \vec{p} } ^ s \right) 
\] To derive this, the best way to go about doing this 
is to look at the operator $ \left( - i \gamma ^ i \partial _ i   - m  \right)  $
on $ u ^ s ( \vec{p} )  $ and $ v ^ s ( \vec{p} )  $.
Due to Dirac's equation, we eliminate these 
things in favour of $ \gamma ^ 0 p _ 0 $, 
and then use this to find what the above is. 
Then we substitute that back into our expression for $ H$. 

If we used commutation relations, we get a minus sign which means that we 
have unbounded lower energy and therefore unstable theory.

\subsection{The Dirac Hole Interpretation}
We can write the Dirac equation as 
\[
i \frac{\partial  \psi }{\partial  t }   = 
( - i \alpha \cdot  \nabla + m \beta ) \psi , \quad \alpha =  - \gamma ^ 0 \gamma , \beta = \gamma ^ 0 
\] The term in the brackets is considered as 
the 1-particle Hamiltonian $ \hat{ H } $. 
This has positive and negative energy solutions. 
There's no consistent way of realising the 
Dirac equation to one particle states.

\subsection{Fermi-Dirac Statistics} 
We expanded our spinor field with operators $ b  $ and $ c $, which 
had a spin index. These operators annihilate the vacuum 
\[
b_{ \vec{p} } ^ s \ket{ 0 }  = 0 =  c_{ \vec{p} } ^ s \ket{ 0 } 
\] Recall that these operators obey anti-commutation relations. 
We can check that these commute with the Hamiltonian as follows 
\begin{align*}
[ H , b_{ \vec{p} } ^{ r \dagger } ] &=  E _p b _{ \vec{p} } ^{ r \dagger }  , \quad \left[  H , b_{ \vec{p} } ^{ r  }  \right]  =   - E _ p b_{ \vec{p} } ^ r   \\
\left[  H, c _{ \vec{p}}^ r   \right]   = - E _{ \vec{p} } c _{ \vec{p} }^ r \quad  \left[  H , c_{\vec{p} } ^{ r \dagger }  \right]   = E_{ \vec{p} } 
c_{\vec{p} }^{ r \dagger }
\end{align*}
If we index this state, for example, as $ \ket{ \vec{p} _ 1, r _ 1 } : = b_{ \vec{p} _ 1 } ^{ r _ 1 \dagger } \ket{ 0 }  $. 
Then the anti-commutation relations give us a sign change when 
we swap two things around. In particular, 
we have that 
\[
\ket{ \vec{p} _ 1 , r _ 1 ; \vec{p} _ 2 , r _ 2 } =  - \ket{ \vec{p} _ 2 , r _ 2 ; \vec{p} _ 1 , r _ 1 } 
\]  You can check this yourself.  

\subsubsection{Going into the Heisenberg picture}
To study propagators in the theory, 
we make the operators $ \psi $ and $ \overline{ \psi } $ time 
dependent by moving into the Heisenberg picture. 
Now, we have a time dependent operator $ \psi ( x) $ satisfying 
$ \frac{\partial  \psi }{\partial  t }  = i \left[  H , \psi  \right]   $ 
which is solved by the Heisenberg picture expansion 
\[
\psi _ \alpha ( x ) = \sum_{ s = 1 } ^ 2 \int \frac{ d ^ 3 p }{ ( 2 \pi ) ^ 3 \sqrt{ 2 E _ p }  } \, 
\left(  b^ s _{\vec{p} } u_{ \vec{p}_ \alpha } ^s e^{ - i p \cdot  x } 
+ c _{\vec{p} } ^{ s \dagger } v_{\vec{p} _ \alpha } ^ s e ^{ i p \cdot  x } \right)  
\] with an analogous expression for $ \psi_ \alpha ^ \dagger $. Honestly, 
the only thing we're doing here is 
attaching a time dependence to the exponential 
previously. Now, we are in a 
position to define the Feynman propagaator 
but in the case of these fermionic fields. 
We then define, in analogy with $ \Delta ( x -y )  = \left[  \phi ( x) , \phi ( y )  \right]  $, 
that for $ \mathbb{ R }$ scalars, 
\[
i S_{ \alpha \beta } ( x  - y )  = \left\{  \psi _ \alpha ( x ) , \overline{ \psi } _ \beta ( y )  \right\} 
\] where $ S _{ \alpha \beta } $ is a four by four matrix. 
For brevity, we'll now drop the $ \alpha , \beta $ for brevity. 
Substituting in our results from previously, 
we have that 
\[
i S ( x - y ) = \sum_{ r, s } \int \frac{ d ^ 3 p d ^ 3 q  }{ ( 2 \pi ) ^ 6 \sqrt{ 4 E_ p E _ q }  } 
\left[  \left\{  b_{ \vec{p} } ^ s , b_{ \vec{q} } ^{ r \dagger }  \right\} e ^{  - i ( p \cdot  x  - q \cdot  y ) }
u_{ \vec{p} } ^ s \overline{u } _{ \vec{q} } ^ r + 
\left\{  c_{\vec{p} } ^{ s \dagger } , c _{\vec{q} } ^{ r } \right\}  v _{ \vec{p} } ^ s 
\overline{ v } _{\vec{q} } ^{ r } e ^{ i ( p \cdot  x - q \cdot  y ) } \right] 
\]
The anti commutators in this expression yield 
delta functions. So, this simplifies to the expression 
\[
i S_{ \alpha \beta } ( x -y )  = \int \frac{d ^ 3 p }{ ( 2 \pi ) ^ e 2 E_ p } 
\left[  \sum _s u_{ \vec{p} _ \alpha } ^ s \overline{ u } _{ \vec{p} _ \beta } ^ s 
e ^{ - i p \cdot  ( x - y ) } + \sum _ s v_{ \vec{p} _ \alpha } ^ s 
\overline{ v } _{ \vec{p} _ \beta } ^ s e ^{ i p \cdot  ( x  -y ) }\right] 
\] Earlier we showed that the outer products 
of the spinors $ u $ and $ v $ summed 
over the spin indices give $\slashed{p} + m $ and $ \slashed{p} - m $. 
This thing then simplifies to 
\[
= \left(  i \slashed{\partial } _ x + m   \right)  D ( x - y )  - \left(  i 
\slashed{\partial} _ x + m \right)  D ( y - x )  = \left(  i \slashed{\partial} _ x 
+ m \right)  \left(  D ( x - y ) - D ( y  - x)  \right) 
\] 
Note that for $ ( x - y ) ^ 2 < 0 $, we have that $ D ( x - y ) - D ( y - x) =0  $. 
We now have $ \left\{  \psi _ \alpha ( x) , \overline{ \psi  }_ \beta ( y )  \right\}   = 0\forall ( x - y ) ^ 2 < 0 $. 
So what about causality? Our observables are bilinear in fermions. 
They do commute at space-like separations so the theory is causal. 

Away from singularities, we have that 
\begin{align*}
( i \slashed{p} _ x - m ) i S ( x - y ) &=  0  \\ 
		&=  ( i \slashed{\partial} _ x - m ) 
		( i \slashed{\partial}  + m ) \left[ D ( x - y )  - D ( y - x )  \right]  \\
		&=  - ( \partial _ x ^ 2 + m ^ 2 ) \left[  D ( x -y )  - D( y - x)  \right]  \\
		&= 0 \text{ using } p ^ \mu p _ \mu  = m ^ 2
\end{align*}

\subsubsection{The Feynman Propagator} 
A similar calculation gives us us that 
the two point propagator between $x $ and 
$ y $ are 
\begin{align*}
\bra{ 0 } \psi _ \alpha ( x) \overline{ \psi } _ \beta ( y ) \ket{ 0 } &=  \int \frac{ d ^ 3 p }{ ( 2 \pi ) ^ 3 
2 E _ p } ( \slashed{p} + m ) _{ \alpha \beta } e ^{  - i p \cdot  ( x - y ) } \\
\bra{ 0 } \overline{\psi } _{ \beta } ( y ) \psi _ \alpha ( x ) \ket{ 0  } &=  
\int \frac{ d ^ 3 p }{ ( 2 \pi ) ^ 3 2 E _ p } ( \slashed{p}  - m )_{ \alpha \beta } e ^{ i p \cdot  ( x - y ) }\\
\end{align*}
If we define $ S _{ F \alpha \beta }  = \bra{ 0 } T \psi _{ \alpha } ( x) \overline{ \psi } _{ \beta } ( y ) \ket{ 0 } $
as the object 
\[
\begin{cases}
\bra{ 0 } \psi _ \alpha ( x) \overline{ \psi } _ \beta ( y ) \ket{ 0 } & x ^ 0 >  y ^ 0 \\
- \bra{ 0 }{ \overline{ \psi } _ \beta ( y ) \psi _ \alpha ( x ) \ket{ 0 }  & y ^ 0 } x ^ 0 
\end{cases} 
\]
The negative sign in the second term is required 
for Lorentz invariance when $ ( x  -y ) ^ 2 < 0 $, since 
there exists no Lorentz invariant way to determine whether $x ^ 0 < y ^ 0 $ 
or the other way around. 
In this case, $ \left\{  \psi ( x) , \overline{ \psi } ( y )  \right\}   = 0 $ and 
so $ T $ as defined is lorentz invariant. 
This is the same for strings of fermionic operators in $T $  - they anti commute. 
We see the same behaviour for normal ordering, we get that 
\[
: \psi _ 1 \psi _ 2 : = - : \psi _ 2 \psi _ 1 : 
\]
We can define our Feynman propagator as 
\begin{equation*}  
\wick{ \c \psi ( x) \c \psi^*( y )} 
\end{equation*} 
From this we get that 
\[
T ( \psi ( x) , \overline{ \psi  }( y )  = : \psi ( x) \overline{ \psi ( y ) } 
\]
Our propagator before can be written as 
a 4-momentum integral, which bears resemblance to 
our propagator for scalar fields. 
\[
S _ F ( x - y ) = i \int \frac{ d ^ 4 p }{ ( 2 \pi )^{ 4 }  } \frac{e ^{  - ip \cdot  
( x -y ) } }{ p ^ 2 - m ^2 + i \epsilon } (\slashed{p} + m ) 
\] 
This propagator acts as a Green's function for the Dirac equation. 
Writing $\slashed{\partial} _ x $ to denote the derivative 
terms acting on $ x $, we have that 
\[
( i \slashed{\partial}_ x - m ) S_ F ( x- y ) = i \delta ^ 4 ( x- y ) 
\] As an example, let's look at 
Fermionic Yukawa theory. Our Lagrangian here looks like 
\[
\mathcal{ L } = \frac{1}{2 } \partial  _ \mu \phi \partial  ^ \mu \phi 
+ \frac{1}{2 } \mu ^ 2 \phi ^ 2 + \overline{ \psi } ( i \slashed{\partial} - m ) \psi 
- \lambda \phi \overline{ \psi } \psi 
\] We ask ourselves, is this 
theory normalisable? To answer this 
question, we need to figure out the mass dimension of 
our coupling constant $ \lambda $. A simple analysis of the mass dimension shows that 
$ [ \phi ] = 1 $, $ [ \psi ] = \frac{3}{2 }  = [ \psi ' ] $, which 
implies that $ [ \lambda  ]  = 0$. 
In the language of statistical 
field theory, we call this 
interaction term marginal. Thus, we have that our theory is renormalisable.

\begin{example}{(Nucleon to Nucleon scattering)}
Let's revisit our problem of 
nucleon to nucleon scattering, $ \psi \psi \to \psi \psi $ but treating 
are nucleons as fermions. Let's 
label our initial state as two nucleons with incoming momentum $ \vec{p}$  
and $ \vec{q}$, as well as spin indexes $ r $ and $ s$,  so that $ \ket{ i }  = \sqrt{ 4 E_{ p }  E_{ q }  } b_{\vec{p} } ^{ s \dagger } b_{ \vec{q} } ^{ r \dagger } \ket{ 0 } $. 
Similarly, we label $ \ket{ f} $ as the state $ \sqrt{ 4 E_{q' }  E_{ p ' }  }  b_{ \vec{p} ' } ^{ s ' \dagger } b_{ \vec{q} ' } ^{ r' \dagger } \ket{ 0 } $. 

This is shown in the following Feynman diagram 

\end{example}

\begin{equation*}
\feynmandiagram [small] {
a -- [fermion] b [blob]  
%c[particle = \( q , r \) ]  -- [fermion] b,
%b -- [fermion] d[particle = \( p ' , s' \) ],
%b --[fermion] e[particle = \( q', r'\) ], 
}; 
\end{equation*}
In computing the scattering amplitude, 
we'll need to take the Hermitian conjugate of 
$ \ket{ f } $, which is \[
\bra{ f }  = \sqrt{ 4 E_{ p' }  E_{ q' }  }  \bra{ 0 } b_{ \vec{q}'  }^ {r'} b_{ \vec{p}'  } ^{ s' }
\] We don't pick up a minus sign here - we have to be careful. 
This is because we are just taking the Hermitian conjugate. 
Let's look at $ O ( \lambda ^ 2) $ scattering 
terms from the fields in the interaction picture. 
Our only non zero contribution to second order is given by 
Wick's theorem 
\[
\bra{ f } : \overline{ \psi  } ( x_1 ) \psi ( x_1) 
\overline{ \psi } ( x_2 ) \psi ( x_2 ) 
\wick{ \c \phi ( x_1 ) \c \phi ( x_2) }  : \ket{ i } 
\] Since in this configuration, the $ \psi $ 's 
annihilate $ \ket{ i } $ and the $ \overline{ \psi } $'s
create $ \bra { f} $.
We'll now work on calculating the 
scattering amplitude we get from this 
problem.
The first step to do is to expand out 
$ \psi $ in terms of our creation and annihilation 
operators. This gives us that 
\begin{align*}
: \overline{ \psi } ( x_1 ) \psi ( x_1) \overline{ \psi } ( x_2 ) \psi ( x_2) : b ^{ s \dagger }_{ \vec{p} } 
b ^{ r \dagger } _{ \vec{q} } \ket{ 0 }   &=   - \int \frac{ d ^ 3 k_1 d ^ 3 k_2 }{ ( 2 \pi )^{ 6 }  } 
\left[  \overline{ \psi } (x_1 ) \cdot  u ^ m ( \vec{k} _ 1 ) \right] \left[  \overline{ \psi } \left( x_2  \right)  
\cdot  u ^ n ( \vec{k} _ 2) \right]  \\
&=  \frac{ e ^{ - i k_1 \cdot  x_1 - i k_2 \cdot  x_2 } }{ \sqrt{ 4 E_{k_1 }  E_{ k_2 }  }  }
b_{\vec{k}_ 1 } ^ m b _{ \vec{k} _ 2 } ^ n b _{ \vec{p} } ^{ s \dagger } b _{ \vec{q} } ^{ r \dagger } \ket{ 0 } 
\end{align*}
The terms in square brackets like 
$ \left[  \overline{ \psi } \left( x_1  \right)  \cdot  u ^m  \right] $
illustrate how we're summing over indices. 
Let's just be clear about what objects we're dealing with here. 
For any value of $ m $, $ u ^ n ( \vec{p} )$ is a 
four component object, and so are the spinors $\overline{ \psi } $, 
so we're taking the dot product here. We additionally need to sum 
over the values $ m  $ and $ n  $, for the different spins. 
Note that we also have an extra minus sign in the beginning 
because we need to commute $ \psi ( x_1) $ past $ \overline{\psi } ( x_2)  $, 
since we need to move the $ b_{\vec{k} _ 1 } $ past the $ b^\dagger $ 
operator nested in $ \overline{ \psi } ( x_2 ) $. 

The next mission is to commute the $ b $ operators 
past the $ b ^ \dagger $ operators.  We do this 
by looking at anti commutation relations. 
We have that 
\begin{align*}
b_{\vec{k} _  1 } ^ m b _{ \vec{k} _ 2 } ^ n b _{ \vec{p} } ^{ s \dagger } b _{ \vec{q} } ^{ r \dagger  } \ket{ 0 } 
&=  \left( \delta_{ mr } \delta _{ n s} \delta ( \vec{k} _ 2 - \vec{p} ) \delta (\vec{k} _1  - \vec{q} ) 
- \delta _{ nr  } \delta _{ ms  } \delta \left( \vec{k} _ 1 - \vec{p}  \right)  \delta ( \vec{k} _2  - \vec{p} ) \right) \ket{ 0 }   \\
\end{align*}
When we integrate over the delta functions, 
we have that the above expression 

\begin{align*}
= \frac{ - 1 }{2 \sqrt{ E_{ p }  E_{ q }  }  } ( \left[ \overline{ \psi } ( x_1 ) \cdot  u ^ r ( \vec{q} )  \right] &  
\left[  \overline{ \psi } ( x_2 ) \cdot  u ^ s ( \vec{p} )  \right]  e ^{  - p \cdot  x_2 - i q \cdot  x_1 } \\
												    &  - \left[  \overline{\psi } ( x_1 ) \cdot  u ^ s ( \vec{p} )  \right]  \left[  \overline{ \psi } ( x_2 ) \cdot  u ^ r ( \vec{q} )  \right]  e ^{  -i p \cdot  x_1  - i q \cdot  x_2 } ) \ket{ 0 } 
\end{align*}
Now, we contract this with $ \bra { f } $. We'll go slow 
and just do one term first. For the first term 
in our expression, we get, writing out $ \bra{ f} $ explicitly, 
the term 
\[
\bra{ 0 } b _{ \vec{q} ' }^{ s ' } b _{ \vec{p}' } ^{ s ' } 
\left[  \overline{ \psi } ( x_1 ) \cdot  u ^ r ( \vec{q} )  \right]  \left[  \overline{ \psi } ( x_2 ) \cdot  u ^ s ( \vec{p} )  \right] \ket{ 0 } 
\] Now, ignoring $ c $ operators again, we bring out the $ b ^\dagger $  operators 
which come from $ \overline{ \psi } $ in the expansion. 
This gives us a string of $ b $ operators on the left, which leaves
the above expression as 
\[
= \frac{ e ^{ i p ' \cdot  x_1 + i q ' \cdot  x_2  } }{ 2 \sqrt{ E_{ p'  }  E_{ q ' } } } \left[ 
\overline{ u }^{ s ' } ( \vec{p} ' ) \cdot  u ^{ r } ( \vec{q} ) \right]  \left[  
\overline{ u } ^{ r ' } \left(  \vec{q} '  \right)  \cdot  u ^{ s } ( \vec{p} ' ) \right]  
- \frac{ e ^{ i p ' \cdot  x_2 + i q' \cdot  x_1 } }{2 \sqrt{ E_{ p' }  E_{ q' }  }  } \left[  
\overline{ u } ^{ r'} \left(  \vec{q} '  \right)  \cdot  u ^ r \left( \vec{q}  \right)  \right]  
\left[  \overline{ u } ^{ s ' } \left( \vec{p} '  \right)  \cdot  u ^ s ( \vec{p} )  \right]  
\] By symmetry, the second term in our expression 
also gives the same contribution. 
Including the relativistic normalisation 
from the $ \ket{ i } $ and $ \ket { f} $ states, 
our final expression for our scattering amplitude is, 
including the expression for our contraction $ \contraction{}{\phi ( x_1 ) }{}{\phi ( x_2) } \phi ( x_1 ) \phi ( x_2 ) $, 
is given by 
\begin{align*}
( - i \lambda ) ^ 2 \int \frac{ d ^ 4 x_1 d ^ 4 x_2 d ^ 4 k }{ ( 2 \pi )^{ 4 }  } \frac{i e ^{ ik \cdot  
\left(  x_1 - x_2  \right)  } }{ k ^ 2 - \mu ^ 2 + i \epsilon } & ( \left[  
\overline{ u } ^{ s ' } ( \vec{p} ' ) \cdot  u ^ s ( \vec{p} ) \right]  \left[  \overline{ u } ^{ r'  } \left( \vec{q}'   \right) \cdot  
u ^{ r } ( \vec{q} ) \right]  e ^{ i x_1 \cdot  ( q' - q ) + i x_2 \cdot  ( p' - p )  } \\
						& - \left[  \overline{ u } ^{ s' } \left( \vec{p}'  \right)  
						\cdot  u ^{ r } ( \vec{q} ) \right]  
						\left[  \overline{ u } ^{ r'} ( \vec{q} ) 
						\cdot  u ^ s ( \vec{p} ) \right]  
						e ^{ i x_1 \cdot  \left( p ' - q  \right)   + i x_2\cdot  
						\left( q' - p  \right)  } ) 
\end{align*} 
After integrating over $ x_1 $ and $ x_2 $, we can extract our 
scattering amplitude from the 
formula $ \bra{ f } S - 1 \ket{ i }  = i \mathcal{ M } ( 2 \pi )^{ 4 }  \delta ^ 4 ( p +  q - p ' - q' ) $. 
Once we do this, our scattering amplitude is given by 
\[
\mathcal{ M } = \left( i \lambda  \right) ^ 2 
\left( \frac{\left[  \overline{ u } ^{ s ' } ( \vec{p} ' ) \cdot  u ^{ s } ( \vec{p}  )  \right]  \left[ 
\overline{  u } ^{ r' } ( \vec{q} ' ) \cdot  u ^{ r } ( \vec{q} ) \right]  }{ \left( p ' - p  \right)  ^ 2 
- \mu ^ 2 +  i \epsilon }  - \frac{ \left[  \overline{ u } ^{ s ' } \left( \vec{p} '  \right) \cdot  u ^ r ( \vec{q} )  \right] \left[ 
\overline{ u } ^{ r' } ( \vec{q} ' ) \cdot  u^ s ( \vec{p} ) \right]   }{ ( q' - p ) ^ 2  - \mu ^ 2 + i \epsilon } \right) 
\] 

\subsection{Momentum Space Feynman Rules for Fermion Amplitudes} 
We are now in a good position to guess the 
Feynman rules for fermions. We can use our intuition to guess these rules.
Compared to momentum space Feynman rules for scalar fields, 
we need to attach a spin as well as a momentum 
for each incoming line. The factor we attach is a spinor. 

\begin{itemize} 
\item From our amplitude above, it's clear that incoming particle with momentum $ \vec{p}$
	and a given spin $ s $ contributes a 
$ u ^ s ( \vec{p} ) $ spinor to our amplitude. Similarly, outgoing particles 
contribute with spin $ r $ and momentum $ \vec{p} $ contribute a $ \overline{ u }^ r ( \vec{p} )  $
spinor factor. 

\begin{equation*}
\feynmandiagram[small, horizontal  = a to b ]{ 
	a[particle = \( u ^ r ( p ) \) ] -- [fermion, momentum = \( p \) ] b, 
b --[fermion] c, 
b -- [scalar] d
}; \quad \quad  
\feynmandiagram[small, horizontal  = b to d]{ 
a -- [fermion] b, 
c -- [scalar] b, 
b -- [fermion, momentum = \( p \) ] d [particle = \( \overline{ u } ^ r(\vec{p} )  \) ], 
}; 
\end{equation*}
\item This is flipped when we consider anti-fermions. For an incoming particle, 
	we associate the opposite frequency 
	spinor $ \overline{ v } $ and for outgoing particles 
	we associate the spinor $ v $. For anti-fermions
of momentum $ p $ and spin $ r $, we associate the spinor 
$ \overline{v} ^ r ( \vec{p} ) $ for ingoing particles. For outgoing 
particles, we associate the spinor $ v ^ r ( \vec{p} ) $. 
\begin{equation*}
	\feynmandiagram[small, horizontal = a to b ]{
		a[particle = \( \overline{v } ^ r ( p ) \) ] -- [anti fermion, momentum = \( p \) ]b, 
		b -- [anti fermion] c, 
		b -- [scalar] d,
	}; \quad \quad 
\feynmandiagram[small, horizontal  = b to c]{
	a  -- [anti fermion] b, 
	b -- [anti fermion, momentum  = \( p \) ] c [particle = \( v ^ r ( \vec{p} ) \) ] ,
	c -- [scalar] b, 
}; 
\end{equation*}
\item For vertices in our Feynman diagram, we attach a factor $ \left( - i \lambda  \right)  $ 
\item For each internal line, for scalars, we attach our standard 
propagator 
\begin{equation*}
\feynmandiagram[small, horizontal  = a to b ]{
	a -- [scalar, momentum = \( \vec{p} \) ] b, 
}; = \frac{i }{ p ^ 2  - \mu ^ 2  + i \epsilon }, \quad \quad  
\feynmandiagram[small, horizontal = a to b ]{ 
	a -- [fermion, momentum = \( \vec{p} \) ] b, 
};  = \frac{ i \left( \slashed{p} + m ^ 2   \right)  }{ p ^ 2 - m ^ 2 + i \epsilon }
\end{equation*}	
Importantly, we have that fermion lines 
need to move consistently throughout the diagram. 
This reflects fermion number conservation.
\item Since we're attaching spinors, which are vectors, 
	to the external legs in the diagram, we need a sensible 
	way to turn these into a number which represents the probability. 
	This is simple, all we do is contract the spinors which 
	join at a vertex. 
\item As before, we need momentum conservation at each vertex. 
Propagators with undetermined momenta require an 
integral over their momentum. 
\item The difference with drawing diagrams 
for fermions versus scalar particles, is 
that we need to take into account fermion statistics when 
we switch around legs in fermion diagrams. 
\end{itemize} 

\begin{example}{(Nucleon scattering Fermion diagrams)} 
At first order, our possible diagrams 
for nucleon to nucleon scattering are given 
below. 
\begin{figure}[htpb]
	\centering
	\input{nucleon-feynman.pdf_tex}
	\caption{The Feynman diagram associated with nucleon to nucleon scattering. 
	Notice that we have Fermi-Dirac statistics, so our switching of momentum 
leads to a minus sign picked up in the amplitude. }%
	\label{fig:}
\end{figure}
We read of the associated amplitude from this Feynman diagram 
to get 
\[
	\mathcal{ M } = ( - i \lambda ) ^ 2 \left( 
	\frac{\left[  \overline{ u } ^{ s' } ( \vec{p} ' ) \cdot  u ^ s ( \vec{p} )  \right] \left[ 
\overline{ u } ^{ r' } \left( \vec{q} '  \right)  \cdot  u ^ r (\vec{q} ) \right]  }{ \left( p - p '  \right)  ^ 2 - \mu ^ 2 } 
 - \frac{ \left[  \overline{ u } ^{ s' } \left( \vec{p} ' \right)  \cdot  u ^ r ( \vec{q} )  \right] \left[ 
		 \overline{ u } ^{ r' } ( \vec{q} ') \cdot  u^{ s } ( \vec{p} )  \right]  }{  \left( p - q'  \right)  ^ 2 
 - \mu ^ 2 }\right)  
	\] 
	Let's justify this 
	picture and the terms in it. In the first diagram, 
	we have two fermions for the top vertex - one going in and 
	one going out with momenta $ \vec{p} $ and $ \vec{p} ' $ 
	and these are contracted together. 
	In addition, we have on the bottom vertex 
	momenta $ \vec{q} $ and  $ \vec{q} ' $, and 
	we contract the spinors associated with these in a similar fashion. 
\end{example}

\begin{example}{(Fermionic loops contribute a minus sign)} 
It doesn't matter so much for scalar fields, 
but we need to remember minus signs when dealing with diagrams.
Fermionic loops contribute a minus sign 
to our overall amplitude. We 
can see this in the following fermionic loop
\begin{equation*}
	\feynmandiagram[small]{ 
		a -- [scalar] b, 
		b -- [fermion, half left] c -- [fermion, half left] b, 
		c -- [scalar] d,
	}; 
\end{equation*}
Let's label the left vertex $ x $ and the right vertex $ y $. 
Our arrow pointing from $ x $ to $ y $ represents 
the contraction between $ \phi ( x)  $ and  $ \overline{ \phi } ( y ) $. 
The arrow pointing in the other direction represents 
a contraction from $ \phi ( y ) $ and $ \overline{ \phi } ( x) $. 
However, Wick's theorem gives us that our interaction term (without 
the contractions between $ \phi $ term s) is proportional to 

\begin{equation*}
	\wick{\c1   \psi ^ * _ \alpha ( x) \c 2 \psi _ \alpha ( x) \c 2 \psi ^ * _ \beta ( y ) \c 1 \psi \beta  ( y ) } 
\end{equation*}
\end{example} 
We have the following diagrams.   
The important thing 
is that operators need to remain the same order, unless 
we decide to anti-commute them and pick up a minus sign. 
Hence, for a closed fermionic loop which looks like 
$ :  \overline{ \psi } _ \alpha ( x) 
\wick{ \c \psi_ \alpha ( x) \c \psi ^ * _ \beta ( y )  } \psi _ \beta ( y )   : $
where we contract the middle two fields, 
to contract the other two fields we need to pick up a 
minus sign (show here). 

Question: what if $ \mathcal{ L } _{ \text{ int } }  = - \lambda \phi  \overline{ \psi }_ \alpha ( \gamma ^ 5 )_{ \alpha \beta } \psi _{ \beta } $  ? 
This interaction preserves parity if $ \phi $ is a pseudo-scalar, 
in other words 
\[
	P \phi ( \vec{x} , t )   = - \phi ( - \vec{x} , t  )
\] 
This interaction looks like the below (diagram here) 
this contributes $ ( - i \lambda ) ( \gamma ^ 5 )_{ \alpha \beta } $. 

\begin{example}{(Nucleon to Meson Decay)}
Now we study the amplitudes for the 
problem $ \psi \overline{ \psi } \to \phi \phi $. 
The key thing about this problem is to think about 
the statistics of the outgoing mesons. Since they're
Bosons, we don't get the minus sign from 
switching the legs like last time. 
We assign the momenta as shown in the figure. 
\end{example}
\subsection{Cross-Sections and Mod-squared expressions}
We want to calculate amplitudes and mod-squared 
expressions like $ | \mathcal{ M } | ^ 2 $ in this 
formalisation with fermions? We know 
how to do this in the case with scalar fields (
our scattering amplitude will depend on the ingoing and 
outgoing momenta), 
but we've yet do discuss how to do this when we've 
added different options for spin and so on. 
It turns out, probably for consistency purposes, is  
that the way people do this is to also 
formulate our scattering amplitude so that it also 
depends \textbf{just on initial and final momenta, and 
not spin}. The way we remove the dependence on spin 
is by averaging over the spins in the initial states, 
and summing over the spins in the final states. 
For example, if we consider the case of $ \psi \psi \to \psi \psi $ 
decay, we need to initialise a choice of spins $ r, s, s' , r' $ for each initial and final fermion
state. 
\begin{align*}
	\ket{ i }  &= \sqrt{ 4 E_{ \vec{q} } E _{ \vec{p} }  }  
	b_{ \vec{p} } ^{ r \dagger } b _{ \vec{q} } ^{ s \dagger } \ket{ 0 } \\
	\ket{ f } &=  \sqrt{ 4 E_{ \vec{q} ' } E _{\vec{p} ' } }  
	b_{ \vec{p} ' } ^{ s ' \dagger } b _{\vec{q} ' } ^{ r ' \dagger } \ket{ 0 } 
\end{align*}
Thus, we need find a scattering amplitude that's a function 
of the momenta $ p , q , p ' $ and $ q ' $ but not the spins? 

In most experiments, and in the formalisation that follows, we make the big assumption that 
the spin states of incoming particles $ \ket{ i } $ are randomly 
distributed. Then, because the incoming spin states are random 
and so we average over them. For example, for 
$ \psi \psi $, it would be $ \frac{1}{4 } \sum_{ r , s = 1 } ^ 2 $, 
since we average over all the possible pairs of 
$ \left( r, s   \right)  $ with the assumption 
that the probability of each pair is$ \frac{1}{4 }$ . 

Another reason we do this is that 
typically the spin states of the final state can't 
be measured, so we sum over these. 
\[
 \mathcal{ M } = B - A , \text{ in } \psi \psi \to \psi \psi 
\] where $ B , A $ are the different terms. 
We wrote appropriate spin sums averages with a line on top. 
\begin{align*}
	\overline{ | \mathcal{ M } | } ^ 2 &=  | \overline{ A } | ^ 2 
	+ | \overline{ B } | ^ 2 - \overline{ A ^ \dagger B } - 
	\overline{ B ^ \dagger A } \\
	A &=  \frac{\lambda ^ 2 \left[  \overline{u  }_{ \vec{p} ' } ^ s 
	\cdot  u_{ \vec{q} } ^ r  \right] \left[  
\overline{ u } _{ \vec{q} ' } ^{ r ' } \cdot  u_{ \vec{p} } ^ s \right]}{
\mu ^ 2- \mu ^ 2+ i \epsilon } \\
\end{align*}
Note that we have $ ( \gamma ^ 0 ) ^ \dagger  = \gamma ^ 0 $. 
 \[
	 | \overline{ A } | ^ 2 = \frac{ | \lambda | ^ 4  }{ 4 ( \mu ^ 2 - m ^ 2 ) ^ 2  } 
 \sum_{ r , s , s' , r ' } \overline{u }_{ \vec{p} ' _ \alpha } ^{ s ' } 
 u_{ \vec{q} _ \alpha } ^ r \overline{ u } _{ \vec{q} _ \beta } ^ r 
 u_{ \vec{p} ' _ \beta } ^{ s ' } \overline{u }_{ \vec{q} ' _ \beta } ^{ r ' } 
 u_{ \vec{p} _ \gamma } ^{ s } \overline{ u }_{ \vec{p} _ \delta } ^ s 
 u_{ \vec{q}' _ \delta } ^{ r ' }
\]  This 
is equal to 
\[
	\frac{ | \lambda |  ^ 4 }{ 4 } \frac{( \slashed{p}' + m)_{ \alpha \beta } 
	( \slashed{q} + m )_{ \beta \alpha } \tr \left[  
( \slashed{q}' + m ) (\slashed{p} + m )  \right] }{ ( \mu ^ 2 - m ^ 2 ) ^  2}
\] Often, we are in the high energy limit, 
where we may wish to neglect particle masses. In this 
case, we then find that 
\[	| \overline{ A } | ^ 2 = \frac{ | \lambda | ^ 4 \tr ( 
	\slashed{p} ' \slashed{q} ) \tr (\slashed{q} ' \slashed{p} ) }{4 \mu ^ 2 }
\] Similarly, we have that for $ | \overline{ B  } | ^ 2 $, 
we get that 
\[
 | \overline{ B } | ^ 2 = \frac{  | \lambda | ^ 2 }{ 4 t ^ 2 }
 \tr ( \slashed{q} ' \slashed{q} ) \tr ( \slashed{p} ' \slashed{p} ) 
\] We also want $  - \overline{ A ^ \dagger B  }  - \overline{ B ^ \dagger A }  = 
- 2 Re \overline{ ( A ^ \dagger B ) } $. 
We calculate this as 
\begin{align*}
	\overline{ A ^ \dagger B  } &  = \frac{ | \lambda | ^ 4 }{ 4 u t} 
	\sum_{ r , r' , s, s ' } \overline{u } _{ \vec{q} _ \beta } ^ r 
	u _{ \vec{p} ' _ \beta }^{ s' } \overline{ u } _{ \vec{p} _ \alpha } ^ s 
	u _{ \vec{q} ' _ \alpha } ^{ r '} \overline{ u } _{ \vec{q}' _ \gamma } ^{ r ' } 
	u_{ \vec{q} _ \gamma } ^ r \overline{ u } _{ \vec{p} ' _ \delta } ^{ s' } 
	u _{ \vec{p} _ \delta } ^ s \\
				    &=  \frac{|\lambda | ^ 2 }{ 4 ut } \tr \left(  
				    \slashed{p} \slashed{p} ' 
			    \slashed{q} \slashed{q}' \right)  \\
\end{align*} 

This gives us the Feynman rules 
for spin summed $ \mathcal{ M } ^ 2 $ diagrams. 
We have that complex conjugation switches $ \ket{ i } $ and 
$ \ket{ f } $ in the diagram. 
Fermion lines are joined with identical momentum on the LHS and RHS. 
Adter a spin sum, a closed fermion line in the $| \mathcal{ M } | ^ 2 $ diagram 
is given by a trace over $ \gamma $ matrices, with appropriate $\gamma ^ 5 $ ' s
etc in vertices at the correct posiition in the trace. trace follows 
fermion arrows backwards. 

IN nucleon to nucleon scattering, 
we have that 
\[
 | \mathcal{ M } | ^ 2 = \frac{| \lambda | ^ 2 }{ 4 } \left\{  
 \frac{\tr \slashed{q}\slashed{q}' \tr \left( \slashed{p} \slashed{p'} \right) }{t ^ 2 } + 
 \frac{ \tr \left( \slashed{q}' \slashed{p} tr\left( \slashed{p}' \slashed{q}  \right)  \right) }{u^ 2 }
  - \frac{2 R  \tr \left( \slashed{p} \slashed{p}' \slashed{q} \slashed{q}' \right) }{ ut }\right\} 
\] 
Using trace techniques from sheet three we can show that 
\[
 | \mathcal{ M } | ^ 2 = \frac{ | \lambda | ^ 4 }{4 } \left[ 
 \frac{ 4 q \cdot  q ' 4 p \cdot  p ' }{ t ^ 2 } + \frac{ 4 q ' \cdot  p 4 p ' \cdot  q }{ u ^ 2 }
   - \frac{8}{ut } ( p \cdot  q ' p ' \cdot  q + p \cdot  p ' q \cdot  q ' - p \cdot  q p' \cdot  q ' )\right] 
\] It's customary to 
express this in terms of $ s, t $ and $ u$. 
We have that, in the  $ m , \mu \to 0 $  limit, 
we get that 
\begin{align*}
	s & = ( p + q ) ^ 2  = ( p' + q ' ) ^ 2 \implies p \cdot  q  = p ' \cdot  q'  = \frac{s}{2 } \\
	t &=  ( p - p' ) ^ 2  = ( q - q ' ) ^ 2 \implies p \cdot  p ' = q \cdot  q ' =  - \frac{t}{2 }  \\
	u &=  ( p - q ' ) ^ 2  = ( q - p ' ) ^ 2 \implies p \cdot  q '  = q \cdot  p ' = - \frac{u}{2 }  
\end{align*}
This implies that 
\[
	| \mathcal{ M } | ^ 2  = | \lambda | ^ 4 \left\{  1 + 1  - \frac{1}{2 ut } \left( u ^ 2 + t ^ 2 - s ^ 2 \right)  \right\} 
\] Adding all the Mandelstam variables, so that 
\[
 s + t + u  = \sum m _ i ^ 2  \to 0 , \quad u = - s - t, \implies | \mathcal{ M } | ^ 2  = 3 | \lambda | ^  4
\] Going into the centre of mass frame, 
we have that 
\[
	\frac{ d \sigma  }{ dt } = \frac{ | \mathcal{ M } | ^ 2 }{ 16 \pi \lambda ( s, 0 , 0 ) }. \quad 
	\frac{dt }{ d \cos \theta } | _{ \text{ COM } }  = 2  |\vec{p} | | \vec{p} ' |  = \frac{ s}{2}
\] Writing out our solid angle $ \Omega$, we have that 
$ d \Omega= d \left( \cos \theta  \right)  d \phi $. 
This means that 
\[
 \frac{ d \sigma }{ d \Omega } |_{ \text{ COM } }  = \frac{ | \mathcal{ M } | ^ 2 }{ 64 \pi ^ 2 s }
\] We have identical particles in the final state. 
We integrate our final state angles over the hemisphere. 
This implies that our cross section is 
\[
 \sigma = \frac{ 3 | \lambda | ^ 4 }{ 32 \pi s }
\] This implies that $ \sigma > 0 $ even with negative quantum 
interference. This means that $ [ \lambda ] =0 $, which means 
that $ [ \sigma ]  = [ s ] ^{ - 1} = - 2$, which is an area. 
This means that everything is correct.

\section{Quantum Electrodynamics}
In this section, we'll first look at the 
reason why $ A ^ \mu $ has four components, 
but physically we have only two distinct polarisation states 
for a photon. 
In electromagnetism, our Lagrangian is given by 
\[
 \mathcal{ L } = - \frac{1}{4 } F_{ \mu \nu } F ^{ \mu \nu }, \text{ where } F_{ \mu \nu }  = \partial  _ \mu A _ \nu - \partial  _ \nu A _ \mu 
\]  is the field strength tensor. As we shown 
in general relativity, this Lagrangian is 
motivated by the fact that it's 
pretty much the only thing we can write down 
in four dimensional space time, given a 
two form $ F $. It comes 
from the action 
\[
 S = \int F \wedge  F 
\]  
Our Euler Lagrange equations read 
\[
	\partial  _ \mu \left( \frac{\partial  \mathcal{ L } }{\partial  ( \partial  _ \mu A _ \nu )  }   \right) =0  = \partial  _ \mu F ^{ \mu \nu } 
\] These are Maxwell's equations in vacua. 
This can be written in terms of our fields as 
\begin{align*}
	\vec{E} &=  - \nabla \phi  - \dot{ A }   \\ 
	\vec{B} &= \nabla \times A 
\end{align*}
Our sign convention is such that 
$ \nabla  = \left( \partial  _ x , \partial  _ y , \partial  _ z  \right) $, 
and $ A ^ \mu = \left( \phi , \vec{A} \right) $. 
From our definitions, we have that $ \vec{E} = \left( F_{ 01}, F _{ 02 },  F_{ 03} \right) 
 = \left(  - F ^{ 01 } , -  F^{ 02 } , - F ^{ 0 3}  \right)  $. 
 This equality comes from the fact that $ F _{ 0 i} = \partial  _ 0 A _ i - \partial  _ i A _ 0   $. 
 In addition, we also have that 
 for $ \vec{B} = \left( B _ 1 , B_2, B_3  \right)  $ gives 
 for example, $B _ 3 = \partial  _ 1 A ^ 2  - \partial  _ 2 A ^1 $. 
 Hence, 
 \[
	 F _{ \mu \nu  }  = \begin{pmatrix}  0 & E _ 1 & E_2 & E_3 \\ 
		 - E _  1 & 0 & - B _ 3 & B _ 2 \\ - E_ 2 & B _ 3 & 0 & - B _ 1 \\
		 - E _ 3 & - B _ 2 & B _ 1 & 0 
 \end{pmatrix}
 \]  
 Our field strength tensor satisfies the Bianchi identity, where 
 \[
  \partial  _ \lambda F _{ \mu \nu } + \partial  _ \mu F _{ \nu \lambda } + \partial  _ \nu F _{ \lambda \mu }  =0 
 \]  When we set $ \lambda = 3 , \mu = 1, \nu = 1 $, 
 we have the equation $ \nabla \cdot  \vec{B} = 0 $. 
 Similarly, we have that for $ \lambda = 0 $, $\mu = i , \nu  =j $  
 then for $ i \neq j $, we get that
  \[
  \dot{ B } =  - \nabla \times \vec{E} 
 \] Also, 
 \[
  \partial  _ \mu F ^{ \mu \nu }  = 0\implies \nabla \cdot  \vec{E} = 0 , \quad \vec{E} = \nabla \times \vec{B}
 \]
 The massless vector field $A_ \mu  $ satisfies 
 4 real degrees for freedom, $\mu = 0 , 1 , 2 , 3 $, but a photon $ \gamma $ 
 only has 2 polarisation states. 
 Note that $ A _ 0 $ is not dynamical - there is no kinetic term in $ \mathcal{ L }$. This means that in particular, our conjugate momentum $ \pi ^ 0  =0 $,
 and solving for the equations of motion we have that 
 \[
	 \frac{\partial  \mathcal{ L } }{\partial  A^ 0 }    =0  \neq \text{an 
	 explicit function of } t
 \] This means we can also sub-out $ A ^ 0 $ in favour of 
 the other degrees of freedom. 
 Given $A _ i ( \vec{x}, t ) $ and $ \dot{ A } _ i ( \vec{x}, t_0)   $, 
 we have that $A_0 $ is fully determined. 
 The constraint that $\nabla \cdot  \vec{E} = 0 $ implies that 
 \[
  \nabla ^ 2 A _ 0 + \nabla \cdot  \vec{A} = 0 
 \] This has solution 
 \[
	 A_0 ( \vec{x}, t_0 )  = \int d ^ 3 x ' \frac{ \nabla \cdot  \vec{A} ( \vec{x} ' , t_0 )  }{4 \pi | \vec{x} ' - \vec{x} | }
 \] where we have that 
 \[
	 \nabla ^ 2 \left( \frac{1}{| \vec{X} - \vec{x} ' |} \right)  = - 4 \pi \delta ^ 3 ( \vec{x} - \vec{x}' ) 
 \]
 In addition there is a large symmetry group 
 \[
	 A_ \mu ( x ) \to A_ \mu ( x) + \partial  _ \mu \lambda ( x) 
 \] where $ \lambda ( x) $ is some function such that 
 $ \lim _{ | \vec{x} | \to \infty} \lambda ( x ) \to 0 $. 
It's easy to show that $F _{ \mu \nu } $ is invariant under this transformation. 
This is a new kind of symmetry, viewed as a redundancy in the description. 
Observe that 
\[
 \eta_{ \mu \nu } \partial  _\rho F ^{ \rho \nu }  = 0 \implies \left[  
 \eta _{ \mu \nu } \partial  _ \rho \partial  ^ \rho  - \partial  _ \mu p_ \nu  \right]  A^ \nu  =0 
\] This operator, $ O _{ \mu \nu  } $  
is not invertible since it annihilates any function 
of the form $ \partial  ^ \nu \lambda ( x) $. 
There's no way to uniquely determine the evolution of $A_ \mu $ 
given $ A _ i , \dot{ A } _ i  $ at $t_0 $. We can't
distinguish between $A_ \mu $ and $A _ \mu + \partial  _ \mu \lambda $ 
which we identify as the same physical state. 
Below we have a diagram of gauge orbits in configuration space.
We choose one representation from each gauge orbit by cutting
 a slice. All states in on the orbit 
 are related to by a gauge transformation and so are physically equivalent. 
It doesn't matter which representative 
we choose from each, since they're all 
physically equivalent.
There are many possibilities, some of which make 
certain calculations easier.
Let's go through some examples of gauges. 
\begin{itemize}
	\item The Lorentz gauge $ \partial  _ \mu A ^ \mu = 0 $. 
		We can always pick a representative that 
		satisfies this. 
		Start with a field $ A _ \mu ' $ such that $\partial _ \mu A ^{' \mu }  = f ( x) $. 
		Then we choose $A _ \mu  = A _ \mu ' + \partial  _ \mu \lambda ( x) $ where 
		$ \partial  _ \mu \partial  ^ \mu \lambda ( x)  = - f ( x ) $, 
		which we can always solve. 
		This condition doesn't pick a unique representative 
		from the orbit, because we can make a further transformation 
		with $ \partial  _ \mu \partial  ^ \mu \lambda ( x) $ 
		which has non trivial solutions. The advantage 
		of this is that the gauge condition is Lorentz invariant. 
        \item The coulomb Gauge or radiation gauge. 
		Here we set $\nabla \cdot  A = 0 $, 
		which exists by an argument similar to the Lorentz gauge. 
		This means that $ A_0  = 0 $. The advantage 
		is that it's easy to see physical degrees of freedom. 
		We have three comonents of $\vec{A} $ satisfying a physical constraint, 
		leaving behind 2 physical degrees of freedom which are our polarisation states. 
\end{itemize}

\subsection{Quantisation of the Electromagnetic Field} 
We can quantise the field 
ay first looking at the conjugate momenta. 
\begin{align*}
	\pi ^ 0 &=  \frac{\partial  \mathcal{ L } }{\partial  \dot { A } }   =0  \\
	\pi ^ i &=  \frac{\partial  \mathcal{ L } }{\partial  \dot{ A } _ i }   = 
	 - \dot{ A} ^ i + \partial  ^ i A ^ 0  = F ^{ i 0 }  = E ^ i 
\end{align*}
Now, when we 
put this into the Hamiltonian, we find that our expression is 
\[
	\mathcal{ H }  = \int  d^ 3 x \left( \pi ^ i \dot{ A } _ i - \mathcal{ L }  \right)  
	= \int d ^ 3 x \frac{1}{2 } \left( | \vec{E} | ^ 2 + | \vec{B} | ^ 2  \right)   - A _ 0 \left( \nabla 
	\cdot  E \right)  
\]  now, the element $ A _ 0 $ acts as a Lagrange multiplier, which imposes 
the equation $ \nabla \cdot  \vec{E} = 0 $ (by the Euler Lagrange equations). 
Let's recall the classical dynamics interpretation of this 
To review this interpretation, check out David Tong's
notes on Classical Dynamics. 
Our form of the Hamiltonian above is 
reminiscent of the Lagrangian of a system 
with constraints given by $ f ^ i ( \vec{x} ^ a )   = 0 $. 
The Lagrangian looks like 
\[
	\mathcal{ L }  '  = \mathcal{ L } + \lambda_b f ^ b ( \vec{x} ^ a ) 
\]  Now, we identify $  A_ 0 $ with the Lagrange 
multiplier here, and view $ \nabla  \cdot  E  =0 $  as the constraint. 
Now that it's a constraint of a system, we can treat $ \vec{A} $ just as 
the physical degrees of freedom. 

\subsubsection{Coulomb Gauge}
In the Coulomb gauge, we're working with 
the condition that $ \nabla \cdot  \vec{A} =  0 $. 
From our discussion earlier, we 
learnt that we could substitute $ A ^ 0 $ in 
favour of  $ \vec{A} $ via the formula 
\[
	A ^ 0 (\vec{x} ) = \int d ^ 3 x' \frac{\nabla  \cdot \left(\frac{\partial  A }{ \partial  t } \left( \vec{x}  \right)    \right)  }{ 4 \pi | \vec{x} - \vec{x} ' | }
\] However, when we commute our time derivative 
operator with $ \nabla $, we simply get that 
the integrand is 0. Hence, we have that $ A ^ 0  = 0 $. 
Now, from our equation of motion, $ \partial  _ \mu F ^{ \mu \nu }  =0 $, 
we have that 
\begin{align*}
	\partial  _ \mu \left( \partial  ^ \nu A ^ \mu  - \partial  ^  \mu A ^ \nu  \right) &=  0  \\
	\partial  _ \mu \partial  ^ \nu A ^ \mu  - \partial  _ \mu \partial  ^ \mu A ^ \nu &=  0  \\ 
	\partial  ^ \nu \left( \dot{ A } ^ 0  - \nabla \cdot  A  \right)  - \partial  _ \mu \partial  ^ \mu A ^ \nu &=  0  \\ 
	\partial  _ \mu \partial  ^ \mu A^ \nu  &=  0  
\end{align*}
In the last line, we used the Coulomb gauge where $ \nabla \cdot  \vec{A} = 0 $ 
and also the fact that $ A ^ 0 $ was a constant. 

\subsubsection{Lorentz Gauge} 
We'll now work in the Lorentz gauge. 
The Lorentz gauge is what we get when we 
impose the condition $ \partial _ \mu A ^ \mu  = 0 $, 
which is different from the Coulomb gauge 
because this is a divergence in space-time.

This implies that the Maxwell's equations which we started with $ \partial  _ \mu F ^{ \mu \nu }  =0 $, 
becomes the relation 
\[
 \partial  _ \mu \partial ^ \mu A ^ \nu  =0 
\] We can view this from a 
different perspective, and construct a 
different Lagrangian where the Lorentz gauge 
is imposed from the equations of motion. 
To do this, we modify the Lagrangian and 
add an extra term, so that it becomes 
\[
	\mathcal{ L }  =  - \frac{1}{4 } F _{ \mu \nu } F ^{ \mu \nu }  - \frac{1}{2 } \left( \partial  
	_ \mu A ^ \mu \right)  ^ 2 
\] Note that this Lagrangian is no longer gauge invariant
under the gauge transformation of the field $ A ^ \mu \to A ^ \mu + \partial  ^ \mu \chi $. 
But, the upshot of 
writing our Lagrangian in this form
is that we get 
\[
	\partial  _ \mu F ^{ \mu \nu } + \partial  ^ \nu \left( \partial  _ \mu 
	A ^ \mu \right)   = 0 \iff \partial  _ \mu \partial  ^ \mu A ^ \nu  =0 
\] which is the condition we imposed before. 
We will now work with this new Lagrangian, 
only imposing $\partial  _ \mu A ^ \mu  =0 $ later, 
at the operator level. 
In general, we could've written a Lagrangian 
\[
	\mathcal{ L } =   - \frac{1}{4 } F _{ \mu \nu } F ^{ \mu \nu }  - \frac{1}{2 \alpha } \left( 
	\partial  _ \mu A ^ \mu \right)  ^ 2 
\] where this gives rise to a continuum 
of different theories. $ \alpha = 1 $ is called 
the Feynman gauge, and $ \alpha \to 0 $ is 
called the Landau gauge. 
For illustration purposes, we'll look at the Feynman gauge. 
Now, for $ \alpha =1 $, we have no gauge symmetry. 
But now, both $ A _ 0 $ and the variables $ \vec{A} $ are dynamical. 
We have that 
\[
	\pi ^ 0 = \frac{\partial  \mathcal{ L } }{\partial  \dot{ A } _ 0  }   =  - \partial  _ \mu A ^ \mu 
\]  and we also have that 
\[
	\partial  ^ i = \frac{\partial  \mathcal{ L } }{\partial  \dot { A} _ i }   = - \dot { A } ^ i + 
	\partial  ^ i A ^ 0 
\] We impose the commutation 
relations 
\[
	\left[  A _ \mu ( \vec{x} ) , A _ \nu ( \vec{y} )  \right]   = 0 
	= \left[  \pi _ \mu ( \vec{x} ) , \pi _ \nu ( \vec{y} )  \right]  
\] As well as a non-trivial commutation relation 
\[
	\left[  A _ \mu ( \vec{x} ) , \pi _ \nu ( \vec{y} )  \right]   = i \delta ^ 3 ( \vec{x} - \vec{y} ) 
	\eta _{ \mu \nu } 
\] We now expand our field $ A _ \mu ( \vec{x} ) $ in terms 
of this. 
\[
	A _ \mu ( \vec{x} )  = \int \frac{ d ^ 3 p }{ ( 2 \pi )^{ 3 }  \sqrt{2  | \vec{p} | }  } 
	\sum _{ \lambda = 0 } ^ 3 \left(  \epsilon _\mu ^ \lambda ( \vec{p} ) a _{ \vec{p} } ^ \lambda 
	e ^{ i \vec{p} \cdot  \vec{x} } + \epsilon _ \mu ^{ \lambda * } (\vec{p} ) a_{\vec{p} } ^{ \lambda \dagger } 
e ^{ - i \vec{p} \cdot  \vec{x} } \right) 
\] where $ \epsilon _ \mu ^{ \lambda = 0 , 1, 2, 3 } $ are four polairsation vectors. 
Similarly, we have that for our conjugate momentum 
\[
 \pi ^ \mu  = \int \frac{ d ^ 3 p  | \vec{p} | }{ ( 2 \pi )^{ 3 } \sqrt{ 2 } }  i 
 \sum _{ \lambda = 0 } ^ 3 \left( \epsilon ^{ \mu \lambda  }  ( \vec{p} ) a _{ \vec{p}  }^ \lambda 
 e ^{ i \vec{p} \cdot  \vec{l} } -  a _{ \vec{p} } ^{ \lambda * } e ^{ - i \vec{p} \cdot  \vec{x} } 
 \left( \epsilon^{ \mu * } ( \vec{p} )  \right)  ^ \lambda \right)  
\] In this formalisation 
we pick $\epsilon ^ 0 _ \mu $ to be timelike, and $\epsilon _ \mu ^ i $ to be timelike. 
We choose normalisation $\epsilon ^ \lambda  = \epsilon ^{ * \lambda }  = \eta ^{ \lambda \lambda ' } $ 
We choose $ \epsilon ^ 1 _ \mu $ and $\epsilon ^ 2 _ \mu $ to be transverse, 
in other words we have $ \epsilon ^ 1 \cdot  p = \epsilon ^ 2 \cdot  p = 0  $, 
and $\epsilon ^ 3 _ \mu $ to be our longitudinal polarisation. For
example, we take $ \gamma $ to be travelling in an $x ^ 3 $ direction. 
We set 
\[
	p ^  \mu  = | \vec{p} | \begin{pmatrix}   1 \\ 0 \\ 0 \\ 1  \end{pmatrix}  , \epsilon ^{ 0 \mu }  = 
	\begin{pmatrix}  1 \\ 0 \\ 0 \\ 0  \end{pmatrix}  , \epsilon ^{ 1 \mu }  = 
	\begin{pmatrix}  0 \\ 1 \\ 0 \\ 0  \end{pmatrix}  , \epsilon ^{ 2  \mu }  = \begin{pmatrix}  
0 \\0 \\ 1 \\ 0  \end{pmatrix}, \epsilon ^{ 3 \mu } = \begin{pmatrix}  0 \\0 \\ 0 \\ 1  \end{pmatrix} 
\] 

The relations above are equivalent to 
the creation operators with 
\[
 \left[  a _{ \vec{p}' } ^ \lambda , a _{ \vec{q} } ^ \lambda  \right]   =0 =
 \left[  a _{ \vec{p} } ^{ \lambda \dagger } , a _{ \vec{q} } ^{ \lambda ' \dagger }   \right]  
\] However, our non zero commutation relation is given by the following 
\[
 \left[  a_{\vec{p} } ^\lambda , a _{ \vec{q} } ^{ \lambda \dagger }  \right]   = 
 - \eta ^{ \lambda \lambda ' } \left( 2 \pi  \right) ^ 3 \delta ^ 3 ( \vec{p} - \vec{q} ) 
\] We're in a bit of trouble here since we have 
an minus sign in the commutation relation here! This is
okay for $ \lambda, \lambda '  = 1, 2, 3 $ due to 
the fact that the Minkowski metric is negative 
in these indices, 
but is unusual for time-like photons, as we will see now.  
We have that $ a _{\vec{p} } ^{ \lambda } \ket{ 0 }  =0  $ as usual. 
Now, as usual we have $ \ket{ \vec{p}, \lambda }  = a_{\vec{p} }^{ \lambda \dagger } \ket{ 0 } $
is fine for $\lambda = 1, 2, 3 $ but actually, we have that 
\[
	\bra{ \vec{p}, \lambda = 0 }\ket{ \vec{q}, \lambda = 0 }  = 
	\bra{ 0 } a_{\vec{p} } ^ 0 a _{\vec{q} } ^{ 0 \dagger } \ket{ 0 }  = - ( 2 \pi )^{ 3 } 
	\delta ^ 3 \left( \vec{p} -  \vec{q} \right) 
\] This is a negative norm state.!
A Hilbert space with a negative norm state is problematic, but the 
constraint equation comes to the rescue - so far we've yet 
to impose the equation $ \partial  _ \mu A ^ \mu  = 0$, 
so we expect this to restrict our Hilbert space and resolve this problem. 
We'll try to 
resolve the problem by trying out new definitions of what 
physical states actually could be. Working in 
the Heisenberg picture, we have that 
\begin{enumerate}
	\item $ \partial  _ \mu A ^ \mu  = 0 $ which doesn't work since $\pi ^ 0  = -\partial _ \mu A ^ \mu $ 
		so commutation relations couldn't be obeyed.
	\item Impose conditions on Hilbert space. We split the 
		state $\ket{ \phi } $. $ \partial  _ \mu A ^ \mu \ket{ \psi } $ 
		is too strong of a condition. 
		We split the integral up into two parts in the Heisenberg picture, into 
		a part that annihilates our vacuum state $ \ket{ 0 }  $ and 
		a part that doesn't. 
		We set
		 \begin{align*}
			 A^ +  _ \mu ( x )  &=  \int \frac{ d^ 3 p }{ \left( 2 \pi  \right)  ^ 3 \sqrt{ 2 | \vec{p} | } }  \sum_{ \lambda = 0 } ^ 3 \epsilon _{ \mu } ^{ \lambda } a _{ \vec{p} } ^ \lambda e ^{  - i p \cdot  x }\\ 
			 A ^ - _ \mu ( x) &=  \int \frac{ d ^ 3 p }{ \left(  2 \pi  \right)  ^ 3 \sqrt{ 2 | \vec{p} | }  } \epsilon_{ \mu } ^{ \lambda * } a _{ \vec{p} } ^{ \lambda \dagger } e ^{ i p \cdot  x  } 
		 \end{align*}
		 Notice that in this formalisation, we have that $ A ^ + _ \mu \ket{ 0 }  =0 $, 
		but unfortunately we have that $ \partial  ^ \mu A ^ - _ \mu \ket{ 0 }  \neq 0 $, 
		so we can conclude that this is not the right way to classify physical states, 
		since our vacuum state isn't even a physical state itself.
	\item The correct way to do this is to classify the physical states
		as states which satisfy the condition 
		\[
			\partial ^ \mu A _ \mu ^ + ( x) \ket{ \psi }  = 0
		\] This is the 'correct way' to  deliver the 
		condition that $ \partial _ \mu A ^ \mu = 0  $ 
		in the Lorentz gauge. We have that 
		for physical states $ \ket{ \psi } $ and 
		$ \ket{ \psi ' } $, we have that  $ \bra{ \psi ' }\partial  _ \mu A ^ \mu \ket{ \psi }  = 0$. 
		In addition, we have that $ \ket{ 0 } $ is also counted 
		as a physical state, so we don't have the 
		same problems which we encountered above. 
		Now, by linearity, we have that the linear span 
		of physical stated constitute a Hilbert space 
		themselves, which we denote as $ \mathcal{ H } _{ \text{phys } } $.
		So, this makes sense. 
\end{enumerate}
Since our operators $ a^ \lambda_{ \vec{p} } $  and 
$ a ^{ \lambda \dagger } _{ \vec{p} } $mutually commute, 
we can decompose the Fock space (the Hilbert space which is 
generated by applying the operators $ a^{ \lambda \dagger }$ to 
the vacuum state $ \ket{ 0 } $) into the direct sum of two states. 
We decompose the state 
\[
 \ket{ \psi } = \ket{ \psi _ T } \ket{ \phi } 
\] where $ \ket{ \psi _ T } $ is the subspace of states generated 
by applying the creation operators $ a ^{ 1, 2 \dagger } _{  \vec{p}}  $ to 
$ \ket{ 0 } $, and $ \ket{ \phi } $ is the 
space of states generated by applying $ a ^{ 0 , 3\dagger  } $ to $ \ket{ 0 } $. 
The states in the $ \ket{ \psi _ T } $ part represent transverse 
polarised states, and in the $ \ket{ \phi } $  represent longitudinal 
polarised states. 
Taking $ p = ( 1, 0 , 0 , 1) $, we have that the operator 
takes the form 
\begin{align*}
	\partial  ^ \mu A _ \mu ^ \dagger &=  \partial  ^ \mu \int 
	\frac{d ^ 3 p }{ ( 2 \pi )^{ 3 }  } \frac{1}{\sqrt{ 2 |\vec{p} | }  } 
	\left( \sum_{ \lambda = 0 } ^ 3 \epsilon _ \mu ^ r a_{\vec{p} } ^ r  \right)  
	e ^{ - i p _ \mu x ^ \mu } \\ 
	&=  \int \frac{d ^ 3 p  }{ ( 2 \pi )^{ 3 }  } \frac{1}{\sqrt{ 2 | \vec{p} | }  } 
	\sum _{ \lambda = 0 } ^ 3 \epsilon _ \mu ^ r a_{\vec{p} } ^ r \left(  - i p ^ \mu  \right) 
	e ^{ - i p _ \nu x ^ \nu } 
\end{align*}
This, when we operate on it with $ \ket{ \psi } $, gives us the 
condition $ \left( a _{ \vec{k} } ^ 3 - a _{ \vec{k} } ^ 0  \right)  \ket{ \phi }  =0  $. 
This is significant because it means that 
whenever a state contains a time-like photon 
of momentum $ \vec{p}$, generated by $ a _{ \vec{p} } ^{ 0 \dagger}$, then by the condition above 
(which is called the Gupta-Blauer condition), we have 
that the state necessarily contains a longitudinal 
photon, which is generated by $ a_{ \vec{p} } ^{ 3 \dagger } $. 

This is an important observation - it tells us 
that in the state $ \ket{ \phi } $, our 
Hilbert space has a basis $ \ket{ \phi _ n } $ which 
denotes the number of pairs of a time-like 
photon and a longitudinal photon. 
Thus, we have that 
\[
 \ket{ \phi } = \sum_{ n = 0 } ^\infty c _ n \ket{ \phi _ n } 
\] The Gupta-Blauer condition gives us 
that the states obey an orthogonality relation
\[
 \bra{ \phi_ m }\ket{ \phi _ n }  = \delta_{ m 0   } \delta _{ n  0}
\] So states with transverse and longitudinal photon pairs 
have zero norm. This is problematic, but we 
can bunch physical states into the equivalence class if they 
differ by just transverse and longitudinal pairs, and 
this solves the problem. 

\subsection{Timelike $ \gamma $ pairs continued}
What's the main point of this section?
Why do we care about photon pairs? 
It seems to me that this whole section is just about being consistent 
with gauge choice. 
We have asserted the condition 
\[
 \left( a _{ \vec{k} } ^ 3 - a_{\vec{k} } ^ 0  \right)  \ket{ \phi }  = 0
\] which implies the normalisation 
condition $ \bra{ \phi _ m }\ket{ \phi _ n }  = \delta _{ m_0 } \delta _{ n 0 }$. 
If we set $ \ket{ \phi _ 1 }  = a _{ \vec{p} _ 1 }^{ 0 \dagger } a _{ \vec{p} _ 2 } ^{ 3 \dagger } 
\ket{ 0 } $, and $ \ket{ \phi _ 1 ' }  = a_{ \vec{p} _ 3 } ^{ 0 \dagger } a_{ \vec{p} _ 4 } ^{ 
3 \dagger}  \ket{ 0 }  $. 
If we contract these two things 
together, we have that 
\begin{align*}
\bra{ \phi _ 1 ' }\ket{ \phi _ 1 } &=  \bra{ 0 }a _{ \vec{p}_ 4 } ^{ 3 } a _{ \vec{p} _ 3 } ^ 0 \ket{ \phi _ 1 }  \\
				   &=  \bra{ 0 }a_{\vec{p} _ 4 } ^{ 3 } a _{ \vec{p} _ 3 } ^ 3 a_{ \vec{p}_ 1 }^{ 0 \dagger } a_{\vec{p}_ 2 } ^{ 3 \dagger } \ket{0 }   
\end{align*}

Now, I'm not sure how to prove this 
but the convention above asserts that this thing must be zero. 
This is because we have the condition that these states 
obey $ \bra{ \phi _ n }\ket{ \phi _ m }  = \delta _{ 0n } \delta_{ 0m }$, 
and since we're setting $ m, n   =1 $ in the above, the above should 
be zero. 

\subsubsection{$ \gamma $ Feynman propagator}
Here we'll go through the computation of 
the Feynman propagator, this time starting from 
the expansion of the field $ A _ \mu ( x) $. 
If we want to compute a propagator bewteen two points 
given by 
\[
	\bra{ 0 }T  A_ \mu ( x ) A _ \nu ( y ) \ket{ 0 }  = 
	\int \frac{d ^  4 p }{ ( 2 \pi )^{ 4 }  } \frac{ -  i }{ p ^ 2 + i \epsilon} 
	\left[  \eta _{ \mu \nu } + ( \alpha - 1 ) \frac{p _ \mu p _ \nu }{ p ^ 2  } \right]  
	e ^{ - i p \cdot  ( x - y ) }
\] for the general $ \alpha $ gauge. 
The propagator takes the simple form $ \sim  - \frac{\eta _{ \mu \nu } }{ p ^ 2 + i \epsilon } $ 
in the Feynman gauge when we take $ \alpha = 1 $. This is also straightforward to prove on its 
own. 

\subsection{Interactions} 
If we want to explore interactions in the theory, 
we set 
\[
 \mathcal{ L }  = - \frac{1}{4 } F _{ \mu \nu } F ^{ \mu \nu }  - e j ^ \mu A _ \mu 
\] $ e $ here is some dimensionless coupling constant, 
which we call the gauge coupling. In addition, $ j ^ \mu $ 
is some current which has some symmetry. 

\begin{claim}{Interaction currents of this form are conserved.}
	We show that $ j ^ \mu $ as actually conserved. 
	That is, $ \partial  _ \mu j ^ \mu  = 0 $. 
	\begin{proof}
	For the Euler-Lagrange equations, we have that 
\[
 \partial  _ \mu F ^{ \mu \nu }  = e j ^ \nu \implies \partial  _ \nu \partial  _ \mu F ^{ \mu \nu } 
  = e \partial  _ \nu j ^ \nu  = 0 
\] We have a zero since the expression 
on the left hand side contains $ F^{ \mu \nu } $, 
which is anti-symmetric in $ \mu \nu $ and the 
symmetric partial derivative terms $ \partial  _ \mu \partial  _ \nu $. 
This means that $ j ^ \nu $ is a conserved current. 	
	\end{proof}
\end{claim}
\subsubsection{Coupling to Fermions} 
Our Dirac part of our Lagrangian 
is now given by 
\[
	\mathcal{ L } _ D = \overline{ \psi } \left( i \slashed{\partial} -m  \right) \psi 
\] which has an internal symmetry from taking $ \psi \to e ^{ - i \alpha } \psi $, 
and $ \overline{\psi } \to e ^{ i \alpha } \overline{ \psi } $, 
where $ \alpha \in \mathbb{  R} $. This internal symmetry 
induces a Noether current $ j ^ \mu  = \overline{\psi } \gamma ^ \mu \psi $, 
which is conserved. 
This gives us our full Lagrangian for quantum electrodynamics. 
\[
 \mathcal{ L } _{ \text{QED } }  = -\frac{1}{4 } F_{ \mu \nu } F ^{ \mu \nu } + 
 \overline{ \psi } \left( i \slashed{\partial} -m  \right)\psi  - e \overline{ \psi } 
 _ \alpha \gamma _{ \alpha \beta } ^{' \mu } A _ \mu \psi _ \beta 
\] This yields the Feynman rule factor $ i e \left( \gamma ^ \mu  \right)  _{ \alpha \beta } $. 
Previously, when discussing 
free Maxwell theory with $ \mathcal{ L }  = -  F_{ \mu \nu } F ^{ \mu \nu } $ , gauge symmetry was one of the arguments we 
used to whittle down our 4 possible polarisations 
to just 2 polarisations (we cancelled out unphysical polarisations). 
Do we still have gauge symmetry here under a transformation 
of the field $ A^ \mu  $ as well as the Dirac 
spinor terms $ \psi $? We will show 
that this indeed is still the case. 
We rewrite our Lagrangian as 
\[
 \mathcal{ L } _{ \text{QED} }  = - \frac{1}{4 } F _{ \mu \nu } F ^{ \mu \nu } 
 + \overline{ \psi } \left( i \slashed{D} - m   \right)  \psi 
\] where we define $ D_ \mu \psi  = \partial  _ \mu \psi + i e A _ \mu \psi  $ 
is called the covariant derivative.
Under the gauge transformation, $ \mathcal{ L } _{ \text{ QED } } $ 
is gauge invariant under 
\begin{align*}
	A _ \mu ( x ) & \to A _ \mu ( x ) + \partial  _ \mu \lambda ( x ) \\
	\psi ( x) & \to e ^{  - i e \lambda ( x) } \psi ( x) 
\end{align*}
To prove this we have that 
\begin{align*}
	D_ \mu \psi  = ( \partial  _ \mu + i e A _ \mu ) \psi & \to \partial  _ \mu ( 
	e^{ - i  e \lambda } \psi ) \\
	&=  e ^{ - i e \lambda }  D_ \mu \psi  \\
\end{align*}
You can check this gauge invariance yourself!

We will show that observables don't depend on timelike 
$ \gamma $ pairs, ie $ \ket{ \phi _ n } $. 
If we compute the Hamiltonian, we 
get that 
\[
	H = \int \frac{d ^ 3p  }{( 2 \pi )^{ 3 }  } | \vec{p} | \left( 
	\sum _{ i =  1 } ^ 3 a_{ \vec{p} } ^{ i \dagger } a_{\vec{p} } ^ i - a _{ \vec{p} } ^{ 0 \dagger } 
a _{ \vec{p} } ^ 0 \right)  
\] But our Gupta condition implies 
\[
 \bra{ \psi }a_{\vec{p} } ^{ 3 \dagger } a_{\vec{p} } ^ 3 \ket{ \psi }  = 
 \bra{ \psi }a_{\vec{p} } ^{ 0 \dagger } a _{ \vec{p} } ^ 0 \ket{ \psi } 
\]
Gauge invariance of $\mathcal{ L } _{ \text{QED} } $ implies that 
we remove the unphysical degrees of freedom in $ A _ \mu $, 
leaving two polarisation states. $ e $ has the interpretation of 
electric charge, since EL are $ \partial  _ \mu F ^{ \mu \nu}  = e j ^ \nu $. 
In electromagnetism, we interpret $ j ^ 0 $ as charge density. 
But as a quantum operstor, we set 
\[
 Q =  - e \int d ^ 3 x \overline{ \psi } \gamma ^ 0 \psi =  - e 
 \int \frac{ d ^ 3 p }{ \left( 2 \pi  \right)  ^ 3 } \sum_{ s } \left( 
 b _{ \vec{p} } ^{ s \dagger } b _{ \vec{p} } ^ s - c _{\vec{p} } ^{ s\dagger } c _{\vec{p} } ^ s \right) 
\] Which is $ - e \left( \text{number of particles }  - \text{number of anti particles} \right) $ 

\subsubsection{Coupling to Scalars} 
We'll now describe $ \pi \pm \gamma $ interactions.
For a real scalar, there is no suitable current and we can;t couple it to electromagentism. 
For a complex scalar $ \phi $, we use a covariant derivative 
\[
D _ \mu \phi = \partial  _ \mu \phi  - i e q A _ \mu \phi  
\] where the $ q $ is just a real number, which was $ - 1$ for an electron. 
This is the charge for a scalar particle. 
Under a gauge transformation, we have that $ \phi ( x) $ 
transforms as 
\[
	\phi ( x) \to e ^{ i e q \lambda ( x) } \phi ( x) 
\] So that $ D_ \mu \phi \to e ^{ i e q \lambda }  D_ \mu \phi $.
$ q $ is chage of $ \phi $ in units of $ e $. 
Our total coupled Lagrangian is 
therefore 
\[
	\mathcal{ L } _{ \text{ QED } }  = -\frac{1}{4 } F_{ \mu \nu }F ^{ \mu \nu }  +  \left( D _ \mu \phi \right)  ^{ \dagger } D ^ \mu \phi - m ^ 2 \phi ^ \dagger \phi  
\]
This means our interaction lagrangian reads 
\[
\mathcal{ L } _{ \phi \text{ QED} } ^{ int } = i e q
\left( \phi ^ \dagger \partial ^ \mu \phi  - \left( \partial  ^ \mu \phi  \right)  ^ \dagger 
\phi \right) A_ \mu + e ^ 2 q ^ 2 A _ \mu A ^ \mu \phi ^ \dagger \phi   
\]  Our first Feynman rules 
are (insert pictures here)
We can then derive a Noether current 
\[
	j ^ \mu  = i  eq \left( \left(  D^ \mu \phi  \right)  ^ \dagger  - \phi ^ \dagger D ^ \mu \phi  \right)  
\] is gauge invariant. 
A good model for electromagentic EM interactions of $ \pi ^{ \pm } $  
s and BSM with $ H ^{ \pm } $ etc. 
To couple a U ( 1) guage field $A _ \mu $ to any number of fields, 
$ \phi ^ a $ (fermions and or bosons), replace space-time derviatives with 
covariant ones 
\[
 \partial  _ \mu \phi ^ a \to D _ \mu \phi ^ a  = 
 \partial  _ \mu \phi ^ a  - ieq _ a A _ \mu \phi ^ a 
\]

