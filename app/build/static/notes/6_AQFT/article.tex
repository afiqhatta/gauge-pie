\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage[margin = 1.1in]{geometry}            		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or eps§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex	
\usepackage{adjustbox}	
\usepackage[section]{placeins}


%% LaTeX Preamble - Common packages
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{textcomp} % provide lots of new symbols
\usepackage{graphicx}  % Add graphics capabilities
\usepackage{flafter}  % Don't place floats before their definition
\usepackage{amsmath,amssymb}  % Better maths support & more symbols
\usepackage[backend=biber]{biblatex}
\usepackage{amsthm}
\usepackage{bm}  % Define \bm{} to use bold math fontsx
\usepackage[pdftex,bookmarks,colorlinks,breaklinks]{hyperref}  % PDF hyperlinks, with coloured links
\usepackage{memhfixc}  % remove conflict between the memoir class & hyperref
\usepackage{mathtools}
\usepackage[T1]{fontenc}
\usepackage[scaled]{beramono}
\usepackage{listings}
\usepackage{physics}
\usepackage{tensor}
\usepackage{simplewick} 
\usepackage{tikz} 
\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}
\usepackage{pgfplots}
\usepackage[compat=1.1.0]{tikz-feynman}
\usepackage{subfiles}
\usepackage{simpler-wick}
\usepackage{slashed}
\usepackage{fancyhdr}

\pagestyle{fancy}
\fancyhf{}
\rhead{Notes by Afiq Hatta}
\lhead{Quantum Field Theory II}
\rfoot{Page \thepage}

%% Commands for typesetting theorems, claims and other things.
\newtheoremstyle{slanted}
{1em}%   Space above
{.8em}%   Space below
{}%  Body font
{}%          Indent amount (empty = no indent, \parindent = para indent)
{\bfseries}% Thm head font
{.}%         Punctuation after thm head
{0.5em}%     Space after thm head: " " = normal interword space;
{}%         \newline = linebreak
{}%          Thm head spec (can be left empty, meaning `normal')

%% Commands for typesetting theorems, claims and other things. 

\theoremstyle{slanted}
\newtheorem{theorem}{Theorem}
\newtheorem*{thm}{Theorem}
\newtheorem*{claim}{Claim}
\newtheorem{example}{Example}
\newtheorem*{defn}{Definition}

\newcommand{\Lagr}{\mathcal{L}} 
\newcommand{\vc}[1]{\mathbf{#1}}
\newcommand{\pdrv}[2]{\frac{\partial{#1}}{\partial{#2}}}
\newcommand{\thrint}[1]{\int d^3 \vc{x} \left( {#1} \right)}

%% QFT specific macros 
\newcommand{\intp}{ \int \frac{ d^3 p }{ (2 \pi)^3 } \, }
\newcommand{\ann}[1]{a_{ \mathbf{ #1 }}}
\newcommand{\crea}[1]{a^\dagger_{ \mathbf{ #1 }}}
\newcommand{\ve}[1]{ \mathbf{ #1 } } 
\newcommand{\mode}[ 1]{ e^{ i \mathbf{ #1 } \cdot \mathbf{x} }}
\newcommand{\nmode}[1]{ e^{  - i \mathbf{ #1 } \cdot \mathbf{x} }}
\newcommand{\freq}[1]{\omega_\mathbf{ #1} } 
\newcommand{\scal}[1]{\phi ( \mathbf{ #1 })} 
\newcommand{\mom}[1]{ \pi (\mathbf{ #1 })} 
\newcommand{\arr}{\rightarrow} 
\newcommand{\planck}{\hbar}

\newcommand{\incfig}[1]{%
\def\svgwidth{\columnwidth}
\resizebox{0.75\textwidth}{!}{\input{./figures/#1.pdf_tex}}
}

\newcommand{\anop}[2]{ #1_\mathbf{#2}}
\newcommand{\crop}[2]{#1_\mathbf{#2}^\dagger}
\renewcommand{\op}[1]{\hat{\mathbf{#1}}}
\let\vec\mathbf


\usepackage{helvet} 

%tikz decoration commands 
\usetikzlibrary{decorations.pathmorphing}


\title{Notes on Quantum Field Theory II}
\author{Afiq Hatta} 
\begin{document} 
\maketitle
\tableofcontents

\pagebreak

\section{Path Integrals}%
\label{sec:path_integrals}

In this section, we'll introduce the path integral in QM, look at some methods with integrals, and then explore Feynman rules. 
Throughout these notes, we'll leave $ \hbar$,
but feel free to set this to $ 1 $ throughout 
the course. 
Let's introduce the path integral from 
the standpoint of quantum mechanics. 
The goal here is to take Schrödinger's equation 
and reformulate it into a "path integral", 
which is roughly speaking, a weighted integral 
summing over all probable paths. 
Let's consider a Hamiltonian 
in just one dimension, which as usual we 
can decompose into a kinetic and potential term
\[
\hat{H }  = H \left( \hat{ x  } , \hat{ p } \right) = \frac{\hat{p } ^ 2 }{ 2m } 
+ V\left( \hat{x} \right), \quad  \text{ with} \left[  
\hat{x } , \hat{ p } \right]  = i \planck 
\] 
Schrödinger's equation says thst 
if we have a state, its time evolution is governed the equation below, which we write as its formal 
solution by 
\[
i \planck \frac{\partial  }{\partial  t } \ket{ \psi ( t ) } 
= \overline{ H } \ket{ \psi ( t ) } 
\] Our formal solution 
is given by mutliplying by the time evolution 
operator 
\[
\ket{ \psi ( t )  } = e ^{  - i H \frac{t}{\planck } } \ket{ \psi (  0 )  }
\] 
In the Schrodinger picture, we have that 
\begin{itemize}
\item States evolve in time 
\item Operators and their eigenstates 
	are constant in time (fixed). 
\end{itemize}
Wavefunctions in position space are denoted
\[
\psi ( x , t ) = \bra{ x  }\ket{ \psi ( t ) } 
\] This gives Schrodingers equation as 
\[
\bra{ \hat{ x }} \overline{ H }\ket{ \psi  ( t ) }  =
\left(  - \frac{\planck ^ 2 }{ 2 m } \frac{\partial  ^ 2 }{\partial  x ^2 }  + V ( x )  \right) \psi ( x , t )  
\] How do we convert this differential equation 
into an integral equation? 
We have that 
\begin{align*}
\psi ( x , t )  & = \bra{ x }e ^{  - i H \frac{t}{\planck } }\ket{ \psi ( 0 ) } \\
&=  \int_{ - \infty } ^{ \infty } \bra{ x } 
e ^{ \frac{ - i H t }{ \planck } }\ket{x_0 } \bra{ x_0}\ket{ \psi ( 0 )} \\
&=  \int_{ - \infty }^{ \infty } dx_0 K ( x , x_0 ; t ) \psi( x_0 , 0 )    
\end{align*} We can introduce an integral quite straightforwardly 
by introducing a projection operator 
onto initial positions. 
We insert a complete set of states 
\[
I = \int dx_0 \ket{ x_0 }\bra{ x_0 } 
\] 
We call $ K ( x, x_0; t ) $ the Kernel. 
Repeat this procedure for $ n $ intermediate 
times and positions. 
Let $ 0 = t_0 < t_1 < \dots < t_ n < t _{ n + 1 }  = T $, 
and we factor 
\[
e^{ -\frac{i H T }{ \planck } }  = e ^{  - \frac{i}{\planck } \overline{ H } \left( 
t _{ n +1 }  -  t_ n \right)  } \dots e^{  - \frac{ i }{ \planck } \overline{ H } \left( 
t_1 - t_0 \right)  }
\] Then, 
\[
K ( x, x_0 ,T ) = \int_{  - \infty } ^{ \infty } \left[  
\prod_{ r = 1 }^ n dx _ r \bra{ x_{ r + 1 } } 
e ^{ - \frac{ i \overline{ H } }{ \planck } \left( t _{ r + 1 }  - t_ r  \right)  } 
\ket{ x _ r } \right]  \bra{ x _1} e ^{   - \frac{ i \overline{ H } }{ \planck} \left( 
t_1 - t_0 \right)  }\ket{ x_0 } 
\] Integrals are over all possible 
position eigenstates at times 
$ t_ r , r = 1 , \dots n $. 
Consider a free theory, with $ V ( \overline{ x } ) = 0 $. 
Let's define a corresponding free kernel
\[
K _ 0 \left( x, x' ; t  \right)  = \bra{ x }\exp\left( \frac{i \hat{p }^ 2   }{2m }t \right)
\ket{ x' } 
\]  Insert, on the right side, the completeness relation 
for the identity. 
\[
I  = \int_{  - \infty }^{ \infty } \frac{ dp }{ 2 \pi \planck } \ket{ p }\bra{ p }, 
\bra{ x }\ket{ p }  = \frac{1}{ \sqrt{ 2 \pi \planck }  } e ^{ \frac{ i p x }{ \planck }}
\] This gives 
\[
K_0 \left( x, x ' ; t  \right)   = 
\int_{ \infty } ^{ \infty } \frac{ dp }{ 2 \pi \planck } e ^{  - i p ^ 2 t / 
2m \planck  } e ^{ i p ( x - x ') / \planck}  = 
e ^{ \frac{ im ( x - x ' ) ^ 2 }{ 2 \planck t } } \sqrt{ \frac{ m }{ 2 \pi i 
\planck t}} 
\] Note, 
\[
\lim_{ t \to 0 } K_ 0 \left( x, x ' ; t  \right)   =\delta ( x   - x ' ) 
\] which is as expected from $ \bra{ x }\ket{ x ' }  = \delta ( x   - x ' ) $. 
From the Baker-Campbell-Haudorf formula, 
we have that 
\[
e ^{ \epsilon \hat{A } }e^{ \epsilon \hat{B } } = 
\exp\left( \epsilon \overline{ A } + \epsilon \overline{ B }  + \frac{ \epsilon ^ 2 }{2 } 
\left[  \overline{ A}, \hat{ B } \right] + \dots \right) \neq e ^{ \epsilon \left( 
\hat{ A } + \hat{ B }\right) } 
\] For small $ \epsilon $, we have that 
\[
e ^{ \epsilon ( \hat{ A  } + \hat{ B } ) } = e^{ \epsilon \hat{ A   } }e ^{ \epsilon \hat{ B } } \left(  1 + O ( \epsilon ^ 2 )  \right)
\] Now let $ \epsilon = \frac{1}{n } $, raise the above to the $ n $ power, 
so we have the result that 
\[
e ^{ \hat{ A } + \hat{ B }  } = \lim_{ n \to \infty } \left( 
e ^{ \hat{ A } / n } e ^{ \hat{B } / n  }\right) ^ n 
\] Take $ t _{  r + 1 }  - t_ r  = \delta t $, with $ \delta t \ll T $. 
Also take $ n $ large such that $ n \delta t  = T $. 
Then we can write that 
\[
 e ^{ \frac{ - i \hat{ H } \delta t }{ \planck } }  = \exp\left( \frac{ 
 - i \hat{ p } ^ 2 \delta t }{ 2 m \planck }  \right)  \exp\left( 
- \frac{ i V ( \hat{ x } ) \delta t }{ \planck }\right) \left[  
1 + O ( \delta t ) ^ 2  \right]  
\] 
Writing out the above, this gives us 
\[
\bra{ x _{ r + 1 } } \exp\left(   - \frac{ i \hat{ H } \delta t  }{ \planck } \right)
\ket{ x _ r }  = e ^{  - i V ( \hat{ x } ) \delta t  / \planck } K _ 0 ( 
x _{ r + 1 }, x _ r ; \delta t )  =
\sqrt{ \frac{m}{2 \pi i \planck  \delta t }} \exp
\left[  \frac{ i m }{ 2 \planck} \left( x_{ r + 1 }  - x _ r  / \delta t  \right)^ 2 \delta t 
- \frac{ i  }{\planck} V ( x _r ) \delta t \right] 
\] with $ T = n \delta t $. 
This gives our final expression as 
\[
K \left( x, x_0 ; T  \right)   = 
\int \left[  \prod_{r = 1 }^ r d x _r  \right]  
\left( \frac{m}{ 2 \pi i \planck \delta t }  \right)  ^{ n +1  / 2 } 
\exp \left[  i \sum_{ r = 0 } ^ n \left[  
\frac{m}{ 2} \left( \frac{x_{ r + 1 }  - x _ r }{ \delta t }  \right) ^ 2  - \frac{1}{ \planck}
V ( x _ r ) \right]   \delta t  \right] 
\] In the limit $ n \to \infty $, $ \delta t \to 0 $, 
with $ n \delta t  = T $, the exponent becomes 
\[
\frac{1}{ \planck} \int _ 0 ^ T \left[  
\frac{1}{2 } m \dot{  X  } ^ 2  - V ( x )  \right] = 
\int_ 0 ^ T dt L \left( x , \dot{ x }   \right) 
\] where $ L $ is our classical Lagrangian. 
The classical action $S  = \int dt L ( x , \dot{ x   } )  $. 
The path integral 
\[
K \left( x, x_0 ; t  \right)   = \bra{x }e ^{  - \frac{ i \hat{ H } t }{ \planck}} \ket{ x_0 } =  
\int \mathcal{ D } x e ^{  \frac{i}{\planck} S }
\] The functional integral $ \mathcal{ D } x  = \lim_{ \delta t \to 0 , n \delta T 
\text{ fixed}} \left( ... \right) \prod_{ r = 1 }^{ n } \left( ... dx_r  \right) $. 
we wont need to care about normalisation factors. 

This has the interpretation 
of the particle having associated probabilities of all 
possible paths, and then summing these. 
We will also talk about analytic continuation 
which allows us to turn the imgainary 
phase into a real exponential. 
We analytically continue to imaginary time. 
Let $ \tau  = it $, then in terms 
of this imaginary time, 
we have 
\[
\bra{ x } e ^{ \op{ H }\frac{\tau}{\planck}} \ket{x_0 } 
= \int \mathcal{ D } x e ^{  - \frac{S}{\planck}}
\]
The $ \planck  = 0 $ argument is more clear. 
Here we see the connection to 
statistical physics, where 
$ e ^{  - \frac{S}{\planck } } $ plays the role 
of the Boltzmann factor $ e ^{  -\beta H } $. 
In this case, integrals are more clearly convergent 
in this framework. 

Quantum mechanics is just quantum field theory in 
0 + 1 dimensions, where $ \op{x } \left( t  \right)  $ is 
a field and $ t $ is a variable. 
To develop a field theory, we 
need to be consistent with Lorentz invariance,
and therefore, $ t $ and $ x $  must 
be on the same footing. 
In QFT, we solve that problem by demoting 
$ x $ to be just another label, a variable. 
For example, $ \phi \left( x, t  \right)  $. 
String theory offers another choice, where 
we demote things in a different way. 

What we next want to do is devewlop the 
methods we want to use in analysing theories. 
We will work perturbatively and use 
Feynman diagrams. 
In order to simplify things a bit, 
we will first work in zero dimensions. 
We want to look at the integrals themselves and not 
worry about position or momentum. 

\section{Integrals and their Diagrams}
The first thing that we'll look at 
are correlation functions. 
In quantum mechanics, time is our only variable 
and we look at the evolution of a wavefunction. 
When we demote $ x   $, we 
now want to look at the behaviour 
in spacetime, and see how a field in one place 
affects the field in another place. 
We will see how they are connected to correlation functions. 

For simplicity, 
consider a zero dimensional 
field 
$ \phi $ which is just a real valued 
variable $ \mathbb{ R } $. 
What we want to do is look at the partition function 
as if we are in imaginary time. 
Let 
\[
	\mathcal{ Z }  = \int _{ \R} d \phi  e^{  - S ( \phi  ) / \hbar} 
\] We will add some assumptions for this. 
We assume that $ S \left( \phi  \right)  $ is a polynomial, 
which is even, and we want it 
to be well behaved as $ S ( \phi ) \to \infty $, 
as $ \phi \to \pm \infty  $ . 
What we are concerned with are our expectation values, 
where 
\[
 \left< f  \right>  = \frac{1}{\mathcal{ Z }  } 
 \int d \phi f ( \phi ) e ^{  - S / \hbar }
\] Again, we assume that 
$ f $ is well behaved and does not 
grow too fast as $ \phi \to \infty $. 
Usually, $ f $ is a polynomial in $ \phi $. 
So we've set the generic notation. 
Let's start with the simplest case which we 
call the free theory. 

\subsection{Free Theory}
For the time being, let's 
for the time being think about having $ N $ 
scalar fields (variables) instead of just one.
We label these
$ \phi _ a , a = 1 , \dots N $. 
The action will be denoted as 
\[
 S _ 0 \left( \phi  \right)   = 
 \frac{1}{2 } M _{ ab} \phi _ a \phi _ b  = \frac{1}{2 } \phi ^ T M \phi 
\] we want $ M $ to be symmetric, $ N \times N $ and positive 
definite, so that $ \det M > 0 $. 
So, as we go to a large number of dimensions, 
this is the kind of term which has both the 
kinetic term as well as the mass term. 
We can currently think of these labels 
as just being flavour labels. 
We'll generalise this when we go to higher dimensions. 
Here, we can just diagonalise. 
Looking at the partition function, 
\[
 M = P \Lambda P ^ T 
\] where $ \Lambda $ is diagonal and $ P $ is orthogonal. 
Lets also do a field redefinition where 
$ \chi  = P ^ T \phi $. 
Then, we get that the free partition function 
\[
	\mathcal{ Z } _ 0  = \int d ^ N \phi \, \exp \left( 
	 - \frac{1}{\hbar} \phi ^ T M \phi \right)  = 
	 \int d ^ N \chi \exp  \left(  - \frac{1}{\hbar } 
	 \chi ^ T \Lambda \chi \right) 
\] We can write this as the product of independent 
integrals. 
\[
 \dots  = \int_{ c = 1 } ^ N \int d \chi _ c e ^{
  - \lambda _ c \chi ^ 2  / 2 \hbar }  = \sqrt{ 
  \left( 2 \pi \hbar  \right)  ^{ N } / \det M } 
\] This 
is a very useful result. 
When we have to introduce anti-commuting numbers, 
we will see something similar. 

Let's introduce another 
concept which is useful, 
another trick from statistical physics. 
We want to get correlations out of partition functions. 
The way to do that is to introduce external sources, 
which we call $ J $, an $ N $ component external 
force. 
In this case, we map 
\[
	S _ 0 \left( \phi  \right)  \to S_ 0 \left( \phi  \right)  + J ^ T \phi 
\] Now, 
we extend the definition of the partition function 
which we call the generating function. 
\[
 Z_ 0 \left( J  \right)   = \int d ^ 4 \phi \exp 
 \left[   - \frac{1}{2 \hbar } \phi ^ T M \phi  - \frac{1}{\hbar} J ^ T \phi  \right] 
\] we now have to complete the square, 
and set $ \tilde{ \phi }  = \phi + M ^{  -1 } J  $. 
This allows us to rewrite the generating function as 
\[
	Z _ 0 \left( J  \right)   = \mathcal{ Z } _ 0 \left( 0  \right)  
	\exp \left( \frac{1}{2 \hbar } J ^ T M ^{ - 1} J  \right) 
\] We see here that this is 
our free theory multiplied by the 
sources coupled to the matrix that 
appears in the action. 
This is something that we call a 'generating function', and it will allow us to calculate correlation 
functions from differentiating with respect to $ J $. 
\[
	\left< \phi _ a \phi _ b  \right>  = \frac{1}{\mathcal{ Z } _ 0 \left( 0  \right)  } 
	\int d ^ N \phi \, \phi _ a \phi _ b \exp 
	\left(  - \frac{1}{2 \hbar} \phi ^ T M \phi  - \frac{1}{\hbar }
	J ^ T \phi \right) \mid_{ J = 0 }
\] we can get the $ \phi $ in the integrand by 
differentiating the exponential with respect to $ J $. 
So, 
\begin{align*}
 \left< \phi _ a \phi _ b  \right> &=  \frac{1}{\mathcal{ Z } _ 0 } 
 \int d ^ N \phi \left(   - \hbar \frac{\partial  }{\partial  J _ a }   \right)  
 \left(  - \hbar \frac{\partial  }{\partial  J_ b }   \right)  \exp \left( 
 \dots \right)  \mid_{ J = 0 } \\
				   &=  \frac{1}{ \mathcal{ Z } _ 0 \left( 0  \right)  } 
				   \left(  - \hbar \frac{\partial  }{\partial J_ a }  \right)
				   \left(  - \hbar \frac{\partial  }{\partial  J _ b }   \right)  \mathcal{ Z } _ 0 \left( J  \right)  \mid _{ J = 0 } \\
				   &=  \hbar \left( M ^{ - 1 }  \right) _{ ab }  \\
				   &=  \text{(diagram of two nodes 
				   connected by a line, called free propagator)} \\
\end{align*}
This is a pairing of the two fields
which are given by the indices. 
We can extend this 
to see how this works more generally. 
Let's invent some notation 
which allows us to be a little more 
general. 
Let $ l ( \phi ) $ be a linear combination 
of $ \phi _ a , a = 1, \dots, N $. 
All these expectation values are linear so we can do 
this. 
So we write 
\[
 l \left(  \phi   \right)   = \int_{ a = 1 } ^ N l _ a \phi _ a , \quad 
 l _ a \in \mathbb{ R } 
\]  Then, the steps above 
are equivalent 
to swapping 
\[
	l \left( \phi  \right)  \text{ for } l \left( 
	 - \hbar \frac{\partial  }{\partial  J } \right)  
	  = - \hbar \sum_{ a = 1 }^ N l _ a \frac{\partial }{\partial J_ a } 
\] Our correlation function 
is thus 
\[
	\left< l ^{ \left( 1  \right)  } \left( \phi  \right)  \dots 
	l ^{ \left( p \right) } \left( \phi  \right)  \right>
	 = \frac{1}{\mathcal{ Z } _ 0 } \int d ^ N \phi 
	 \prod_{ i =  1} ^ p l ^{ \left( i  \right)  } \left( \phi  \right) 
	 e ^{  - \frac{1}{ 2 \hbar } \phi ^ T M \phi  - \frac{1}{\hbar } J ^ T \phi } \mid_{ J =  = 0 }
\] Moving the functions of $ \phi $ to functions 
of derivatives, 
we find that this is equal to 
\[
	\left< \lambda ^{ \left( 1  \right)  } \left( \phi  \right)  
	\dots l ^{\left( p  \right)  }\left( \phi  \right)  \right>  
	 = \left(  - \hbar  \right)  ^ p 
	 \prod _{ i = 1 } ^ p l ^{ \left( i  \right)  } 
	 \left( \frac{\partial  }{\partial  J }   \right)  \exp \left( 
	 \frac{1}{  2 \hbar} J ^{ T } M ^{ - 1 } J \right) \mid_{ J = 0 } 
\]  
Now, if $ p$  is odd the answer is zero, 
then the integrand is odd in some $ \phi _a $ 
and the integral over $ \phi _ a \in \left(  - \infty , \infty  \right)  $ 
vanishes. 
For $ p = 2k $, the terms which are 
non-zero has $ J \to 0 $: half the derivatives to bring down 
components of $ M ^{ - 1} J $ and half to remove 
$ J $ dependence from the prefactor. 
This establishes that we get exactly $ k $ factors of $ M ^{ - 1 } $. 
Let's look at the four point function 
\[
\left< \phi _ b \phi _ c \phi _ d \phi _ f  \right>  = 
\hbar ^ 2 \left[  \left( M ^{  - 1}  \right) _{ b c } \left( M ^{ - 1 }  \right)  
_{ 
df } + \left( M ^{ - 1 } \right) _{ bd } \left( M ^{ - 1}  \right) _{ cf } 
+ \left( M ^{ - 1}  \right) _{ bf } \left( M ^{ - 1 }  \right)_{ cd }\right] 
\] In terms 
of Feynman diagrams, we've just got various propagators 
here. In terms of connecting the $ \phi $s, 
we have different components. 
We can represent this as connecting different lines. 
(Insert diagrams of lines here). 
The number of terms is the number of 
ways of forming pairs, which os 
\[
	\frac{\left(  2k  \right)  ! }{ 2 ^ k k ! }  = \text{ # ways of permutating points }
	/ ( \text{ permute inside pair }  \times \text{ permute pairs } ) 
\]  If we have a complex matrix, 
$ \phi _ a $ complex and $ M $ hermitian, 
then $ \left< \phi _ a \phi _ b ^ *  \right>  =  \hbar M ^{ab  }^{ - 1 } $ 
is represented by a line with an arrow from $ a $ to $ b $. 
 
\subsection{Interacting Theory}
We want to go beyond 
the free theory and add higher power terms 
of $ \phi $. The way 
to do this is 
to expand about $ \hbar  =0 $, which is the classical 
result. 
We will be expanding about the minimum of the action. 
On the other hand, we will not 
be as satisfactory as one may imagine, 
because the expansion may not even be convergent. 

Lets look at integrals like 
\[
	\int d \phi f \left( \phi  \right)  e ^{  - S / \hbar}
\] which do not have a Taylor expansion 
about $ \hbar   = 0 $. 
The proof is by Dyson. 
If we did have a Taylor expansion about $ \hbar  =  0 $ which 
existed for $ \hbar > 0 $,
then in the complex $ \hbar $ plane, there must be  
some finite radius of convergence. 
If there's some finite radius of convergence in 
the complex $ \hbar $ plane. 
then the expansion needs to exist 
for some negative real values of $ \hbar $. 
But this is manifestly not true. 

For $ S ( \phi  )$ to have a minimum, the integral 
is divergent if  $ \Re\left( \hbar  \right)  < 0 $. 
Therefore, the radius of convergence 
cannot be greater than zero. 
So we're not going to have convergent expansions 
here. 
(Insert diagram of complex $ \hbar$ plane with small circle 
at origin). 

So, our $ \hbar $  - expansion is at best asymptotic. 
\[
 I \left( \hbar  \right)  \sim \sum_{ n = 0 } ^{ \infty } c _ n \hbar ^  n 
\] where $ \sim $ means asymptotic to. 
This means that 
\[
	\lim _{ \hbar \to 0 } \frac{1}{ \hbar^ N  } | I \left( \hbar  \right)  
	 - \sum_{ n = 0 } ^ N c _ n \hbar ^ n | = 0 
 \]  where the limit is taken with $ N $ fixed. 
 As we take $ \hbar$ to zero, the series
 is arbitrarily close to zero. 

 It is important to note that 
 the series misses out a transcendental terms 
 like $ e^{  - \frac{1}{\hbar ^ 2 } } \sim 0  $. 
 But, $ e ^{  - \frac{1}{\hbar ^ 2 } } $ for finite $ \hbar$. 
 These are what we call 'non-perturbative contributions'. 
Let's get 
back to the theory we're interested in. 
Take our action to be 
\[
 S \left( \phi  \right)   = \frac{1}{2 } m ^ 2 \phi ^ 2 + \frac{\lambda }{ 4 ! } \phi ^ 4 
\] where we set $ S_ 0 \left( \phi  \right)  $ to be the first term, 
and $ S _ 1 \left( \phi  \right)  $ to be the second term. 
Here, we also assume that $ m ^ 2 > 0 $ and $ \lambda > 0 $. 

We can expand about the minimum of $ S \left( \phi  \right)  $, 
where $ \phi  = 0 $. 
We expand about the saddle point, so that 
\begin{align*}
	\mathcal{ Z } &=  \int d \phi e ^{  - S / \hbar }  \\
	&=  \int d \phi e ^{  - S_0 / \hbar } \sum_{ v  = 0  } ^{ \infty } 
	\frac{1}{ V! } \left(  - \frac{\lambda}{4 !  \hbar }  \right) ^{ v } \phi ^{ 4 v } 
\end{align*}
what we'll do is that we'll truncate the series 
so that we miss out transcendental terms. 
In order to make progress, we need to 
truncate the series and swap summation and integration. 
This misses out transcendental terms 
like what we had before.  

In the end what we have, is a series that 
\[
 \mathcal{ Z } \sim \frac{\sqrt{ 2 \hbar }  }{ m } \sum_{ v = 0 }^{ N } \frac{1}{v ! } 
 \left(  - \frac{\hbar \lambda }{ 4 ! m ^ 4   }  \right)^ v 2 ^{ 2v } 
 \int _ 0 ^ \infty d x \, e ^{ - x } x^{ 2v + \frac{1}{2 }  - 1 } 
\]  where $ x  = \frac{1}{ 2 \hbar } m ^ 2 \phi ^ 2 $. 
The integrand is just a gamma function, where 
\[
 \int _ 0 ^{ \infty } dx \, e ^{ - x } x ^{ 2 v + \frac{1}{2 } - 1 } 
 = \Gamma \left(  2v + \frac{1}{2 }  \right)   = \frac{ \left( 4v  \right)  ! 
 \sqrt{ \pi }  }{ 4 ^{ 2v } \left( 2v  \right)  ! }
\] In closed form, we have 
\[
 Z \sim \frac{ \sqrt{ 2 \pi \hbar }  }{ m } 
 \sum _{ v = 0 }^{ N } \left(  - \frac{ \hbar \lambda  }{ m }  \right)^{ v } 
 \frac{1}{\left( 4 !  \right)  ^{ v } v ! } \frac{\left( 4v   \right) ! }{ }
\] From String's approximation, 
we have that $ v ! \sim e ^{ v \log v } $, 
then the factors which are multiplied together 
are approximately $ v ! $. 
We have that factorial growth : asymptotic series. 
The first term in the 
product comes from the Taylor expansion of $ e ^{  - S _ 1  / \hbar  } $. 
The second term in the product comes from pairing 
the $ 4 v $ fields of the $ v $ copies of $ \phi ^ 4 $. 

We will now follow the diagrammatic 
method. 
If we write the action 
including a source term 
\begin{align*}
	\mathcal{ Z } \left( J  \right)  & = \int d \phi  \exp \left\{  
	-\frac{1}{\hbar } \left( S _ 0 \left( \phi  \right)  + S _ 1 \left( \phi  \right)  
+ J \phi \right)   \right\} \\
					 &=  \exp \left[  - \frac{1}{\hbar } S_ 1 \left(  - \hbar \frac{\partial }{\partial  J }  \right)  \right] \int 
					 d \phi \exp \left\{  
					 - \frac{1}{\hbar } \left( 
				 S_ 0 + J \phi \right) \right\} \\
				 & \propto 
				 \exp \left[  
				 - \frac{ \lambda  }{ 4 ! \hbar } \left( 
			 \hbar \frac{\partial  }{\partial  J }  \right)  ^ 4 \right]
			 \exp \left( \frac{1}{ 2 \hbar  } J ^ T 
			 M ^{ - 1 } J \right) \\
			 & \sim \sum_{ v  =0 } ^ N \frac{1}{ v ! } 
			 \left[   - \frac{ \lambda }{ 4 ! \hbar } \left( 
			 \hbar \frac{\partial  }{\partial  J }   \right) ^ 4   \right] ^ V 
			 \sum_{ p = 0  } \frac{1}{p !  } \left( \frac{1}{ 2 \hbar } J m ^{ - 2 }  J \right) ^ P  
\end{align*}

This has the associated diagrams below. 
We should check $ \mathcal{ Z } \left( 0  \right)  $. 
For a term to be non-zero when $ J = 0 $, 
we require that the number of derivative is equal to 
the number of propagators. 
This means we require 
\[
 E = 2P - 4 V  =0 
\]  where $ E $ is the number of sources 
left undifferentiated. 
Our first non-trivial terms include 
$ \left( V , P  \right)   = \left( 1, 2  \right)   = \left( 2, 4  \right)  $. 
For $ \mathcal{ Z } \left( 0  \right)  $, our first terms 
are ... 

We can count the number of times each diagram appears. 
Consider the figure 8 graph, the 'pre-diagram', 
it has one vertex with four free vertices, 
and $ p = 2 $ propagators. 
There are four factorial ways of matching 
derivatives to sources. $ A  = 4 ! $. 
The denominator od the $ \mathcal{ Z } \left( J  \right)  $ 
expansion is just, reading off, 
is 
\[
	F = \left( V !  \right)  \left( 4 !  \right)  ^{ v } \left( p !  \right)  
	2 ^ p  = 4  ! \cdot  2 \cdot  2 
\] Thus, the figure of $ 8 $ comes 
with a pre factor of $ \frac{A}{F }  = \frac{1}{8 } $ multiplied 
by $ - \frac{h \lambda }{ m ^  4 }  $. 
More generally, $ F $ accounts for permutations of 
\begin{itemize}
	\item all vertices $ v ! $ 
	\item each vertex legs $ 4 ! $ 
	\item All propagators $ p ! $ 
	\item both ends of each propagator $ 2 $ 
\end{itemize}
Symmetry of particular graph is 
important. 
For example, take the figure of eight diagram. 
Take the pairing  $ \left( 1a, 2a', 3b, 4b'  \right)  $.
Consider swapping $ a \iff a'  $  and $ 1 \iff 2  $, 
gives exactly the same graph. 
So 
\[
 \frac{A}{F }   = \frac{1}{\mathcal{ S } }, \quad \mathcal{ S } \text{ is the symmetry factor}
\] $ \mathcal{ S } $ is the number of 
ways of redrawing unlabelled graph, 
leaving it unchanged. 
For example, 
for the figure of eight graph, we can 
swap the direction fo the upper and lower loops, 
and swap the upper and lower loops. 

Looking at the basket ball diagram, 
we have $ 4 ! $ for each of the four lines attaching the two vertices, 
and swapping the vertices. 
(Insert pre-diagram drawing here)

\[
	\frac{ Z( 0 ) }{ Z _ 0 \left( 0  \right)  } 
	 = 1 - \frac{ \hbar \lambda }{ 8 m ^ 4 } + \frac{ \hbar ^ 2 \lambda ^ 2 }{ m ^ 8 } 
	 \left( \frac{1}{48 } + \frac{1}{16 } + \frac{1}{128 } \right) 
\]

From last time 
we have that \[
	\mathcal{ Z } \left( J  \right) 
	\sim \sum_{ v = 0 } ^{ N } \frac{1}{v ! } \left[  
	- \frac{\lambda}{4 ! \hbar } \left( \hbar \frac{\partial  }{\partial  J }   \right)  
^ 4 \right]  ^ v \sum _{ p = 0  } \frac{1}{p ! } \left[  
\frac{1}{2 \hbar } \frac{J ^ 2 }{ m ^ 2 } \right]   ^ p 
\] 
If we focus on the case with $ E   =   2 $, 
we have that 
\[
 Z \left( J  \right)  \superset \text{all diagrams with two external points}
\] 
We can factor out the vacuum bubble diagrams so that 
\[
 Z ( J )  = \left[  \text{No vacuum bubbles}  \right]  \left[  
 Z ( 0 ) \text{ vacuum bubbles }\right] 
\] 
Our expectation values 
are hence 
\begin{align*}
	\left< \phi ^ 2  \right> &=  \frac{ \left(  - \hbar  \right)^ 2   }{ 
	\mathcal{ Z } ( 0 ) } \left( \frac{\partial  }{\partial  J }   \right)^ 2  
	\mathcal{ Z } ( J ) \mid _{ J = 0 } \\ 
	&=  \left[  \text{ connected diagrams} \right]  \\
\end{align*}

In terms of our symmetry factors, 
from $ Z ( J ) $ the $ E = 2 $ , $ V  = 0 $, $ P = 1 $ 
term 
gives a contribution of 
\[
  = \frac{1}{2 \hbar } \frac{J^2}{m ^ 2 } , \quad F = 2, A = 1 , \frac{A}{F } 
   = \frac{1}{2 }  = \frac{1}{\mathcal{ S } }
\] So the first order contribution is 
$ \left< \phi ^ 2  \right> = \frac{\hbar}{m ^ 2 }  = \text{line diagram}$., 
$ \left< \phi ^{ 2n }  \right> $ proceeds similarly, but note 
there are disconnected diagrams. 
(Insert diagram here). 

\subssection{Effective actions}
Define the Wilsonian effective action $ \mathcal{ W } \left( J  \right)  $ 
such that 
\[
	\mathcal{ Z }\left( J \right)   = e ^{  - \mathcal{ W } \left( J  \right)  / \hbar }
\] We want to show that 
\[
	\mathcal{ W } \left( 0 \right)  = \sum \text{ all connected vacuum diagrams }
\] and 
\[
	\mathcal{ W } \left( J  \right)   = \sum \text{ all connected diagrams}
\] 
Any diagram $ D $ is a product of connected diagrams $ C _ I $. 
 \[
	 D  = \frac{1}{S _ D}\prod_{ I } \left( C _ I  \right)  ^{ n _ I } \text{ I : index over unique 
	 connected diagrams }, \quad n _ I  = \text{numbers of times } C _ I \text{ appears in } $ D $ 
\] Assume $ C _ I $ includes appropriate symmetry factor $ \frac{1}{S _ I } $. 
where $ S_ D $ is a symmetry factor 
associated with rearranging $ C _ I 's $. 
\[
	S _ D  = \prod _ I  \left( n _ I  \right)   !
\]
For example,  
if we take $ D  = $ (Insert diagram here)
The since the disconnected parts commute, 
we have  $ n_1  = 3 , n_2  = 1 $. 
This means the total symmetry factor $ S _ D = 3 ! 1!  = 6 $. 

If we write $ \left\{  n _ I  \right\}  $ as the set of integers 
specifying $ D $, we have that 
\begin{align*}
	\frac{\mathcal{ Z } }{ \mathcal{ Z } _ 0 } &=  \sum_{ n _ I } D  \\ 
						   &=  \sum _{ \left\{  n _ I  \right\}  } \prod_ I \frac{1}{ n _ I ! } \left( C _ I  \right)  ^{ n_  I }  \\
						   &=  \prod_ I 
						   \sum _{ n _ I } \frac{1}{n _ I ! }
						   \left( C _ I  \right)  ^{ n _ I } 
						   \\
						   &=  \exp \left( \sum _ I c _ I  \right)  \\
						   &=  \exp \left( \text{ 
						   \sum of unique connected diagrams }  \right)   \\
						   &=  e ^{  - \left( \mathcal{ W } 
						    - \mathcal{ W } _ 0 \right)   / \hbar }  \\
\end{align*}
so that we have $ \mathcal{ W }  = \mathcal{ W } _ 0  - \hbar \sum _ I c _ I $. 
$ \mathcal{ W } \left( J  \right)  $ is the 
generating functional for connected 
correlation functions. 
This means that we have 
\begin{align*}
	-\frac{1}{\hbar } W \left( J  \right)   &=  \log Z \left( J  \right)   \\ 
	 - \frac{1}{\hbar } \frac{\partial  ^ 2 }{\partial  J ^ 2 }  W \mid 
	_{ J = 0 } &= \frac{1}{ \mathcal{ Z } \left( 0  \right)  } 
	 \frac{\partial  ^ 2 \mathcal{ Z } }{\partial  J ^ 2 }  \mid_{ J = 0 } 
	 - \frac{1}{\left( \mathcal{ Z } \left( 0  \right)   \right)  ^ 2 } 
	 \left( \frac{\partial  \mathcal{ Z } }{\partial  J }   \right)  ^ 2 \mid _{ J = 0 } \\
	 &=  \frac{1}{\hbar ^ 2 } \left[  
	 \left< \phi ^ 2  \right>  - \left< \phi  \right> ^ 2 \right]   \\
	 & = \frac{1}{\hbar^  2 } \left< \phi ^ 2  \right> _{ \text{ connected }}
\end{align*}
Less trivially, we may encounter theories where the expecation of 
$ \phi $ is non zero, but we're not discussing that. 
Less trivially, 
\[
  - \frac{1}{\hbar } \frac{\partial  ^ 4 \mathcal{ W } }{\partial  J ^ 4 }  \mid_{ J = 0 } 
  = \frac{1}{ \mathcal{ Z } \left(  0  \right)  } \frac{\partial  
  ^ 4 \mathcal{ Z } }{\partial  J ^ 4 }  \mid _{ J = 0 }  - 
  \left( \frac{1}{ \mathcal{ Z } \left(  0   \right) } \frac{\partial  ^ 2  
  \mathcal{ Z } }{\partial J ^ 2  }    \right)  \mid_{ J = 0 } 
\]   This implies that 
\[
 \left< \phi ^ 4  \right>_{ \text{ connected } }  = \left< \phi ^ 4  \right>  - 
 \left< \phi ^ 2  \right> ^ 2 
\]  
Let's consider an action 
with two real fields. 
\[
 S \left( \phi , \chi  \right)  = \frac{m ^ 2 }{ 2 } \phi ^ 2 
 + \frac{ M ^ 2 }{ 2 } \chi ^2  + \frac{\lambda}{4 } \phi ^ 2 \chi ^ 2 
\] Note that we don't have a factorial here. 
With two fields, 
we now have two sets of Feynman rules. 
We can look at the 
Wilson effective action 
by looking at the connected vacuum diagrams. 
\[
  - \mathcal{ W } / \hbar   = \text{diagram of connected vacuum diagrams }
\] Counting 
the symmetry factors of 
this diagram are 
\[
  - \frac{\mathcal{ W } }{ \hbar }  = 
   - \frac{\hbar \lambda }{ 4 m^ 2 M ^ 2 } + \frac{\hbar ^ 2 \lambda ^ 2 }{ 
   m ^ 4 M ^ 4 } \left[  \frac{1}{16 } + \frac{1}{16 } + \frac{1}{8 } \right] 
\] Also, from 
Feynman diagrams, 
the 
\[
	\left< \phi ^ 2  \right>    = \text{(connected diagrams with external lines)}
\] Again, counting the 
symmetry factors, we get that 
\[
 \left< \phi ^ 2  \right>  = \frac{\hbar}{m ^ 2 }
  - \frac{\hbar ^ 2 \lambda }{ 2 m ^ 4 M^ 2 } + \frac{\hbar ^ 3 \lambda ^ 2  }{ 
  \m ^ 6 M ^ 4 } \left[  \frac{1}{4  } + \frac{1}{2 } + \frac{1}{4 } \right] 
\] say we don't care about $ \chi $ 
explicitly,
maybe because we don't know that much about $ \chi $, 
we may want to integrate it out. 
This may be because $ M \gg  m $, never 
produced on experimental scales. 
We define $ \mathcal{ W } \left(  \phi  \right)  $, 
to give 
\[
	e ^{  - \mathcal{  W } \left( \phi  \right)   / \hbar } 
	= \int d \chi e ^{  - S \left( \phi , \chi  \right)   / \hbar }
\] Thus, $ \phi ^ 2 \chi ^ 2 $ is treated 
as a source term with $ J  = \phi ^ 2 $ in earlier 
notation. We're using our low energy 
particles, bashing them together, 
and using them as a source. 

We want to look at correlation 
functions only involving $ \psi $ fields. 
\[
	\left< f ( \phi )  \right>  = \frac{1}{2
	} \int d \phi d \chi f \left( \phi  \right)  e ^{  - S \left( 
\phi , \chi  \right)  / \hbar  }  = \frac{1}{\mathcal{ Z } } 
\int d \phi f \left( \phi  \right)  e ^{  - W \left( \phi  \right)  / \hbar }
\]  In this simple example, we 
have that 
\[
	\int d \chi e ^{  - S \left( \phi , \chi  \right)  / \hbar } 
	 = e ^{  - m ^ 2 \phi ^ 2  / 2 \hbar } \sqrt{ \frac{2 \pi \hbar }{ 
	 M ^ 2 + \left( \lambda \phi ^ 2  \right)   / 2 }} 
\]  This implies that, 
solving for $ W \left( \phi  \right)  $, 
we have 
\[
 W \left( \phi  \right)   = \frac{1}{2 } m ^ 2 \phi ^ 2  + 
 \frac{\hbar}{2 } \log \left( 1 + \frac{ \lambda }{ 2 M^ 2 } \phi ^ 2   \right)  
 + \frac{\hbar}{2 } \log \frac{ M ^ 2 }{ 2 \pi \hbar } 
\] The final term is a constant. 
One way to think about this 
is in the context of the cosmological 
constant problem. 
This cancels out in expectation 
values in QFTs. 
Let's expand the logarithm. 
We've been explicit in the inclusion of 
$ \hbar $, so expansions in the logarithm 
term are quantum effects. 
This gives us 
\[
 W \left( \phi  \right)   = 
 \left( m ^ \frac{2}{ 2 } + \frac{\hbar \lambda }{ 4 M ^ 2 }  \right)  \phi ^ 2 
  - \frac{\hbar \lambda ^ 2 }{ 16 M ^ 4 } \phi ^ 4 + 
  \frac{ \hbar \lambda ^ 3 }{ 48 M ^ 6} \phi ^ 6 + \dots 
\]One 
can think of these as an effective 
mass term. So, we have that 
\[
  W\left( \phi  \right)   = 
  \frac{ m _{ \text{eff } } ^ 2 }{ 2 } \phi ^ 2 + \frac{ \lambda ^ 4 }{ 4 ! } 
  \phi ^ 4 + \frac{ \lambda ^ 6  }{6  ! } \phi ^ 6 + \dots \frac{ \lambda _{ 2k } }{ \left( 2k  \right)  ! } \phi ^{ 2k } + \dots 
\] where we have defined $ m_{ \text{ eff } } ^ 2  = m ^   2 + 
\frac{\hbar \lambda }{ 2 M } $, 
and we define 
\[
	\lambda _{ 2k }  = \left( - 1  \right) ^{ k + 1 } \hbar 
	\frac{ \left(  2k  \right)  ! }{ 2 ^{ k + 1 } k } \frac{\lambda ^ k }{ M ^{ 2 k }}
\] In $ \dim > 0  $ , we 
usually need to calculate 
$ W \left( \phi  \right)  $ perturbatively. 
From the action $ S( \phi , \chi ) $, 
and the path integral over $ \chi $, 
we have the Feynman rules. 

The dotted lines come from the $ \phi $ field. 
Putting the integrals 
together, we have that 
this makes it equal to 
\[
	W \left( \phi  \right)   = S \left( \phi  \right)  
	+ \frac{1}{2 } \frac{ h \lambda }{ 2 M ^ 2 }\phi ^ 2  - 
	\frac{1}{4 } \frac{ \hbar \lambda ^ 2 }{ 4 M ^ 4 } \phi ^ 4 
	+  \frac{1}{3 ! } \frac{ \hbar \lambda ^ 3 }{ 8 M ^ 6 } \phi ^ 6 + \dots 
\]  
Using the effective action, 
we can also calculate the correlation 
function 
\begin{align*}
	\left< \phi ^ 2  \right> &=  \frac{1}{ \mathcal{ Z } } 
	\int d \phi \phi ^ 2 e ^{  - W \left( \phi  \right)   / \hbar  }\\
	 = \frac{ \hbar  }{ m _{ \text{eff} }^ 2  } - \frac{ \lambda _ 4 \hbar ^ 2 }{2 
	 m _{ \text{ eff } } ^ 6 }
\end{align*}

\subsection{Quantum Effective Action}
We represent the quantum effective action by $ \Gamma $. 
We want to define the 
average field in the 
presence of an external source. 
\[
	\Phi  : = \frac{\partial  W }{\partial  J } =  \left< \phi  \right> _ J 	=  - \frac{ \hbar }{ Z \left( J  \right) }
	\frac{\partial  }{\partial  J } \int d \phi e ^{  - \left(  S + J \phi  \right)   / \hbar } , S \left( 
	\phi \right)  \text{ same as before }
\] We define the Legendre transformation from $ W \left( J  \right)  
\to \Gamma \left( \Phi  \right)  $.
This is 
\[
	\Gamma ( \Phi ) = W \left(  J  \right)   - \Phi J 
\]  Note that 
\[
 \frac{\partial  \Gamma }{\partial  \Phi }   = 
 \frac{\partial  W }{\partial  \Phi }   - J -  \Phi \frac{\partial  J }{\partial  
 \Phi }   = \frac{\partial W }{\partial  J }  \frac{\partial  J }{\partial  \Phi }  
  - J  -\Phi \frac{\partial  J }{\partial  \Phi } 
\] This means 
that 
\[
 \frac{\partial  J }{\partial  \Phi }   = - J 
\] so $ J $ is the minimum of the quantum effective 
action. If $ J  = 0 $, then 
\[
 \left. \frac{\partial  \Gamma }{\partial  \Phi }  \right\vert_{ J  =0 }  = 0
\] So, $ J \to  0 $ corresponds to an 
extremum of $ \Gamma \left(  \Phi  \right)  $. 

In higher dimensions, 
one performs a derivative expansion 
\[
 \Gamma \left( \Phi   \right)   = 
 \int d ^ d x \left[   -V \left( \Phi  \right)  
  - \frac{1}{2 } \partial  ^ \mu \Phi \partial  _ \mu \Phi + \dots \right] 
\] where $ V \left( \Phi  \right)  $ is the effective potential. 
There is some analogy 
here with statistical mechanics. $ h $ is a magnetic field. 
\[
	e ^{  - \beta F (h  ) }  = \int \mathcal{ D } s \exp 
	( - \beta \mathcal{ H } )
\] The magentization 
$ M  = - \frac{\partial  F }{\partial  h }  $. The Gibbs free energy 
is \[
 G ( M  )  = F \left( h  \right)  + M h 
\] as $ h \to 0 $ , $ M $ of the system is the 
minimum of $ G $. 

We do a perturbative calculation of ,$ \Gamma \left(  \Phi   \right) $
We write 
\[
	e ^{  - W _{ \Gamma } \left( J  \right)   / g }  = \int d \Phi e ^{ 
	- \left( \Gamma \left(  \Phi  \right)   + J \Phi  \right)   / g } 
\] We define a new Planck fictitious constant, 
and include the source term $ g $. 
We know that 
$ W _{ \Gamma } \left(  J  \right)  $ is the 
sum of connected vacuum diagrams. 
\[
	W _{\Gamma }\left( J  \right) 
	= \int_{ l  =0 } ^{ \infty } g ^ l W _{ \Gamma } ^{ \left(  l  \right)   } 
	\left( J  \right) 
\]  We know that 
$ W  _{ \Gamma } ^{ \left(  0  \right)   }$ 
is composed of tree diagrams. 
In the $ g \to 0 $ limit, 
we have that $ W_{ \Gamma } \left( J  \right)    =  W_{ \Gamma } ^{ \left(  0  \right)  } 
\left( J  \right)  $. 
Also as $ g \to 0 $, integral over $ \Phi $ is 
dominated by the minimum of the exponent, 
in other words the $ \Phi $ such that 
\[
 \frac{\partial  \Gamma }{\partial  \Phi }   =  - J 
\]  But then 
\[
	W _{ \Gamma } ^{ \left(  0  \right)  } \left(  J \right)   = 
	\Gamma ( \Phi ) + J \Phi  = W \left( J  \right)  
\] where the $ W ( J ) $ is from earlier 
with action  $ S ( \phi  )  + J \phi  $. 
The moral of the 
story is that the sum of the connected diagrams 
in theory with action $ S( \phi  ) + J \phi  $ 
which is  $ W( J  )  $, can 
be constructed from the sum of tree diagrams with action  $ \Gamma \left( \Phi  \right)  
+ J \Phi $.

We make the definition that an internal line in  a graph 
is a bridge if cutting it 
would make a graph disconnected. 
A connected graph is called a 
one particle irreducible (1PI)
if it has no bridges. 

The irreducible parts are loops. 
Buried within it, 
$ \Gamma $ sums up the loop diagrams (1PI). 

\subsection{Fermions and Grassman Variables}
In zero dimensions, 
we don't have a concept of spin, 
since we don't even have a way to 
orientate things correctly. 
Thus, the best we can do is 
to construct a set of $ N $ variables, 
fermion fields, which anti-commute. 

We call these fields $ \theta ^ a , a  = 1, \dots N $. 
This has the characteristic property that 
\[
 \theta_ a \theta _ b  =  - \theta_ b \theta _ a , \quad a = 1 , \dots N 
\] 
This in particular implies that 
for a given field $ \theta ^ a $, we have 
\[
 \theta ^ a \theta ^ a  =0
\] They also 
have the property that they commute with 
scalar fields, 
so we have that 
\[
 \phi _ a \psi _ b  = \psi _ b \phi _ a , \quad a = 1 , \dots N 
\] 
With this data, we can define functions 
of these variables as a finite expansion.  
\[
 F \left( \theta  \right)  = f + \rho _ a \theta ^ a 	
 + \frac{1}{2 ! }g _{ ab } \theta ^a \theta ^ b + \frac{1}{n ! }\dots h_{ ab \dots n } \theta ^ a \theta ^ b 
 \dots \theta ^ n 
\] In these 
expansions, we have that each of the 
tensors are totally anti-symmetric.
Suppose that we only had one field 
in the case that $ a = 1 $ only. 
Then, the most 
general function we could write with this is 
\[
 F \left( \theta  \right)   = f + \rho \theta 
\] since any terms of higher order 
go to zero by antisymmetry. 

We define differentiation and 
integration on these variables as follows.
For differentiation, we have that 
\[
 \frac{\partial}{\partial \theta ^ a  } \theta ^ b + \theta ^ b \frac{\partial   }{\partial  \theta ^ a }  
  = \delta \indices{ ^ b _ a }  
\] We 
also have the integration rules. 

The integrals should be invariant under 
translation, so 
\[
	\int d \theta \left( \theta + \eta  \right)   = \int d \theta \theta 
\] If we're dealing with a single variable, 
we can then integrate by parts, since clearly 
\[
	\int d \theta \frac{\partial   }{\partial  \theta }  F \left( \theta  \right)    = 0 	 
\]  We can extend this to 
integration rules for $ n $ variables. 
Namely, we only have a non-vanishing integral when 
our integrand is a product of one power 
of each Grassman number.
\[
 \int d ^ n \theta ^ 1 \dots \theta ^ n  = 1 
\] By antisymmetry, we have that for a 
given ordering of the Grassman variables, we have that 
\[
 \int d ^ n \theta \, \theta ^{ a_1 } \dots \theta ^{ a _ n  }
  = \epsilon ^{ a_1 \dots a_ n} 
\] We can compute the Jacobian of 
this measure as follows. Suppose 
that we relate a set of new Grassman 
variables $ \theta^{  ' a  }  = N \indices{^ a _ b } \theta ^ b  $, 
where $ N \in GL \left( 2 , \mathbb{ C }  \right)   $. 
This means that 
we have, integrating over the variables, 
\begin{align*}
	\int d ^ n \theta \, \theta ^{ ' a_1  } \theta ^{ ' a_2  } \dots \theta ^{  ' a_ n  } 
	&=  N \indices{ ^{ a_1 } _{ b_ 1 } } N \indices{ ^{ a_2  } _{ b_2 } } 
	\dots N \indices{ ^{ a_n  } _{ b_n  }  } \int d^ n \theta ^{ b_ 1 } \dots \theta ^{ b _ n }  \\
	&=  N \indices{ ^{ a_1 } _{ b_1 }  } \dots N \indices{ ^{ a_ n } _{b _ n } } 
	\epsilon ^{ b_ 1 \dots b _ n }  \\
	&=  \det N \epsilon ^{ a_1 \dots a_  n }  \\
	&=  \det N \int d ^ n \theta ^{  ' } \theta^{ ' a_1 } \dots \theta ^{  ' a _n  }  
\end{align*} 

This implies that $ d ^ n  \theta  = \det N d ^ n \theta ' $.

\subsubsection{Fermionic Free Field Theory}
If we 
want to build a bosonic theory out of fermions, 
we need to include an even number of 
fermions. 
In full generality, this 
means our action has to take the form 
\[
 S \left( \theta  \right)  = \frac{1}{2 } A_{ ab } \theta ^ a \theta ^ b 
\] We have that this is 
\begin{align*}
	\mathcal{ Z }_ 0  &=  \int  d^{ 2m } \theta e ^{  - S\left( \theta  \right)   }  \\ 
			  &=  \int d ^{ 2m } \theta e ^{  - \frac{1}{2  } A\left( \theta, \theta  \right) } \\
			  &=  \int d ^{ 2m } \theta 
			  \sum_{ n  =0 } ^{ 2m } \frac{\left(  - 1  \right)  ^ n }{ 
			  \left( 2 \hbar  \right)  ^ n n !  } \left( A _{ ab } \theta ^ a 
		  \theta ^ b \right)  ^ n 
\end{align*}

Notice however, that 
when we perform Berezin integration, 
only terms which 
have a single power of each variable
don't vanish. 
Hence, the only term which doesn't 
vanish is when $ n = 2m $, 
\begin{align*}
	\mathcal{  Z} _ 0 & = 
	\int d ^2m \theta \frac{\left(  - 1  \right)  ^ n  }{ 
	\left( 2 \hbar  \right)  ^ n n ! } A_{ a_1 a_2 } \dots A _{ a_{ 2m - 1 } a _{ 2m } } 
	\theta ^{ a_1 } \theta ^{ a_2 } \dots \theta ^{ a _{ 2m } } \\
			  &=  \frac{\left( - 1  \right)  ^ n }{ 
			  \left( 2 \hbar  \right)  ^ n n ! } A_{ a_1 a_2 } \dots 
			  A_{ a _{ 2m  - 1 } a _{ 2m }  } \epsilon ^{ 
			  a_1 \dots a _{ 2m  } }
\end{align*}


\pagebreak 
\section{LSZ Reduction Formula}
We're going to 
do an illustrative example here, 
so we can get some intuition going on 
in terms of a free theory. 
The main result we'll be exploring 
today is 
scattering amplitudes in terms 
of correlation functions. For example,
let's look at $ 2 \to 2 $ scattering 
of scalar particles. 
Recall from the previous set of notes 
from quantum field theory, that our scattering 
amplitude can be written in the form $ \bra{ f }S\ket{ i } $. 
Now, it is in our interest to try and find out 
what this is in terms of our correlation functions of 
our fields $ \phi \left( x  \right) $. 
Recall that a correlation function looks like $ \bra{0}\mathcal{T }\phi ( x_1 )\phi(x_2 )\ket{0}    $. 
This is what our LSZ reduction formula is. 

Our motivation for proceeding 
is as follows. 
Since initial and final states $ \ket{ i }, \ket{ f }  $ 
are written in terms of creation operators, 
we will need to invert these to 
get expressions in $ \phi $. 

We write our free scalar field 
which can be built out of plane waves. 
\[
	\phi \left( \vec{x}  \right)  = \int \frac{d^ 3 k }{ \left( 2 \pi  \right)  ^ 3 
	2 E } \left[  a \left( \vec{k}  \right)  e^{  - i k \cdot  x } + 
a ^\dagger \left( \vec{k}  \right)  e ^{ i k \cdot  x } \right] 
\] where we have $ k \cdot  x  = E t  - \vec{k} \cdot  \vec{x} $ . 
We have relativistic 
normalisation for $ a \left( \vec{k}  \right)  $. 
Now, it's convenient to 
invert this expression via the inverse Fourier transform 
of the field and it's derivative 
\[
	\int d ^ 3 x e ^{ i k \cdot  x } \phi \left( \vec{x}  \right)  , \quad 
	\int d ^ 3 x e ^{ i k \cdot   x } \partial  _ 0 \phi \left( x    \right)  
\] One 
can easily verify that the identities below 
hold, using the standard identities. 
\begin{align*}
	a\left( \vec{k}   \right)  &=  \int d ^ 3 x e ^{ i k \cdot  x } 
	\left[  i \partial  _ 0 \phi \left( x \right) + E \phi \left( x  \right)    \right]  \\ 
	a ^\dagger \left( \vec{k}  \right)  &=  \int d ^ 3 x e ^{  - i k \cdot   x } 
	\left[   -  i \partial  _ 0 \phi (x ) + E \phi \left( x  \right)   \right] 
\end{align*}
We set our initial and final states for the free theory,
to be one-particle momentum states, 
created by applying a creation operator 
to the particle vacuum. 
\[
	\ket{ k }  = a ^\dagger \left( k  \right)  \ket{ \Omega } 
\] where $ \ket{ \Omega } $ is the true vacuum, 
which in a weakly interacting theory is 
not too different from the true free vacuum.
This is a key assumption which 
we have to make. 
We have that $ \ket{ \Omega }  $ satisfies 
$ a \left( k  \right)   \ket{ \Omega }  = 0 $, 
for all  $ k $, and $ \bra{ \Omega }\ket{ \Omega }  = 1 $ . 
We have the norm 
\[
	\bra{ \vec{k} }\ket{\vec{k}} = \left( 2 \pi  \right)  ^ 3 \left( 2 E  \right)  
	\delta ^ 3 \left( \vec{k} - \vec{k}  '  \right)  , \quad E  = \sqrt{ \vec{k}^ 2 + m ^ 2 } 
\] 
The initial and
final states we're interested in will 
be time moving Gaussian wavepackets which we 
construct from the creation operators. We introduce a Gaussian wavepacket 
\[
	a _ 1 ^\dagger : = \int d ^ 3 k f _ 1 \left( \vec{k}  \right)  a ^\dagger \left( \vec{k}  \right)  
	, \quad f _ 1 \left( \vec{k}  \right)  \propto \exp \left[  
	- \frac{\left( \vec{k}_ 1  - \vec{k} _ 2   \right)  ^ 2   }{ 4 \sigma ^ 2 }\right] 
\] similarly, we define a different moving Gaussian wavepacket for $ a _ 2 ^\dagger $ 
Now, we want to see what happens 
when these wavepackets collide with each other. 

We can evolve these Gaussians into the 
distant past and future, 
where the overlap in coordinate space is negligible. 
Assume this works when including interactions. 

We are going to evolve including the full Hamiltonian, so, 
there will be a complication that there is 
some time dependence. $ a ^\dagger \left( \vec{k}  \right)  $  
becomes time dependent, so 
we will get that $ a _  1 ^\dagger \left( t  \right)  $ and $ a _ 2 ^\dagger \left( t  \right)  $ 
depend on time. 

Assume that as $ t \to \pm \infty $, $ a _ 1 ^\dagger $ and $ a _ 2 ^\dagger $ 
coincide with their free theory 
expansions, and that we can Fourier transform 
without worrying about this complication too much. 

Define the initial and final states
as two Gaussian wavepackets moving. 
\begin{align*}
	\ket{ i }  & = \lim _{ t \to- \infty } a _1 ^\dagger \left( t  \right)  a _ 2 ^\dagger \left( t  \right)  \ket{ \Omega } \\
	\ket{ f } &=  \lim_{t \to \infty  } a _{1 ' } ^{ \dagger } \left(  t  \right)
	a _{ 2 ' } ^\dagger \left( t  \right)  \ket{ \Omega } \\
\end{align*}

We assume that $ \bra{ i }\ket{ i }  = \bra{ f }\ket{ f }  = 1 $, 
and that $ \vec{k} _ 1 \neq \vec{k} _ 2 $. 
We want $ \bra{ f }\ket{ i }  $, the scattering  
amplitude.
To do this, we need to use a 
trick. 
Note for example, that 
\begin{align*}
	a _ 1 ^\dagger \left( \infty  \right)   - 
	a_ 1 ^\dagger \left(  - \infty  \right)  &=  \int_{ - \infty } ^{ \infty } dt 
	\partial  _ 0 a _ 1 ^\dagger \left( t  \right)  \\ 
						 &=  \int d ^ 3 k _ 1  f_ 1 \left( k  \right)  
						 \int d ^ 4 x \partial  _ 0 
						 \left[  e ^{  - i k \cdot  x } 
						 \left(  -i \partial  _ 0 \phi 
					 + E \phi \right)  \right]   \\ 
						 &=  - i \int d ^ 3 k _ 1 f _ 1 \left( k  \right)  
						 \int d ^ 4 x e ^{  -i k \cdot  x } 
						 \left(  \partial _ 0 ^ 2 
						 +  E ^ 2 \right) \phi \\ 
						 &=  \int \dots \int d ^ 4 x e ^{  -i k \cdot  x } \left( 
					 \partial  _ 0 ^ 2  - \nabla ^{ \leftarrow 2 } 
				 + m ^ 2 \right) \phi ^ 2    \\
						 &=   -i \int d ^ 3 k f _ 1 \left( x  \right)  
						 \int d ^ 4 x e ^{  -i k \cdot  x } 
						 \left( \partial  ^2 + m^ 2   \right)  
						 \phi  
\end{align*} 
This is great, because 
in the last line, we simply have the Klein-Gordon operator. 
Note in free theory, we have that 
our fields solve the Klein-Gordon equation, 
so in this case we have that the difference is zero. 
\[
	a _ 1 ^\dagger \left( \infty  \right)   - a _ 1 ^\dagger\left(  - \infty  \right)   = 0 
\]
We are however looking at the 
weakly interacting case, so the 
integrand doesn't necessarily evaluate to zero. 
Now we can start to calculate the 
scattering amplitude. 
\[
 \bra{ f }\ket{ i }  = 
 \bra{ \Omega } \mathcal{ T } a _{ 1 ' } \left( \infty  \right)  
 a _{ 2 ' } \left( \infty  \right)  a _{ 1 } ^\dagger \left( - \infty  \right)  
 a _ 2 ^\dagger \left( - \infty  \right)  \ket{ \Omega } 
\]  use $ a _ j ^\dagger \left(  - \infty   \right)  = a _ j ^\dagger \left( \infty  \right)   
+ i \int d ^ 3 k f _ j \left( k  \right)  \int d ^ 4 x e ^{  - i k \cdot   x } \left( 
\partial  ^ 2 + m ^ 2 \right)  \phi $. 
Similarly, we have that 
\[
	a _ j\left( \infty  \right)   =a _ j \left(  - \infty  \right)  
	+ i \int \dots e ^{ i k \cdot   x } \dots 
\] Then, the 
only non-zero term is 
\begin{align*}
	\bra{ f }\ket{i } & = \left( i  \right)  ^ 4 
	\int d ^ 4 x_ 1 d ^ 4 x _ 2 d ^ 4 x ' _ 1 d ^ 4 x ' _ 2 e ^{ 
	 - k_ 1 \cdot  x } e ^{  - i k _  2 \cdot  x _ 2 } e ^{ i k _ 1 ' \cdot  x _ 1 ' } 
	 e ^{ i k _ 2 ' \cdot  x _ 2 '  } \\
			  & \times \left( \partial  _ 1 ^ 2 + m ^ 2  \right)  \left( \partial  _ 2 ^ 2 
	 + m ^ 2 \right)  \left( \partial  _{ 1 ' } ^ 2 + m ^ 2  \right)  \left( 
 \partial  _{2 ' } ^ 2 + m ^ 2 \right)  \\
			  & \times \bra{\Omega } \mathcal{ T } 
			  \phi \left( x_1  \right)  \phi \left( x_2  \right)  \phi 
			  \left( x_1 '  \right)  \phi \left( x_2 '   \right) \ket{ \Omega } 
\end{align*}
having taken $ \sigma \to 0 $ such that 
$ f \left( \vec{k} _ j  \right)  \to \delta ^ 3 \left( \vec{k} - \vec{k} _ j  \right)  $. 
Let's examine 
assumptions here. 
The general deviation requires 
only weaker assumptions. 

\begin{itemize}
	\item We need a unique $ \Omega $, such that 
		the first excited state is a single particle. 
	\item We want $ \phi \ket{ \Omega }  $ to be a 
		single particle state. In 
		other words, we want 
		\[
		 \bra{ \Omega} \phi \ket{ \Omega}  = 0 
		\] If not, and $ \bra{ \Omega } \phi \ket{ \Omega }  = v \neq 0 $, 
		then let $ \tilde{ \phi }  = \phi  -v   $. 
	\item We want $ \phi $ normalised such that 
		\[
			\bra{ k }\phi ( x )\ket{ 0 }  = e ^{ i k \cdot  x } 
		\] as in the free case. Usually interactions require us 
		to rescale $ \phi \to Z_{ \phi } ^{ \frac{1}{2 } } \phi $.
		We see the need to renormalise, for example, 
		\[
		 \mathcal{ L } = \frac{1}{2 } \partial _ \mu \phi \partial  ^ \mu 
		 \phi  - \frac{1}{2 } m ^ 2 \phi ^ 2  - \frac{\lambda }{ 4 ! } \phi ^ 4 
		\] From here, the coefficients 
		may spoil the LSZ formula. 
		\[
		 \mathcal{ L }  = \frac{Z _ \phi }{ 2 } 
		 \partial  _ \mu \phi \partial  ^ \mu \phi  - \frac{1}{2 } 
		 Z _ m m ^ 2 \phi ^ 2  - \frac{ \lambda }{ 4 ! } Z _ \lambda \phi ^ 4 
		\] 
\end{itemize}


\subsection*{Summary}

\subsubsection{Path Integral Derivations}
\begin{itemize}
	\item You get path integrals from repeatedly inserting 
		the completeness relation 
		\[
		 I = \int dx_0 \, \ket{x_0 }\bra{ x_0 } 
		\]
	\item The kernel is 
		\[
		 K \left( x, x_0 ,t   \right)   = \bra{x}e^{ -\frac{i \hat{H } t }{ \planck}}\ket{ x_0}
		\] 
	\item Our action is defined as 
		\[
			S  = \int_{ 0 } ^ T dt L \left(  x , \dot{ x }  \right) 
		\] 
	\item Our measure is the two-way limit 
		\[
			\mathcal{ D } x  = \lim_{ \delta t \to 0 , n \delta \text{ fixed}} 
			\sqrt{\frac{m}{ 2 \pi i \planck \delta t } }  \prod_{ r  = 1 } ^ n 
			\left( \sqrt{  \frac{m  }{2 \pi i \planck \delta t  }} dx _r  \right) 
		\] 
\end{itemize}

\subsubsection{Free Partition Functions}
\begin{itemize}
	\item The free theory is defined as 
		\[
		 S_0\left( \phi  \right)   = \frac{1}{2 } M _{ ab } \phi _ a \phi _b 
		\] 
	\item The free partition function 
		\[
			\mathcal{ Z } _ 0  = \int d ^N \phi e^{  - S \left( \phi  \right)  
			 / \hbar } 
		\] 
	\item With a source term, $ S_ 0 + J \phi $, this free partition 
		function as a function of $ J $ is 
		\[
			\mathcal{ Z } \left(  J  \right)   = 
			Z\left( 0  \right)  \exp ( \frac{1}{2\hbar  } J ^ T 
			M J ) 
		\] 
\end{itemize}


\subsubsection{Feynman Diagrams}
\begin{itemize}
	\item For each graph with $ n $ vertices, we add a combinatoric factor of 
		\[
		 \frac{| D _ n |  }{ | G _ n  | }  = \sum \frac{1}{ | \text{Aut } \Gamma | }
		\]
	\item There are two ways to generate diagrams. 
		See which combinations of exponents 
		reduce the source terms to zero, 
		then construct the possible diagrams. 
\end{itemize}

\subsubsection{Effective Actions}
\begin{itemize}
	\item The Wilsonian effective action 
		is the logarithm of the partition 
		function 
		\[
		 \mathcal{ W } =  - \hbar \log \mathcal{ Z } 
		\]
	\item The connected correlation function for $ n $ 
		variables is the $ n $ the derivative 
		of the Wilsonian effective action. 
	\item With two real 
		fields, derive the Feynman rules 
		\[
			S\left( \phi , \chi  \right)   = \frac{1}{2 } m ^2  \phi ^ 2 
			+ \frac{1}{2 } M ^ 2 \xi ^ 2  + \frac{\lambda}{4 } 
			\chi ^ 2 \phi ^ 2 
		\] The Wilsonian effective action 
		\[
		  - \mathcal{ W }  / \hbar = \text{connected vacuum bubbles} 
		\] 
	\item Integrate out high energy fields with 
		\[
			e ^{  - \mathcal{ W } \left( \phi  \right)   / \hbar } 
			= \int d \chi \, e ^{  - S \left( \phi , \chi  \right)   \ \hbar } 
		\] 
\end{itemize}

\section{Regularisation and Renormalisation}%
\label{sec:regularisation_and_renormalisation}

\section{Gauge Theories}%
\label{sec:gauge_theories}


\section{Formulating the Path Integral} 

In this section, we'll be moving on from 
our standard procedure of quantising a given Hamiltonian 
in quantum mechanics. We'll be introducing 
the concept of a path integral. The path integral 
is a 'functional integral' where we integrate over 
all possible paths with a Gaussian probability factor.

\subsection{Classical and Quantum Mechanics}
In classical mechanics, we use the Lagrangian 
as a conduit to encode the information about our 
physical system. The Lagrangian is given by a function 
of position and velocity, with 
\[
	\mathcal{ L }  = \mathcal{ L } \left( q _ a , \dot {q} _ a  \right) 
\] where $ a = 1 , \dots  , N $ is an index for each particle 
in our system. We can convert this to the Hamiltonian formalism 
where we put position and momentum on the same pedestal and 
define our conjugate momenta
\[
 p _ a = \frac{\partial  \mathcal{ L }}{\partial  \dot{q } ^ a  } 
\] We then work in terms of the Hamiltonian 
which is the Legendre transformation of the 
Lagrangian, where we eliminate $ \dot{ q }^ a   $
everywhere in the Lagrangian in favour of $ p^ a$ as follows 
\[
	H ( q_a , p _ a  ) = \sum _{ a } \dot{ q }_ a p ^ a  - \mathcal{ L } \left( q _ a , \dot{ q } _ a  \right)   
\] 
The quantum mechanical analog of this is the same. 
However, $ p_ i $ and $ q _ i $ are \textbf{promoted} to 
what we call operators, and obey commutation relations 
which as we know, eventually lead to discrete energy levels 
in the Hamiltonian. In quantum mechanics,
we write the position and momentum operators 
as $ \vec{q}^ i  $ and $ \vec{p} ^ i $ for position  
and momentum respectively. 
In the Heisenberg picture of quantum mechanics, 
operators (and not states), depend on time. 
So, we impose the commutation relations 
for some fixed coordinate time $ t \in \mathbb{ R } $, where 
\[
 \left[  \vec{q}^ i , \vec{p} _ j  \right]   = i  \delta \indices{ ^ i _ j }  
\]  
In classical field theory, we 
promote operators 
to fields instead. If $ \phi ( \vec{x} , t ) $  
represents a classical scalar field at some point in time $ t $, 
then the field as well as it's conjugate momentum $ \pi \left( \vec{x}, t   \right) $ 
obey the commutation relations
\[
	\left[  \phi ( \vec{x},  t ) , \pi ( \vec{y}, t  )  \right]  
	= i \delta ^ 3 \left( \vec{x} - \vec{y} \right) 
\] There is however a caveat in performing these 
approaches to quantisation. 
The theory is not manifestly Lorentz invariant. This is because 
when we imposed the equal time commutation 
relations above, we had to pick a preferred coordinate 
time $ t $. 

\subsection{Formulating the Path Integral} 
We use the Hamiltonian 
as a starting point. 
\[
	H ( q, p ) = \frac{p ^ 2 }{ 2m } + V ( q ) 
\] The Schrödinger equation for 
a state $ \ket{ \psi ( t ) } $ which is time dependent 
is given by 
\[
	i \frac{ d }{ dt } \ket{ \psi ( t ) }  = \op{H }  \ket{ \psi ( t ) } 
\] Now, this is 
is a first order differential equation 
and can be solved provided that 
we have the right initial conditions. 
For now, let's just write down the solution 
in a 'formal' sense, where we 'exponentiate' 
the Hamiltonian whilst being vague 
about what this actually means. 
We write the solution as 
\[
	\ket{ \psi ( t ) } = \exp\left(  - i \op{ H } t  \right)  
	\ket{ \psi ( 0 ) } 
\] To do calculations however, we 
need construct an appropriate basis of states.
For this section, we'll use 
the position basis $ \ket{ q , t } $, for 
$ q, t  \in \mathbb{ R } $. These states are 
are defined to be the eigenstates of 
the position operator $ \op{q} \left( t  \right)  $, 
so that 
\[
	\op{q } \left( t   \right) \ket{ q , t }  = q \ket { q , t }   
\] We'll impose the condition 
that these states are normalised 
so that for a fixed time, we have 
\[
 \bra{q , t}\ket{ q ' , t } = \delta \left( q - q '  \right) 
\] We impose the analogous conditions as 
well for momentum eigenstates. For now though, we'll work in 
the Schrodinger picture so that $ \op{q } $ is fixed
and hence we have that the eigenstates $ \ket{ q } $ 
are time-independent. Since these states form 
a basis, we have that they obey the completeness 
relation 
\[
	1 = \int d ^ 3 q \, \ket{ q }\bra{ q } 
\] We also label the time-independent 
momentum eigenstates as $ \ket{ p } $, 
and impose the completeness relation 
\[
	1 = \frac{ d ^ 3 p }{ ( 2 \pi )^{ 3 }  } \ket{ p } \bra{ p } 
\] Note the factor of $ 2 \pi $ that we divide by. 
Other literature doesn't include this. 
With this set of basis states, we can 
now write the abstract state $ \ket{ \psi( t ) } $ 
in terms of the position basis, where we denote 
\[
	\psi ( q, t ) = \bra{ q}\ket{ \psi  ( t ) } 
	=  \bra{q } \exp\left(  - i \op{H }t  \right)\ket{ \psi ( 0 ) } 
\] We will put this into an integral form 
for reasons we will discuss later. 
To put any equation in integral 
form, the rule of thumb is 
to employ the completeness relations 
for either the position or momentum basis.
We get that 
\begin{align*}
	\bra{ q } \exp\left( - i \op{ H } t  \right) \ket{ \psi ( 0 ) } &=  \int d ^ 3 q '\,  \bra{ q }\exp \left(  - i \op{ H } t  \right)\ket{ q ' } \bra{ q ' }\ket{\psi ( 0 )}    \\ 
									&=  \int d ^ 3 q '\,  \bra{q}\exp \left(  - i \op{H } t  \right) \ket{ q' }\psi ( q' , 0 )  \\ 							&=  \int  d ^ 3 q' \, K \left( q, q' ; t  \right)  \psi ( q' , 0 )  \\
									&=  \int d ^ 3  q ' K ( q , q ' ; t ) \psi ( q ' , 0 )  
\end{align*}  
Here we've defined $ K ( q , q '; t )  = \bra{q}\exp\left(  - i \op{H } t  \right) \ket{ q ' } $. 
Now to make progress, we need to find
a meaningful expression for what $ K \left( q, q ; T \right)  $ 
actually is. First, 'split up' 
our $ \exp (  - i \op{H } T)$ term into smaller pieces - 
that is, partition $ T $ as 
\begin{equation}
	\exp\left(  - i \op{H } T  \right)  = 
	\exp \left(  - i \op{H } \left( t_{ n + 1 }  - t _ n  \right)   \right) \exp \left(  - i \op{H } \left( t_n  - t_{ n - 1 }  \right)   \right)  \dots \exp\left(  - i \op{H } \left( t _ 1  - t _ 0  \right)   \right)  
\end{equation} here, we set by definition that 
$ t_{ n + 1 }  =T  > t _ n > t _{ n - 1 } > \dots > t _ 1 > t _ 0 = 0 $. For example, setting $ n = 1$ and inserting one 
integral as part of the completeness relation, 
we get that 
\begin{align*}
	K \left( q, q' ; T  \right)  &=  
	\bra{ q }\exp\left(  - i \op{H } \left( t_2 - t_1  \right)  \right) \exp\left(  - i \op{ H } \left( t_1  - t_0   \right)   \right) \ket{q ' }  \\
	&=  \int d q_1 \,  
	\bra{ q } \exp\left(  - i \op{H } \left( t_2  - t_1  \right) \right)\ket{q_1 } \bra{q_1 } \exp\left( - i \op{H } \left( t_1  - t_0  \right)   \right)\ket{q ' } 
\end{align*}
where we've set $ t_2 = T $. We can generalise this 
to the case where we have $ n $ time slices. We 
have that 
\begin{equation}
	K\left( q, q' , r  \right)   = 
	\int \prod_{ i = 1 } ^ n \left( d q _  r \, 
	\bra{q _{ r +  1} } \exp \left(  - i \op{ H } 
\left(  t _{ r + 1 }  - t _ r  \right)  \right) \ket{q _ r }\right)\bra{q _  1}\exp\left(  - i \op{H } \left( t_1 - t_0  \right)   \right) \ket{q ' } 
\end{equation}

\pagebreak
\section*{Example Sheet 1}

\subsection*{Question 1 (2020)}
We use the completeness relation 
in the position basis. 
\begin{align*}
	\int dx ' K ( x, t, x ' , t ' ) K \left( x' , t ' ; x_0 , t_0  \right)  
	&=  \int dx ' \, \bra{ x } e ^{  - i H \left( t - t '  \right)  } 
	\ket{ x' } \bra{ x ' } e ^{  - i H \left(  t ' -  t_0  \right)  } \ket{ x_0 } \\ 
	&=  \bra{ x } e ^{  - i H \left(  t - t '  \right)  } e ^{   - i H 
	\left( t '  - t_0  \right)  } \ket{ x_0 }  \\ 
	&=  K ( x, t , x_0 , t_0 ) 
\end{align*}
To show that $ f ( x )  = \delta ( x ) $, 
we need to show that $ f (x )  = 0 \, \forall x \neq 0 $, 
and that $ \int dx \, f ( x )  = 1 $. 

\subsection*{Question 1 (2018)}
We expand the exponential 
involving $ \lambda $ as 
\begin{align*}
	\mathcal{ Z } \left( \lambda  \right)   & = \frac{1}{\sqrt{ 2 \pi }  } 
	\int dx e ^{  - \frac{1}{2 } x ^ 2 } \sum_{ l = 0 } ^ n 
	\left(  - \lambda \frac{x ^ 4 }{ 4 ! }  \right)  ^ l \frac{1}{l ! } \\
						&=  \sum_{l = 0 }^{ n }  \frac{1}{\sqrt{ 2 \pi }  } \left(  - \frac{\lambda}{4 ! }  \right) ^{ l } \frac{1}{l ! } \int_{ \mathbb{ R } } dx \, 
						e ^{  - \frac{1}{2 } x ^ 2 } x ^{ 4l } 
\end{align*}
Now, we evaluate the integral using a trick. 
We arbitrarily set 
\[
 I ( \alpha )  = \int dx \, e ^{ \frac{1}{2 } \alpha x ^ 2 } 
\] Differentiating this integral with respect to $ \alpha $, 
we have that 
\[
	\frac{d ^{ 2l } I }{ d \alpha ^{ 2l } }  = \int_{ \mathbb{ R } } 
	dx \, \left( \frac{1}{2 }  \right)^{ 2l } x ^{ 4l } e ^{  - \frac{\alpha}{2 } x ^ 2 }
	= \sqrt{ 2 \pi }  \left( \frac{1}{2 }  \right)  ^{ 2l } 1 \left( 3  \right)  \dots 
	\left( 4l - 1  \right)  
\] Cancelling out factors and using the 
standard formula for odd factorials, 
we get that 
\[
	\int dx \, x ^{ 4l } e ^{  - \frac{\alpha}{2 } x ^ 2 }  = \sqrt{ 2 \pi }  \frac{\left( 4l  \right)  ! }{ 4 ^ l \left( 2l  \right)  ! }
\] Substituting this in 
means that we get our expression for our 
partition function as 
\[
	\mathcal{ Z } _ n \left( \lambda  \right)   = 
	\sum_{ l = 0 } ^ n \left( - \frac{ \lambda }{ 4 ! }  \right)^{ l } 
	\frac{\left( 4l  \right)  ! }{  4 ^ l \left( 2l  \right)  ! }
\]
Our contributing Feynman diagrams 
at $ l \ll 3 $ are shown in the figure.
At $ l  = 1$,  $a_ l = \frac{1}{8 } $, 
which is in agreement with a figure of $ 8 $ 
diagram. At $l  =2  $, $ a _ l  = \frac{35}{384}$, 
which agrees with the sum of the automorphism factors 
at 2 loops.

At  $l = 3 $, $ a _ l = \frac{385}{ 3072}$. 

\begin{figure}[htpb]
	\centering
	\input{e1_q1.pdf_tex}
	\caption{Feynman diagrams and their automorphism 
	factors}%
	\label{fig:}
\end{figure}
We need to sum multiple diagrams, 
which are connected with $ n $ loops to get terms in the 
expansion. 
There are two ways to get terms in the expansion. 
One is to sum all possible diagrams, 
the other is to sum connected diagrams with a certain number of loops! 

What are the possible 3 loop diagrams? 
What are the automorphism factors?
I've tried exponentiating 
the sum of connected vacuum bubbles  - doesn't 
seem to add up!


\section{Useful Identities}

\subsection{Integral Identities}
\begin{itemize}
	\item The gamma function is defined as 
		\[
		 \Gamma\left( Z   \right)  = \int_0^{ \infty} dx \, x ^{ z - 1 } e ^{ - x }
		\] 
\end{itemize}
\end{document} 
